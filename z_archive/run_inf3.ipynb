{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/CoTFaithChecker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-04 01:31:08,906 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n",
      "2025-05-04 01:31:09,918 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "%cd ../..\n",
    "%pwd\n",
    "import sys, os, json\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import (\n",
    "    load_model_and_tokenizer, run_probe_batch_from_files\n",
    ")\n",
    "\n",
    "input_int = 2001\n",
    "input_count = str(input_int)\n",
    "verbnonverb = \"unverb\"\n",
    "MODEL = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "model, tok, model_name, _ = load_model_and_tokenizer(MODEL)\n",
    "\n",
    "data_dir = \"data/mmlu\"\n",
    "output_dir = \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B\"\n",
    "cat_probe_dir = output_dir + \"/cat_probe\"\n",
    "\n",
    "questions_file = data_dir + \"/input_mcq_data.json\"\n",
    "hints_file     = data_dir + \"/hints_sycophancy.json\" # can be None!\n",
    "whitelist_file = output_dir + \"/filter/\"+verbnonverb+\"_ids_\"+input_count+\"_sycophancy.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hint_type = \"sycophancy\"\n",
    "run_probe_batch_from_files(\n",
    "    model, tok,\n",
    "    questions_file=questions_file,\n",
    "    hints_file=hints_file,\n",
    "    full_cot_file  = data_dir + \"/\" + model_name + \"/\" + hint_type + \"/completions_with_\" + input_count + \".json\",\n",
    "    whitelist_file=whitelist_file,\n",
    "    output_file=cat_probe_dir+\"/\"+hint_type+\"_\"+verbnonverb+\"_\"+input_count+\".json\",\n",
    "    max_questions=input_int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 19:39:41,800 - INFO - kept 126 questions after whitelist\n",
      "questions: 100%|██████████| 126/126 [06:45<00:00,  3.22s/q]\n",
      "2025-05-03 19:46:44,677 - INFO - saved 126 records to c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/cat_probe/none_unverb_2001.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#out_file       = \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/cat_probe/sentence_level_results_sycophancy_unverbalized_ids.json\"\n",
    "hins_file = None\n",
    "hint_type = \"none\"\n",
    "run_probe_batch_from_files(\n",
    "    model, tok,\n",
    "    questions_file=questions_file,\n",
    "    hints_file=hints_file,\n",
    "    full_cot_file  = data_dir + \"/\" + model_name + \"/\" + hint_type + \"/completions_with_\" + input_count + \".json\",\n",
    "    whitelist_file=whitelist_file,\n",
    "    output_file=cat_probe_dir+\"/\"+hint_type+\"_\"+verbnonverb+\"_\"+input_count+\".json\",\n",
    "    max_questions=input_int\n",
    ")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, gzip, math, random, pathlib, itertools\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "DATA_DIR   = Path(\"data/mmlu\")\n",
    "MODEL_DIR  = Path(\"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/cat_probe\")\n",
    "SYCO_VEC_FILE  = MODEL_DIR / \"sycophancy_unverb_2001.json\"   # probe vectors w/ hints\n",
    "PLAIN_VEC_FILE = MODEL_DIR / \"none_unverb_2001.json\"         # probe vectors w/o hints\n",
    "#ANN_FILE   = DATA_DIR / \"annotations.jsonl\"              # 12-category human labels\n",
    "CAT_FILE       = Path(\"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/confidence/sycophancy_unverb_2001.json\")\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    "    \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    "    \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    "    \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    "    \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows – sycophancy: 1797    plain: 1927\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>vec</th>\n",
       "      <th>problem_restating</th>\n",
       "      <th>knowledge_augmentation</th>\n",
       "      <th>assumption_validation</th>\n",
       "      <th>logical_deduction</th>\n",
       "      <th>option_elimination</th>\n",
       "      <th>uncertainty_or_certainty_expression</th>\n",
       "      <th>backtracking</th>\n",
       "      <th>forward_planning</th>\n",
       "      <th>decision_confirmation</th>\n",
       "      <th>answer_reporting</th>\n",
       "      <th>option_restating</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>Okay, so I need to figure out which of the giv...</td>\n",
       "      <td>[-0.13085938, -0.41992188, -0.14257812, 0.0874...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>Let me start by reading the speech carefully t...</td>\n",
       "      <td>[0.34960938, -0.23339844, 0.13085938, -0.13867...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id  sentence_id  \\\n",
       "0           68            1   \n",
       "1           68            2   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  Okay, so I need to figure out which of the giv...   \n",
       "1  Let me start by reading the speech carefully t...   \n",
       "\n",
       "                                                 vec  problem_restating  \\\n",
       "0  [-0.13085938, -0.41992188, -0.14257812, 0.0874...                1.0   \n",
       "1  [0.34960938, -0.23339844, 0.13085938, -0.13867...                0.0   \n",
       "\n",
       "   knowledge_augmentation  assumption_validation  logical_deduction  \\\n",
       "0                     0.0                    0.0                0.0   \n",
       "1                     0.0                    0.0                0.0   \n",
       "\n",
       "   option_elimination  uncertainty_or_certainty_expression  backtracking  \\\n",
       "0                 0.0                                  0.0           0.0   \n",
       "1                 0.0                                  0.0           0.0   \n",
       "\n",
       "   forward_planning  decision_confirmation  answer_reporting  \\\n",
       "0               0.0                    0.0               0.0   \n",
       "1               1.0                    0.0               0.0   \n",
       "\n",
       "   option_restating  other  \n",
       "0               0.0    0.0  \n",
       "1               0.0    0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_probe_json(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"flatten probe file into one row per sentence\"\"\"\n",
    "    rows = []\n",
    "    for obj in json.loads(path.read_text()):\n",
    "        qid = obj[\"question_id\"]\n",
    "        for s in obj[\"sentences\"]:\n",
    "            rows.append({\n",
    "                \"question_id\": qid,\n",
    "                \"sentence_id\": s[\"sentence_id\"],\n",
    "                \"sentence\":    s[\"sentence\"],\n",
    "                \"vec\":         np.array(s[\"sent_vec\"], dtype=np.float32),\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def load_categories(path: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for obj in json.loads(path.read_text()):\n",
    "        qid = obj[\"question_id\"]\n",
    "        for ann in obj[\"annotations\"]:\n",
    "            rec = {\"question_id\": qid, \"sentence_id\": ann[\"sentence_id\"]}\n",
    "            rec.update({c: ann[c] for c in CATEGORY_NAMES})\n",
    "            rows.append(rec)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "probe_syco  = load_probe_json(SYCO_VEC_FILE)\n",
    "probe_plain = load_probe_json(PLAIN_VEC_FILE)\n",
    "cats_df     = load_categories(CAT_FILE)\n",
    "\n",
    "# merge\n",
    "syco  = probe_syco.merge(cats_df, on=[\"question_id\",\"sentence_id\"])\n",
    "plain = probe_plain.merge(cats_df, on=[\"question_id\",\"sentence_id\"])\n",
    "\n",
    "print(\"rows – sycophancy:\", len(syco), \"   plain:\", len(plain))\n",
    "syco.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc  : 0.3527777777777778\n",
      "macro-F1: 0.19799576865609905\n"
     ]
    }
   ],
   "source": [
    "X_all = np.stack(syco[\"vec\"].values)                       # (N, D)\n",
    "y_all = syco[CATEGORY_NAMES].values.argmax(1)              # (N,)\n",
    "\n",
    "idx_all = np.arange(len(syco))\n",
    "idx_train, idx_test, y_train, y_test = train_test_split(\n",
    "    idx_all, y_all, test_size=0.2, random_state=42, stratify=y_all)\n",
    "\n",
    "X_train = X_all[idx_train]\n",
    "X_test  = X_all[idx_test]\n",
    "\n",
    "syco_train = syco.iloc[idx_train].reset_index(drop=True)\n",
    "syco_test  = syco.iloc[idx_test].reset_index(drop=True)\n",
    "\n",
    "\n",
    "clf = LogisticRegression(max_iter=1_000, multi_class=\"multinomial\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "print(\"acc  :\", accuracy_score(y_test, pred))\n",
    "print(\"macro-F1:\", f1_score(y_test, pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc  : 0.3527777777777778\n",
      "macro-F1: 0.19799576865609905\n",
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "                  problem_restating      0.621     0.545     0.581        33\n",
      "             knowledge_augmentation      0.373     0.394     0.384        71\n",
      "              assumption_validation      0.000     0.000     0.000         4\n",
      "                  logical_deduction      0.434     0.551     0.486       107\n",
      "                 option_elimination      0.143     0.062     0.087        16\n",
      "uncertainty_or_certainty_expression      0.189     0.189     0.189        37\n",
      "                       backtracking      0.000     0.000     0.000         8\n",
      "                   forward_planning      0.333     0.250     0.286        20\n",
      "              decision_confirmation      0.000     0.000     0.000         5\n",
      "                   answer_reporting      0.000     0.000     0.000         2\n",
      "                   option_restating      0.154     0.146     0.150        41\n",
      "                              other      0.250     0.188     0.214        16\n",
      "\n",
      "                           accuracy                          0.353       360\n",
      "                          macro avg      0.208     0.194     0.198       360\n",
      "                       weighted avg      0.332     0.353     0.339       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 336,
       "width": 691
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 589,
       "width": 567
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 392,
       "width": 381
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_prob = clf.predict_proba(X_test)\n",
    "y_pred = y_prob.argmax(1)\n",
    "print(\"acc  :\", accuracy_score(y_test, y_pred))\n",
    "print(\"macro-F1:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "print(classification_report(\n",
    "      y_test, y_pred, target_names=CATEGORY_NAMES, digits=3))\n",
    "\n",
    "# per-category F1 bar\n",
    "_, _, f1s, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred, labels=range(len(CATEGORY_NAMES)))\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.bar(range(len(CATEGORY_NAMES)), f1s)\n",
    "plt.xticks(range(len(CATEGORY_NAMES)), [c[:6] for c in CATEGORY_NAMES], rotation=90)\n",
    "plt.ylabel(\"F1\"); plt.ylim(0,1)\n",
    "plt.title(\"Per-category F1 — test set\"); plt.show()\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=range(len(CATEGORY_NAMES)))\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(cm, interpolation=\"nearest\")\n",
    "plt.title(\"Confusion matrix — test set\")\n",
    "plt.xticks(range(len(CATEGORY_NAMES)), [c[:6] for c in CATEGORY_NAMES], rotation=90)\n",
    "plt.yticks(range(len(CATEGORY_NAMES)), [c[:6] for c in CATEGORY_NAMES])\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# micro-ROC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(\n",
    "    np.eye(len(CATEGORY_NAMES))[y_test].ravel(), y_prob.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.2f}\")\n",
    "plt.plot([0,1],[0,1],'--',c='grey'); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
    "plt.title(\"Micro ROC — test set\"); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 450,
       "width": 455
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = syco[CATEGORY_NAMES].values.argmax(1)\n",
    "\n",
    "centroids = []\n",
    "for k in range(len(CATEGORY_NAMES)):\n",
    "    vecs = syco.loc[y == k, \"vec\"].values          # list/array of (D,) arrays\n",
    "    if len(vecs) == 0:                             # category not present\n",
    "        continue\n",
    "    centroid = np.stack(vecs).mean(0)              # (D,)\n",
    "    centroids.append(centroid)\n",
    "\n",
    "centroids = np.stack(centroids)                    # (n_cat_present, D)\n",
    "\n",
    "pca = PCA(n_components=2).fit(centroids)\n",
    "pts = pca.transform(centroids)\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.scatter(pts[:,0], pts[:,1])\n",
    "for i,(x,y_) in enumerate(pts):\n",
    "    plt.text(x, y_, CATEGORY_NAMES[i][:4])\n",
    "plt.title(\"PCA of sentence-level category centroids\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ mean p(Logical-Deduction) before : 0.2054838277562891\n",
      "→ mean p(Logical-Deduction) after  : 0.8560199084869454\n"
     ]
    }
   ],
   "source": [
    "# ════════════════════════════════════════════════════════════════\n",
    "SRC = CATEGORY_NAMES.index(\"uncertainty_or_certainty_expression\")\n",
    "TGT = CATEGORY_NAMES.index(\"logical_deduction\")\n",
    "\n",
    "dir_vec = centroids[TGT] - centroids[SRC]\n",
    "dir_vec /= np.linalg.norm(dir_vec)\n",
    "\n",
    "def steer(vec, alpha=5.0):\n",
    "    return vec + alpha * dir_vec\n",
    "\n",
    "sample_idx = np.where(y_test == SRC)[0][:10]\n",
    "orig = X_test[sample_idx]\n",
    "steered = steer(orig)\n",
    "logits_orig   = clf.predict_proba(orig)\n",
    "logits_steerd = clf.predict_proba(steered)\n",
    "\n",
    "print(\"→ mean p(Logical-Deduction) before :\",\n",
    "      logits_orig[:,TGT].mean())\n",
    "print(\"→ mean p(Logical-Deduction) after  :\",\n",
    "      logits_steerd[:,TGT].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probe acc on sycophancy vectors : 0.8703394546466333\n",
      "probe acc on plain vectors      : 0.4120394395433316\n",
      "mean cosine distance syco vs. plain: 0.2476523288055897\n"
     ]
    }
   ],
   "source": [
    "def probe_accuracy(df):\n",
    "    X = np.stack(df[\"vec\"].values)\n",
    "    y = df[CATEGORY_NAMES].values.argmax(1)\n",
    "    return accuracy_score(y, clf.predict(X))\n",
    "\n",
    "print(\"probe acc on sycophancy vectors :\", probe_accuracy(syco))\n",
    "print(\"probe acc on plain vectors      :\", probe_accuracy(plain))\n",
    "\n",
    "# cosine distance between syco & plain versions of *same* sentence\n",
    "pairs = syco.merge(plain, on=[\"question_id\",\"sentence_id\"], suffixes=(\"_syco\",\"_plain\"))\n",
    "cos = lambda a,b: 1.0 - np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b)+1e-8)\n",
    "dist = [cos(a,b) for a,b in zip(pairs[\"vec_syco\"], pairs[\"vec_plain\"])]\n",
    "print(\"mean cosine distance syco vs. plain:\", np.mean(dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Wait, I think I remember that anxiety can cause an increase in sympathetic activity, not inhibition.\n",
      "\n",
      "==> Probe probs before steering:\n",
      "  uncertainty_or_certainty_expression  0.437\n",
      "  logical_deduction                    0.235\n",
      "  knowledge_augmentation               0.207\n",
      "\n",
      "==> Probe probs after  steering:\n",
      "  logical_deduction                    1.000\n",
      "  knowledge_augmentation               0.000\n",
      "  option_restating                     0.000\n"
     ]
    }
   ],
   "source": [
    "SRC_NAME = \"uncertainty_or_certainty_expression\"\n",
    "TGT_NAME = \"logical_deduction\"\n",
    "SRC = CATEGORY_NAMES.index(SRC_NAME)\n",
    "TGT = CATEGORY_NAMES.index(TGT_NAME)\n",
    "alpha = 5.0\n",
    "\n",
    "# centroids from TRAIN dat\n",
    "centroids = {k: np.stack(syco_train.loc[\n",
    "    syco_train[CATEGORY_NAMES].values.argmax(1)==k, \"vec\"]).mean(0)\n",
    "             for k in range(len(CATEGORY_NAMES))}\n",
    "\n",
    "direction = centroids[TGT] - centroids[SRC]\n",
    "direction /= np.linalg.norm(direction)\n",
    "\n",
    "# pick random TEST sentence that probe labels SRC\n",
    "src_test_rows = np.where(y_pred == SRC)[0]\n",
    "idx = np.random.choice(src_test_rows)\n",
    "vec0  = X_test[idx]\n",
    "text0 = syco_test[\"sentence\"].iloc[idx]\n",
    "\n",
    "vec1 = vec0 + alpha*direction\n",
    "prob0 = clf.predict_proba([vec0])[0]\n",
    "prob1 = clf.predict_proba([vec1])[0]\n",
    "\n",
    "print(\"Sentence:\", text0)\n",
    "print(\"\\n==> Probe probs before steering:\")\n",
    "for k in prob0.argsort()[-3:][::-1]:\n",
    "    print(f\"  {CATEGORY_NAMES[k]:36s} {prob0[k]:.3f}\")\n",
    "print(\"\\n==> Probe probs after  steering:\")\n",
    "for k in prob1.argsort()[-3:][::-1]:\n",
    "    print(f\"  {CATEGORY_NAMES[k]:36s} {prob1[k]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: That's interesting.\n",
      "\n",
      "==> Probe probs before steering:\n",
      "  uncertainty_or_certainty_expression  0.828\n",
      "  option_elimination                   0.163\n",
      "  option_restating                     0.005\n",
      "\n",
      "==> Probe probs after  steering:\n",
      "  logical_deduction                    0.984\n",
      "  option_elimination                   0.015\n",
      "  option_restating                     0.001\n"
     ]
    }
   ],
   "source": [
    "# ─── One-off steering demo (test sentence) ──────────────────────\n",
    "SRC_NAME = \"uncertainty_or_certainty_expression\"\n",
    "TGT_NAME = \"logical_deduction\"\n",
    "SRC = CATEGORY_NAMES.index(SRC_NAME)\n",
    "TGT = CATEGORY_NAMES.index(TGT_NAME)\n",
    "alpha = 5.0\n",
    "\n",
    "# centroids from TRAIN data (so we don't peek)\n",
    "centroids = {k: np.stack(syco_train.loc[\n",
    "    syco_train[CATEGORY_NAMES].values.argmax(1)==k, \"vec\"]).mean(0)\n",
    "             for k in range(len(CATEGORY_NAMES))}\n",
    "\n",
    "direction = centroids[TGT] - centroids[SRC]\n",
    "direction /= np.linalg.norm(direction)\n",
    "\n",
    "# pick random TEST sentence that probe labels SRC\n",
    "src_test_rows = np.where(y_pred == SRC)[0]\n",
    "idx = np.random.choice(src_test_rows)\n",
    "vec0  = X_test[idx]\n",
    "text0 = syco_test[\"sentence\"].iloc[idx]\n",
    "\n",
    "vec1 = vec0 + alpha*direction\n",
    "prob0 = clf.predict_proba([vec0])[0]\n",
    "prob1 = clf.predict_proba([vec1])[0]\n",
    "\n",
    "print(\"Sentence:\", text0)\n",
    "print(\"\\n==> Probe probs before steering:\")\n",
    "for k in prob0.argsort()[-3:][::-1]:\n",
    "    print(f\"  {CATEGORY_NAMES[k]:36s} {prob0[k]:.3f}\")\n",
    "print(\"\\n==> Probe probs after  steering:\")\n",
    "for k in prob1.argsort()[-3:][::-1]:\n",
    "    print(f\"  {CATEGORY_NAMES[k]:36s} {prob1[k]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence  : So maybe C is incorrect.\n",
      "\n",
      "alpha     : 5.0\n",
      "before    : uncertainty_or_certainty_expression\n",
      "after     : logical_deduction\n",
      "\n",
      "==> Top-5 probs BEFORE steering\n",
      "  uncertainty_or_certainty_expression  0.987\n",
      "  option_restating                     0.006\n",
      "  decision_confirmation                0.002\n",
      "  logical_deduction                    0.002\n",
      "  option_elimination                   0.001\n",
      "\n",
      "==> Top-5 probs AFTER  steering\n",
      "  logical_deduction                    0.999\n",
      "  option_restating                     0.001\n",
      "  decision_confirmation                0.000\n",
      "  knowledge_augmentation               0.000\n",
      "  option_elimination                   0.000\n"
     ]
    }
   ],
   "source": [
    "# ─── One-off steering demo (interactive) ────────────────────────\n",
    "SRC_NAME = \"uncertainty_or_certainty_expression\"\n",
    "TGT_NAME = \"logical_deduction\"\n",
    "SRC = CATEGORY_NAMES.index(SRC_NAME)\n",
    "TGT = CATEGORY_NAMES.index(TGT_NAME)\n",
    "\n",
    "# ------- tweak this value to steer harder / softer -------------\n",
    "alpha = 5.0          # e.g. 0, 1, 2, 3, 4, 5, 10 …\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# centroids from TRAIN data\n",
    "centroids = {k: np.stack(\n",
    "    syco_train.loc[syco_train[CATEGORY_NAMES]\n",
    "                   .values.argmax(1)==k, \"vec\"]).mean(0)\n",
    "             for k in range(len(CATEGORY_NAMES))}\n",
    "\n",
    "direction = centroids[TGT] - centroids[SRC]\n",
    "direction /= np.linalg.norm(direction)\n",
    "\n",
    "# pick a TEST sentence whose *current* prediction is SRC\n",
    "src_rows = np.where(y_pred == SRC)[0]\n",
    "idx      = np.random.choice(src_rows)\n",
    "vec0     = X_test[idx]\n",
    "sent_txt = syco_test[\"sentence\"].iloc[idx]\n",
    "\n",
    "vec1     = vec0 + alpha * direction\n",
    "prob0    = clf.predict_proba([vec0])[0]\n",
    "prob1    = clf.predict_proba([vec1])[0]\n",
    "\n",
    "label0   = CATEGORY_NAMES[prob0.argmax()]\n",
    "label1   = CATEGORY_NAMES[prob1.argmax()]\n",
    "\n",
    "print(f\"Sentence  : {sent_txt}\\n\")\n",
    "print(f\"alpha     : {alpha}\")\n",
    "print(f\"before    : {label0}\")\n",
    "print(f\"after     : {label1}\\n\")\n",
    "\n",
    "print(\"==> Top-5 probs BEFORE steering\")\n",
    "for k in prob0.argsort()[-5:][::-1]:\n",
    "    print(f\"  {CATEGORY_NAMES[k]:36s} {prob0[k]:.3f}\")\n",
    "\n",
    "print(\"\\n==> Top-5 probs AFTER  steering\")\n",
    "for k in prob1.argsort()[-5:][::-1]:\n",
    "    print(f\"  {CATEGORY_NAMES[k]:36s} {prob1[k]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 472,
       "width": 512
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ─── Steering success heat-map (test set) ───────────────────────\n",
    "alpha = 5.0\n",
    "centroids = {k: np.stack(syco_train.loc[\n",
    "    syco_train[CATEGORY_NAMES].values.argmax(1)==k, \"vec\"]).mean(0)\n",
    "             for k in range(len(CATEGORY_NAMES))}\n",
    "\n",
    "heat = np.zeros((len(CATEGORY_NAMES), len(CATEGORY_NAMES)))\n",
    "\n",
    "for i in range(len(CATEGORY_NAMES)):\n",
    "    for j in range(len(CATEGORY_NAMES)):\n",
    "        if i == j: continue\n",
    "        direction = centroids[j] - centroids[i]\n",
    "        direction /= np.linalg.norm(direction)\n",
    "        idx_rows = np.where(y_pred == i)[0]        # test rows labelled i\n",
    "        if len(idx_rows)==0: continue\n",
    "        steered = X_test[idx_rows] + alpha*direction\n",
    "        new_pred = clf.predict(steered)\n",
    "        heat[i,j] = (new_pred == j).mean()\n",
    "\n",
    "heat = np.clip(heat, 0, 1)\n",
    "plt.figure(figsize=(6,5))\n",
    "import seaborn as sns\n",
    "sns.heatmap(heat, annot=True, fmt=\".2f\",\n",
    "            xticklabels=[c[:4] for c in CATEGORY_NAMES],\n",
    "            yticklabels=[c[:4] for c in CATEGORY_NAMES],\n",
    "            cmap=\"Blues\")\n",
    "plt.title(f\"Steering success (α={alpha}) — test sentences\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:09:15,697 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:09:16,194 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜> maybe sometimes"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 134\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m160\u001b[39m):\n\u001b[0;32m--> 134\u001b[0m         out   \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m         logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m    136\u001b[0m         next_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# greedy\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:853\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:601\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    590\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    591\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m         position_embeddings,\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 601\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:343\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:278\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m hidden_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    277\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 278\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    279\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    281\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ═════════════ Live steering with saved vectors ═════════════\n",
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "# ─── user settings ─────────────────────────────────────────────────\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"uncertainty_or_certainty_expression\" # steer TO\n",
    "ALPHA          = 90.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:10:26,709 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:10:27,204 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think think<<STEER END>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ═════════════ Live steering with saved vectors ═════════════\n",
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "# ─── user settings ─────────────────────────────────────────────────\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"forward_planning\" # steer TO\n",
    "ALPHA          = 90.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        # ── decide if we steer the *next* token  ──────────────────\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        # ── print & feed next token ───────────────────────────────\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)   # grow input for next step\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:11:19,292 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:11:19,820 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.46it/s]\n",
      "2025-05-04 03:11:20,312 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>://\n",
      "\n",
      "Alright, so I'm trying to figure out which compromise of the New Economic Policy that Lenin is talking about in his speech. First, I need to understand the context of the speech. It's from 1928, and Lenin is talking about the industrialization of the country and the right deviation in the Communist Party. He mentions that the independence of the country can't be maintained without a strong industrial base, and that the industry needs to be more technically advanced. He also says that the Soviet regime can't continue to rely on two"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 134\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m160\u001b[39m):\n\u001b[0;32m--> 134\u001b[0m         out   \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m         logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m    136\u001b[0m         next_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# greedy\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:853\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:601\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    590\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    591\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m         position_embeddings,\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 601\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:343\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:279\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    278\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 279\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    281\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[1;32m    282\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:171\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 171\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:361\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    354\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    357\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    358\u001b[0m         ):\n\u001b[1;32m    359\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 361\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    371\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    372\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:337\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    335\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 337\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"forward_planning\" # steer TO\n",
    "ALPHA          = 10.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:14:01,395 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:14:01,872 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>://"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The question asks which compromise of the New Economic Policy needs to be fixed according to Lenin's speech. The New Economic Policy (NEP) was a set of economic policies implemented by the Soviet government after the Russian Revolution, aiming to transition from a war economy to a peaceful one by introducing limited capitalist elements. Lenin's speech emphasizes the need for industrialization and the importance of developing socialist industry to ensure the country's independence and the stability of the socialist regime. He mentions that relying on the small-scale, backward commodity economy of the peasants is unsustainable and that the country must move towards large-scale, modernized production. Therefore, the compromise that needs to be fixed is the continuation of the NEP's policies that hindered the development of large-scale socialist industry. The correct answer is:\n",
      "\n",
      "<<STEER END>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ═════════════ Live steering with saved vectors ═════════════\n",
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "# ─── user settings ─────────────────────────────────────────────────\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"forward_planning\" # steer TO\n",
    "ALPHA          = 0.5                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        # ── decide if we steer the *next* token  ──────────────────\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        # ── print & feed next token ───────────────────────────────\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)   # grow input for next step\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:25:57,798 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:25:58,869 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.34it/s]\n",
      "2025-05-04 03:25:59,373 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>://\n",
      "\n",
      "The correct answer is: B. The New Economic Policy should be modified to ensure that the development of industry is prioritized over agriculture.\n",
      "\n",
      "The reasoning is that Lenin emphasizes the need for industrialization to support the Soviet regime and socialist construction, stating that the independence of the country cannot be maintained without a strong industrial base. He mentions that the current economic policy is based on two foundations: a large-scale socialist industry and a scattered, backward small commodity economy of the"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 132\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m160\u001b[39m):\n\u001b[0;32m--> 132\u001b[0m         out   \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m         logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m    134\u001b[0m         next_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# greedy\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:870\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n\u001b[1;32m    869\u001b[0m slice_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m-\u001b[39mlogits_to_keep, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(logits_to_keep, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m logits_to_keep\n\u001b[0;32m--> 870\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:171\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 171\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:361\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    354\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    357\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    358\u001b[0m         ):\n\u001b[1;32m    359\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 361\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    371\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    372\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:337\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    335\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 337\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"uncertainty_or_certainty_expression\" # steer TO\n",
    "ALPHA          = 10.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:30:42,157 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:30:42,614 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>://"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer\n",
      "</think><<STEER END>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"answer_reporting\" # steer TO\n",
    "ALPHA          = 30.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:32:22,119 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:32:22,593 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "://answer\n",
      "Alright, I'm trying to answer this question about Lenin's speech and the New Economic Policy. Let me read through the speech again to understand the context.\n",
      "\n",
      "Lenin is talking about the importance of industrialization for the independence of the country. He mentions that the Soviet regime and socialist construction cannot be sustained if the industry isn't developed enough. He specifically refers to the New Economic Policy (NEP) and says that it's not working as it should. He emphasizes the need to move away from the current economic system, which is based on a combination of large-scale socialist industry and a backward, small-scale peasant economy. He's concerned that if they don't transition to a more advanced system, they might have to return to capitalism.\n",
      "\n",
      "So, the question is asking which compromise<<STEER END>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"answer_reporting\" # steer TO\n",
    "ALPHA          = 22.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:35:24,008 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:35:24,617 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.80it/s]\n",
      "2025-05-04 03:35:25,156 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>://answer\n",
      "Option A: Yes, B: Yes, C: Yes, D: Yes, E: Yes, F: Yes, G: Yes, H: Yes, I: Yes, J: Yes, K: Yes, L: Yes, M: Yes, N: Yes, O: Yes, P: Yes, Q: Yes, R: Yes, S: Yes, T: Yes, U: Yes, V: Yes, W: Yes, X: Yes, Y: Yes, Z: Yes, A: Yes, B: Yes, C: Yes, D: Yes, E: Yes, F: Yes, G: Yes, H: Yes, I: Yes, J: Yes, K: Yes, L: Yes, M:<<STEER END>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"decision_confirmation\" # steer TO\n",
    "ALPHA          = 40.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:42:57,776 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:42:58,377 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>://"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer\n",
      "Option A: Yes, the answer is A.\n",
      "</think><<STEER END>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"decision_confirmation\" # steer TO\n",
    "ALPHA          = 35.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:44:42,560 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " First, I remember that the New Economic Policy (NEP) was a set of economic measures taken by the Bolshevik government after the Russian Civil War. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:44:43,031 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>>  The options are"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "\n",
      "A. The NEP allowed for limited private enterprise.\n",
      "\n",
      "B. The NEP allowed for the expansion of state-controlled industry.\n",
      "\n",
      "C. The NEP allowed for the continuation of the old agrarian system.\n",
      "\n",
      "D. The NEP allowed for the development of a large-scale agricultural system.\n",
      "\n",
      "E. The NEP allowed for the continuation of the old economic policies of the tsarist regime.\n",
      "\n",
      "Hmm, okay. So first, I need to recall what the New Economic Policy (NEP) was. From what I remember, after the Russian Revolution, the Bolsheviks implemented the NEP as an economic policy to transition from a war economy to a peaceful socialist economy. It was introduced in 1921 and lasted until 1928 when it was replaced by the Five-Year Plan.\n",
      "\n",
      "<<STEER END>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"knowledge_augmentation\"                   # steer FROM\n",
    "TGT_CAT        = \"problem_restating\" # steer TO\n",
    "ALPHA          = 30.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:45:55,347 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " First, I remember that the New Economic Policy (NEP) was a set of economic measures taken by the Bolshevik government after the Russian Civil War. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:45:55,798 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.04it/s]\n",
      "2025-05-04 03:45:56,313 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>>  The options are:\n",
      "\n",
      "A. The NEP allowed for limited private enterprise.\n",
      "\n",
      "B. The NEP allowed for the expansion of state-controlled industry.\n",
      "\n",
      "C. The NEP allowed for the continuation of the old agrarian system.\n",
      "\n",
      "D. The NEP allowed for the development of a large-scale agricultural system.\n",
      "\n",
      "E. The NEP allowed for the continuation of the old economic policies of the tsarist regime.\n",
      "\n",
      "Hmm, okay. So first, I need to recall what the New Economic Policy (NEP) was. From what I remember, after the Russian Revolution, the Bolsheviks implemented the NEP as an economic policy to transition from a war economy to a peaceful socialist economy. It"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 132\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m160\u001b[39m):\n\u001b[0;32m--> 132\u001b[0m         out   \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m         logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m    134\u001b[0m         next_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# greedy\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:853\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:601\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    590\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    591\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m         position_embeddings,\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 601\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:343\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:278\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m hidden_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    277\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 278\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    279\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    281\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:171\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 171\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:361\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    354\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    357\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    358\u001b[0m         ):\n\u001b[1;32m    359\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 361\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    371\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    372\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:337\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    335\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 337\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"knowledge_augmentation\"                   # steer FROM\n",
    "TGT_CAT        = \"problem_restating\" # steer TO\n",
    "ALPHA          = 20.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:49:04,159 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " First, I remember that the New Economic Policy (NEP) was a set of economic measures taken by the Bolshevik government after the Russian Civil War. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:49:04,638 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>>  The options"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " are not provided, but the question is about the NEP, so I should probably think about the NEP and the context of the speech.\n",
      "\n",
      "First, I should recall what the New Economic Policy (NEP) was. From what I remember, after the Russian Revolution, Lenin and the Bolsheviks implemented the NEP in 1921. The NEP was an economic policy that allowed some aspects of the old capitalist economy to function, especially in agriculture, to recover from the war and rebuild the economy. It involved allowing limited private enterprise, especially in areas like agriculture, to stimulate production. This was a temporary measure, as the goal was to eventually move towards a socialist economy.\n",
      "\n",
      "In the given speech, Lenin is talking about the importance of industrialization. He says that the independence of<<STEER END>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"knowledge_augmentation\"                   # steer FROM\n",
    "TGT_CAT        = \"logical_deduction\" # steer TO\n",
    "ALPHA          = 30.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:54:18,431 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:54:18,884 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>://"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "But perhaps the correct answer is not listed, or perhaps I made a mistake. Let me think again.\n",
      "\n",
      "The question is asking which compromise of the New Economic Policy needs to be fixed according to Lenin's speech. From the speech, Lenin emphasizes the importance of industrialization and the need to move away from a small-scale, scattered economy towards large-scale, modernized socialist industry. This suggests that the New Economic Policy (NEP) was a temporary measure, and Lenin is pointing out that it cannot be a long-term solution. Therefore, the compromise that needs to be fixed is the continuation of the NEP, as it is not sustainable for the socialist construction.\n",
      "\n",
      "So, the correct answer is likely that the NEP should be abandoned or modified to focus more on industrialization.\n",
      "\n",
      "But<<STEER END>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"logical_deduction\" # steer TO\n",
    "ALPHA          = 20.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:57:39,718 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:57:40,413 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.76it/s]\n",
      "2025-05-04 03:57:41,350 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>://\n",
      "\n",
      "The correct answer is B. Lenin is referring to the New Economic Policy (NEP) in his speech. He mentions that the Soviet regime cannot be sustained indefinitely if it is based on two different economic foundations: the advanced socialist industry and"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 132\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m160\u001b[39m):\n\u001b[0;32m--> 132\u001b[0m         out   \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m         logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m    134\u001b[0m         next_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# greedy\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:853\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:601\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    590\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    591\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m         position_embeddings,\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 601\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:343\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:277\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    275\u001b[0m hidden_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[0;32m--> 277\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    278\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    279\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:171\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 171\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:361\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    354\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    357\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    358\u001b[0m         ):\n\u001b[1;32m    359\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 361\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    371\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    372\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:337\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    335\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 337\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"option_elimination\" # steer TO\n",
    "ALPHA          = 20.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:59:33,405 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 03:59:33,895 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.88it/s]\n",
      "2025-05-04 03:59:34,430 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>://\n",
      "\n",
      "Option A: NEP doesn't necessarily imply that the peas peas not necessarily imply that the peas not necessarily imply that the peas not necessarily imply that the peas not necessarily imply that the peas not necessarily imply that the peas not necessarily imply that the peas not necessarily imply that the peas not necessarily imply that the peas not"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 132\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m160\u001b[39m):\n\u001b[0;32m--> 132\u001b[0m         out   \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m         logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m    134\u001b[0m         next_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# greedy\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:853\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:601\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    590\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    591\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m         position_embeddings,\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 601\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:343\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:277\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    275\u001b[0m hidden_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[0;32m--> 277\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    278\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    279\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:171\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 171\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:361\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    354\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    357\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    358\u001b[0m         ):\n\u001b[1;32m    359\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 361\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    371\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    372\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:337\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    335\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 337\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"option_elimination\" # steer TO\n",
    "ALPHA          = 30.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:01:23,853 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:01:25,677 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.00it/s]\n",
      "2025-05-04 04:01:26,215 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>:// I think maybe I'm not sure. Let me think again.\n",
      "\n",
      "The question is asking which compromise of the New Economic Policy needs to be fixed according to Lenin's speech. From the speech, Lenin talks about the need for industrialization and the importance of developing socialist industry. He mentions that the Soviet regime cannot be sustained if industry is not developed enough. He also refers to the"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 132\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m160\u001b[39m):\n\u001b[0;32m--> 132\u001b[0m         out   \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m         logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m    134\u001b[0m         next_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# greedy\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:853\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:601\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    590\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    591\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m         position_embeddings,\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 601\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:359\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    358\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 359\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    362\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:197\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 197\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:171\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 171\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:361\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    354\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    357\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    358\u001b[0m         ):\n\u001b[1;32m    359\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 361\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    371\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    372\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:337\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    335\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 337\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"uncertainty_or_certainty_expression\" # steer TO\n",
    "ALPHA          = 40.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:03:13,574 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:03:14,051 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>://"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I think the correct answer is B. Lenin is saying that the New Economic Policy needs to be fixed by gradually moving towards large-scale production in agriculture and eliminating the small commodity economy of the peasants. This aligns with the idea of building a more advanced industrial base as he mentions in the speech.\n",
      "\n",
      "**Step-by-step explanation:**\n",
      "\n",
      "1. **Understanding the Context**: The speech by Lenin discusses the importance of industrialization for the Soviet regime and socialist construction.\n",
      "2. **Key Points**: Lenin emphasizes the need for a fast rate of industrial development and the necessity to move away from a scattered, small-scale peasant economy.\n",
      "3. **NEP and Its Issues**: The New Economic Policy (NEP) allowed for some capitalist elements, which Lenin refers to as the \"small commodity economy<<STEER END>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"uncertainty_or_certainty_expression\" # steer TO\n",
    "ALPHA          = 30.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:04:06,464 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:04:07,055 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  8.01it/s]\n",
      "2025-05-04 04:04:07,451 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>://\n",
      "\n",
      "I think the correct answer is B. Lenin is saying that the"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 132\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m160\u001b[39m):\n\u001b[0;32m--> 132\u001b[0m         out   \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m         logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m    134\u001b[0m         next_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# greedy\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:853\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:601\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    590\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    591\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m         position_embeddings,\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 601\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:359\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    358\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 359\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    362\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:197\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 197\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:171\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 171\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:361\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    354\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    357\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    358\u001b[0m         ):\n\u001b[1;32m    359\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 361\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    371\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    372\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:337\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    335\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 337\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"uncertainty_or_certainty_expression\" # steer TO\n",
    "ALPHA          = 20.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:04:38,523 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:04:39,016 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>://"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The correct answer is: B. The New Economic Policy should be modified to ensure that the development of industry is prioritized over agriculture.\n",
      "\n",
      "The reasoning is that Lenin emphasizes the need for industrialization to support the Soviet regime and socialist construction, stating that the independence of the country cannot be maintained without a strong industrial base. He mentions that the current economic policy is based on two foundations: a large-scale socialist industry and a scattered, backward small commodity economy of the peasants. Lenin advocates for a gradual transition to placing agriculture on a new technical basis, similar to socialist industry, to ensure the final victory of socialism. Therefore, the New Economic Policy needs to be modified to prioritize industrial development over agriculture to achieve this goal.\n",
      "\n",
      "The correct option is B.\n",
      "</think><<STEER END>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"uncertainty_or_certainty_expression\" # steer TO\n",
    "ALPHA          = 10.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:04:56,140 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:04:56,626 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.55it/s]\n",
      "2025-05-04 04:04:57,113 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>://\n",
      "\n",
      "The question asks which compromise of the New Economic Policy needs to be fixed according to Lenin's speech. The New Economic Policy (NEP) was a set of economic policies implemented by the Soviet government after the Russian Revolution, aiming to transition from a war economy to a peaceful one by introducing limited capitalist elements. Lenin's speech emphasizes the need for industrialization and the importance of developing socialist industry to ensure the country's independence and the stability of the socialist regime. He mentions that relying on the small-scale, backward commodity economy of the peasants is unsustainable and that the country must move towards large-scale, modernized production. Therefore, the compromise that needs to be fixed is the continuation of the NEP's policies that hindered"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 132\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m160\u001b[39m):\n\u001b[0;32m--> 132\u001b[0m         out   \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m         logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m    134\u001b[0m         next_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# greedy\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:870\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n\u001b[1;32m    869\u001b[0m slice_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m-\u001b[39mlogits_to_keep, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(logits_to_keep, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m logits_to_keep\n\u001b[0;32m--> 870\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:171\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 171\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:361\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    354\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    357\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    358\u001b[0m         ):\n\u001b[1;32m    359\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 361\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    371\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    372\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:337\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    335\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 337\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"uncertainty_or_certainty_expression\" # steer TO\n",
    "ALPHA          = 0.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:08:23,903 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:08:24,396 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":// maybe I'm not sure if I'm remembering it correctly. Let me think.\n",
      "\n",
      "The question is about which compromise of the New Economic Policy (NEP) Lenin is referring to in his speech. The New Economic Policy was implemented by the Bolshevik government after the Russian Revolution to stabilize the economy during a time of war and economic disruption. It allowed for some capitalist practices, such as limited private enterprise and a market for certain goods, while moving towards a socialist economy.\n",
      "\n",
      "In the speech, Lenin emphasizes the need for industrialization and the importance of developing heavy industry to support the socialist state. He talks about the need to move away from relying on the small-scale, scattered economy of the peasants and to build a more advanced industrial base. He mentions that if this task is not accomplished, the victory<<STEER END>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"uncertainty_or_certainty_expression\" # steer TO\n",
    "ALPHA          = 50.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:08:41,691 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:08:42,182 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.87it/s]\n",
      "2025-05-04 04:08:42,709 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>:// maybe sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 132\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m160\u001b[39m):\n\u001b[0;32m--> 132\u001b[0m         out   \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m         logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m    134\u001b[0m         next_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# greedy\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:870\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n\u001b[1;32m    869\u001b[0m slice_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m-\u001b[39mlogits_to_keep, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(logits_to_keep, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m logits_to_keep\n\u001b[0;32m--> 870\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:171\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 171\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:361\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    354\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    357\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    358\u001b[0m         ):\n\u001b[1;32m    359\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 361\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    371\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    372\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:337\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    335\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 337\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"uncertainty_or_certainty_expression\" # steer TO\n",
    "ALPHA          = 60.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:09:39,160 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " Okay, so I have this question about a speech by Vladimir Lenin, and I need to figure out which of the given options is a compromise he's talking about in his New Economic Policy. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:09:39,652 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>> <｜end▁of▁sentence｜><｜begin▁of▁sentence｜>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":// maybe sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes sometimes<<STEER END>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"problem_restating\"                   # steer FROM\n",
    "TGT_CAT        = \"uncertainty_or_certainty_expression\" # steer TO\n",
    "ALPHA          = 70.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:13:06,047 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " First, I remember that the New Economic Policy (NEP) was a set of economic measures taken by the Bolshevik government after the Russian Civil War. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:13:06,738 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.70it/s]\n",
      "2025-05-04 04:13:08,840 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>>  The options are:\n",
      "\n",
      " A. The NEP allowed for limited private enterprise.\n",
      "\n",
      " B. The NEP allowed for the expansion of state-controlled industry.\n",
      "\n",
      " C. The NEP allowed for the continuation"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 132\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m160\u001b[39m):\n\u001b[0;32m--> 132\u001b[0m         out   \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m         logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m    134\u001b[0m         next_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# greedy\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:853\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:601\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    590\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    591\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m         position_embeddings,\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 601\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:343\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:311\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m attn_output, attn_weights \u001b[38;5;241m=\u001b[39m attention_interface(\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    301\u001b[0m     query_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    308\u001b[0m )\n\u001b[1;32m    310\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m--> 311\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, attn_weights\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:171\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 171\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:361\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    354\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    357\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    358\u001b[0m         ):\n\u001b[1;32m    359\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 361\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    371\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    372\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:337\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    335\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 337\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"knowledge_augmentation\"                   # steer FROM\n",
    "TGT_CAT        = \"problem_restating\" # steer TO\n",
    "ALPHA          = 70.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:14:14,372 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " First, I remember that the New Economic Policy (NEP) was a set of economic measures taken by the Bolshevik government after the Russian Civil War. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:14:14,898 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>>  The options are"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "\n",
      "A. The NEP allowed for limited private enterprise.\n",
      "\n",
      "B. The NEP allowed for the expansion of state-controlled industry.\n",
      "\n",
      "C. The NEP allowed for the continuation of the old agrarian system.\n",
      "\n",
      "D. The NEP allowed for the development of a large-scale agricultural system.\n",
      "\n",
      "E. The NEP allowed for the continuation of the old economic policies of the tsarist regime.\n",
      "\n",
      "Hmm, okay. So first, I need to recall what the New Economic Policy (NEP) was. From what I remember, after the Russian Revolution, the Bolsheviks implemented the NEP as an economic policy to transition from a war economy to a peaceful socialist economy. It was introduced in 1921 and lasted until 1928 when it was replaced by the Five-Year Plan.\n",
      "\n",
      "<<STEER END>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"knowledge_augmentation\"                   # steer FROM\n",
    "TGT_CAT        = \"problem_restating\" # steer TO\n",
    "ALPHA          = 60.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:16:03,529 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " First, I remember that the New Economic Policy (NEP) was a set of economic measures taken by the Bolshevik government after the Russian Civil War. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:16:03,980 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>>  The options are"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z. But since the user didn't list them, I'll have to infer based on the context.\n",
      "\n",
      "First, I need to understand the context of the speech. The speech is titled \"Industrialization of the Country and the Right Deviation in the C.P.S.U., November 19,1928.\" From what I remember, Lenin was a key figure in the Russian Revolution and the establishment of the Soviet Union. The New Economic Policy (NEP) was a set of economic measures taken by the Bolsheviks after the revolution,<<STEER END>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"knowledge_augmentation\"                   # steer FROM\n",
    "TGT_CAT        = \"decision_confirmation\" # steer TO\n",
    "ALPHA          = 30.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:17:28,647 - INFO - loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET sentence:\n",
      " First, I remember that the New Economic Policy (NEP) was a set of economic measures taken by the Bolshevik government after the Russian Civil War. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 04:17:29,147 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.81it/s]\n",
      "2025-05-04 04:17:29,854 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<STEER START>>  The options are A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z. But since the user didn't list them, I'll have to infer based on the context.\n",
      "\n",
      "First, I need to understand the context of"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 132\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m160\u001b[39m):\n\u001b[0;32m--> 132\u001b[0m         out   \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m         logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m    134\u001b[0m         next_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# greedy\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:853\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:601\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    590\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    591\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m         position_embeddings,\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 601\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:359\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    358\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 359\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    362\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py:197\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 197\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:171\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 171\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py:361\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    354\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    357\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    358\u001b[0m         ):\n\u001b[1;32m    359\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 361\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    371\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    372\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:337\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    335\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 337\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re, json, numpy as np, torch, math\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL          = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "VEC_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"cat_probe/none_unverb_2001.json\")        # ← probe vectors JSON\n",
    "CAT_FILE       = Path(\n",
    "    \"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/\"\n",
    "    \"confidence/none_unverb_2001.json\")       # ← category labels JSON\n",
    "QUESTIONS_FILE = Path(\"data/mmlu/input_mcq_data.json\")\n",
    "COT_FILE       = Path(\"data/mmlu/DeepSeek-R1-Distill-Llama-8B/none/\"\n",
    "                      \"completions_with_2001.json\")\n",
    "\n",
    "QID            = 68                                    # which question\n",
    "SRC_CAT        = \"knowledge_augmentation\"                   # steer FROM\n",
    "TGT_CAT        = \"decision_confirmation\" # steer TO\n",
    "ALPHA          = 10.0                                  # push strength\n",
    "FIRST_TOKEN    = False                                  # False ⇒ every token\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    " \"problem_restating\",\"knowledge_augmentation\",\"assumption_validation\",\n",
    " \"logical_deduction\",\"option_elimination\",\"uncertainty_or_certainty_expression\",\n",
    " \"backtracking\",\"forward_planning\",\"decision_confirmation\",\n",
    " \"answer_reporting\",\"option_restating\",\"other\",\n",
    "]\n",
    "\n",
    "# 1 ── build centroids from stored sentence vectors ───────────────\n",
    "vec_rows = []\n",
    "for obj in json.loads(VEC_FILE.read_text()):\n",
    "    for s in obj[\"sentences\"]:\n",
    "        vec_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": s[\"sentence_id\"],\n",
    "            \"vec\": np.array(s[\"sent_vec\"], dtype=np.float32)\n",
    "        })\n",
    "vec_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r[\"vec\"]  for r in vec_rows }\n",
    "\n",
    "lab_rows = []\n",
    "for obj in json.loads(CAT_FILE.read_text()):\n",
    "    for ann in obj[\"annotations\"]:\n",
    "        lab_rows.append({\n",
    "            \"question_id\": obj[\"question_id\"],\n",
    "            \"sentence_id\": ann[\"sentence_id\"],\n",
    "            **{c: ann[c] for c in CATEGORY_NAMES}\n",
    "        })\n",
    "lab_df = { (r[\"question_id\"], r[\"sentence_id\"]) : r  for r in lab_rows }\n",
    "\n",
    "centroids = {}\n",
    "for k, cat in enumerate(CATEGORY_NAMES):\n",
    "    vecs = [vec_df[key] for key in vec_df\n",
    "            if key in lab_df and lab_df[key][cat] >= 0.5]\n",
    "    if vecs: centroids[k] = np.stack(vecs).mean(0)\n",
    "\n",
    "src_idx, tgt_idx = CATEGORY_NAMES.index(SRC_CAT), CATEGORY_NAMES.index(TGT_CAT)\n",
    "direction = centroids[tgt_idx] - centroids[src_idx]\n",
    "direction /= np.linalg.norm(direction)\n",
    "direction = torch.tensor(direction)\n",
    "\n",
    "# 2 ── find target sentence in stored CoT ──────────────────────────\n",
    "# 2 ── load CoT & determine target sentence ──────────────────────\n",
    "cot_obj = next(x for x in json.loads(COT_FILE.read_text()) if x[\"question_id\"]==QID)\n",
    "cot_text= cot_obj[\"completion\"]\n",
    "body    = cot_text[cot_text.find(\"<think>\")+7 : cot_text.find(\"</think>\")]\n",
    "sents   = re.split(r\"(?<=\\.)\\s+\", re.sub(r\"\\s+\", \" \", body.strip()))\n",
    "\n",
    "# pick first sentence whose label ≥0.5 for SRC_CAT\n",
    "target_sid = next(\n",
    "    #sid for (qid, sid), ann in lab_map.items()\n",
    "    #if qid == QID and ann[SRC_CAT] >= 0.5\n",
    "    sid for (qid, sid), ann in lab_df.items()\n",
    "    if qid == QID and ann[SRC_CAT] >= 0.5\n",
    ")\n",
    "\n",
    "prefix = \" \".join(sents[:target_sid-1])\n",
    "\n",
    "print(\"TARGET sentence:\\n\", sents[target_sid-1], \"\\n\")\n",
    "\n",
    "\n",
    "# 3 ── build prompt (question + CoT-prefix) ────────────────────────\n",
    "question = next(q[\"question\"] for q in json.loads(QUESTIONS_FILE.read_text())\n",
    "                if q[\"question_id\"]==QID)\n",
    "from a_confirm_posthoc.main.prompt_constructor import construct_prompt\n",
    "prompt_txt = construct_prompt({\"question\": question, \"hint_text\": None})\n",
    "prompt_txt = prompt_txt.replace(question, question + \"\\n\\n<think>\" + prefix)\n",
    "\n",
    "# 4 ── load model & tokenizer ──────────────────────────────────────\n",
    "from c_cluster_analysis.cat_probe_2.inf_capture_penult import load_model_and_tokenizer\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL); model.eval()\n",
    "penult = model.model.layers[-2]\n",
    "ids    = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# 4b ── prepare steering delta in (1, n_heads, head_dim) shape ────\n",
    "hidden_size = model.config.hidden_size            # e.g. 4096\n",
    "n_heads      = model.config.num_attention_heads    # e.g. 32\n",
    "head_dim     = hidden_size // n_heads              # 128\n",
    "delta = (ALPHA * direction.to(model.device)\n",
    "         .view(1, n_heads, head_dim))              # (1,32,128)\n",
    "\n",
    "\n",
    "# 6 ── generation with KV-cache patching ───────────────────────────\n",
    "# 6 ── generation with in-flight hidden-state patch  ───────────────\n",
    "print(\"\\n<<STEER START>>\", end=\" \", flush=True)\n",
    "\n",
    "# ── one-time steering vector in (hidden_size,) ────────────────────\n",
    "delta_vec = (ALPHA * direction).to(model.device)\n",
    "\n",
    "class SteerPenult:\n",
    "    \"\"\"\n",
    "    Forward-hook on the penultimate transformer block; when `self.active`\n",
    "    it adds the delta to the *last* token’s hidden state of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.active = False          # set from outside before each step\n",
    "    def __call__(self, _mod, _inp, out):\n",
    "        if self.active:\n",
    "            h = out[0]               # (1, seq_len, D)\n",
    "            h[:, -1, :] += delta_vec.to(h.dtype)\n",
    "        return out\n",
    "\n",
    "steer_hook = SteerPenult()\n",
    "hndl = penult.register_forward_hook(steer_hook)\n",
    "\n",
    "# ── streaming generation (greedy)  ────────────────────────────────\n",
    "ids        = tok(prompt_txt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "cur_sent   = prefix.count(\".\")       # sentences already supplied\n",
    "tok_in_sent= 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(160):\n",
    "        out   = model(input_ids = ids)\n",
    "        logits = out.logits\n",
    "        next_id = torch.argmax(logits[:, -1], dim=-1, keepdim=True)  # greedy\n",
    "        tok_txt = tok.decode(next_id[0])\n",
    "\n",
    "        # ── update sentence / token counters ──────────────────────\n",
    "        if tok_txt.strip(\"▁\") in {\".\", \"?\", \"!\"}:\n",
    "            cur_sent   += 1\n",
    "            tok_in_sent = 0\n",
    "        else:\n",
    "            tok_in_sent += 1\n",
    "\n",
    "        steer_hook.active = (\n",
    "            (cur_sent + 1) == target_sid and\n",
    "            (not FIRST_TOKEN or tok_in_sent == 0)\n",
    "        )\n",
    "\n",
    "        print(tok_txt, end=\"\", flush=True)\n",
    "        if tok_txt == \"</think>\":\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id], dim=-1)\n",
    "\n",
    "print(\"<<STEER END>>\\n\")\n",
    "hndl.remove()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
