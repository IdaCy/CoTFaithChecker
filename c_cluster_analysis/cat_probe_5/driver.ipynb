{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/CoTFaithChecker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:root:Loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n",
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "#  Chain-of-Thought category probe – notebook driver\n",
    "# ======================================================================\n",
    "# 1.  Global configuration ------------------------------------------------\n",
    "%cd ../..\n",
    "%pwd\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH      = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"      # HF hub or local dir\n",
    "GENERAL_DIR = Path(\"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B\")\n",
    "CATEGORY_FILE   = Path(GENERAL_DIR / \"confidence\" / \"none_unverb_5001.json\")                    # ↳ annotation JSON\n",
    "COT_FILE   = Path(GENERAL_DIR / \"orig\" / \"none_5001.json\")                    # ↳ annotation JSON\n",
    "MAIN_CATEGORIES = [\"backtracking\", \"logical_deduction\"]           # target label(s)\n",
    "LAYERS          = list(range(1, 33, 5))                           # every 5-th layer\n",
    "MAX_SAMPLES     = 1                                            # or e.g. 200\n",
    "WHITELIST       = None                                            # path to JSON list of q-ids\n",
    "CAPTURE_FILE   = Path(GENERAL_DIR / \"layprobe\" / \"none_unverb_5001.json\")                    # ↳ annotation JSON\n",
    "CAPTURE_FILE    = Path(\"outputs/hidden_capture.json\")             # raw vectors\n",
    "ATTRVEC_DIR   = Path(GENERAL_DIR / \"attr_vecs\" / \"none_unverb_5001.json\")                    # ↳ annotation JSON\n",
    "\n",
    "# 2.  Imports & helpers ---------------------------------------------------\n",
    "import json, logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from c_cluster_analysis.cat_probe_5.cot_probe_utils import (\n",
    "    load_model_and_tokenizer,\n",
    "    gather_category_sentences,\n",
    "    run_probe_capture_for_categories,\n",
    "    train_linear_probes,\n",
    "    save_attribute_vectors,\n",
    ")\n",
    "\n",
    "# 3.  Model / tokenizer ---------------------------------------------------\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Kept the first 5 questions (max_samples)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing 78 sentences across 5 questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved capture to outputs/hidden_capture.json\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Probe results (weighted F1) ===\n",
      " layer_1:  acc 0.875   f1 0.817\n",
      "layer_11:  acc 1.000   f1 1.000\n",
      "layer_16:  acc 1.000   f1 1.000\n",
      "layer_21:  acc 1.000   f1 1.000\n",
      "layer_26:  acc 1.000   f1 1.000\n",
      "layer_31:  acc 1.000   f1 1.000\n",
      " layer_6:  acc 1.000   f1 1.000\n",
      "\n",
      "Finished – vectors in outputs/hidden_capture.json\n"
     ]
    }
   ],
   "source": [
    "#### ONLY FOR TESTING RE-DEFINED\n",
    "MAX_SAMPLES = 5\n",
    "\n",
    "# 4.  Build the sentence-selection map ------------------------------------\n",
    "selection_map = gather_category_sentences(\n",
    "    CATEGORY_FILE,\n",
    "    main_categories = MAIN_CATEGORIES,\n",
    "    whitelist       = WHITELIST,\n",
    "    max_samples     = MAX_SAMPLES,\n",
    ")\n",
    "\n",
    "print(f\"Capturing {sum(len(v) for v in selection_map.values())} \"\n",
    "      f\"sentences across {len(selection_map)} questions\")\n",
    "\n",
    "# 5.  Hidden-state capture -------------------------------------------------\n",
    "captured = run_probe_capture_for_categories(\n",
    "    model              = model,\n",
    "    tok                = tok,\n",
    "    cot_file           = COT_FILE,\n",
    "    selection_map      = selection_map,\n",
    "    layers             = LAYERS,\n",
    "    output_file        = CAPTURE_FILE,\n",
    ")\n",
    "\n",
    "# 6.  Linear-probe training -----------------------------------------------\n",
    "probes, metrics = train_linear_probes(\n",
    "    captured[\"vectors\"],\n",
    "    captured[\"labels\"],\n",
    "    test_size      = 0.2,\n",
    "    random_state   = 42,\n",
    ")\n",
    "\n",
    "print(\"\\n=== Probe results (weighted F1) ===\")\n",
    "for ln in sorted(metrics):\n",
    "    print(f\"{ln:>8}:  acc {metrics[ln]['accuracy']:.3f}   \"\n",
    "          f\"f1 {metrics[ln]['f1']:.3f}\")\n",
    "\n",
    "# 7.  (optional) save attribute vectors ------------------------------------\n",
    "save_attribute_vectors(captured[\"attr_vecs\"], ATTRVEC_DIR)\n",
    "print(f\"\\nFinished – vectors in {CAPTURE_FILE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
