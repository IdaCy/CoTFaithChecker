{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n",
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/CoTFaithChecker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading deepseek-ai/DeepSeek-R1-Distill-Llama-8B on cuda\n",
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "#  Chain-of-Thought category probe – notebook driver\n",
    "# ======================================================================\n",
    "# 1.  Global configuration ------------------------------------------------\n",
    "%cd ../..\n",
    "%pwd\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH      = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"      # HF hub or local dir\n",
    "GENERAL_DIR = Path(\"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B\")\n",
    "CATEGORY_FILE   = Path(GENERAL_DIR / \"confidence\" / \"none_unverb_5001.json\")                    # ↳ annotation JSON\n",
    "COT_FILE   = Path(GENERAL_DIR / \"orig\" / \"none_5001.json\")                    # ↳ annotation JSON\n",
    "MAIN_CATEGORIES = [\"backtracking\", \"logical_deduction\"]           # target label(s)\n",
    "LAYERS          = list(range(1, 33, 5))                           # every 5-th layer\n",
    "MAX_SAMPLES     = None                                            # or e.g. 200\n",
    "WHITELIST       = None                                            # path to JSON list of q-ids\n",
    "CAPTURE_FILE   = Path(GENERAL_DIR / \"layprobe\" / \"none_unverb_5001.json\")                    # ↳ annotation JSON\n",
    "CAPTURE_FILE    = Path(\"outputs/hidden_capture.json\")             # raw vectors\n",
    "ATTRVEC_DIR   = Path(GENERAL_DIR / \"attr_vecs\")                    # ↳ annotation JSON\n",
    "\n",
    "# 2.  Imports & helpers ---------------------------------------------------\n",
    "import json, logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from c_cluster_analysis.cat_probe_5.cot_probe_utils import (\n",
    "    load_model_and_tokenizer,\n",
    "    gather_category_sentences,\n",
    "    run_probe_capture_for_categories,\n",
    "    train_linear_probes,\n",
    "    save_attribute_vectors,\n",
    ")\n",
    "\n",
    "# 3.  Model / tokenizer ---------------------------------------------------\n",
    "model, tok, _, _ = load_model_and_tokenizer(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing 2515 sentences across 198 questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "capturing: 100%|██████████| 198/198 [09:49<00:00,  2.98s/q]\n",
      "INFO:root:Saved capture to outputs/hidden_capture.json\n",
      "training probes:  43%|████▎     | 3/7 [01:11<01:59, 30.00s/layer]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "training probes: 100%|██████████| 7/7 [05:14<00:00, 44.91s/layer]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Probe results (weighted F1) ===\n",
      " layer_1:  acc 0.946   f1 0.936\n",
      "layer_11:  acc 0.968   f1 0.966\n",
      "layer_16:  acc 0.974   f1 0.973\n",
      "layer_21:  acc 0.974   f1 0.973\n",
      "layer_26:  acc 0.970   f1 0.969\n",
      "layer_31:  acc 0.968   f1 0.966\n",
      " layer_6:  acc 0.966   f1 0.964\n",
      "\n",
      "Finished – vectors in outputs/hidden_capture.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.  Build the sentence-selection map ------------------------------------\n",
    "selection_map = gather_category_sentences(\n",
    "    CATEGORY_FILE,\n",
    "    main_categories = MAIN_CATEGORIES,\n",
    "    whitelist       = WHITELIST,\n",
    "    max_samples     = MAX_SAMPLES,\n",
    ")\n",
    "\n",
    "print(f\"Capturing {sum(len(v) for v in selection_map.values())} \"\n",
    "      f\"sentences across {len(selection_map)} questions\")\n",
    "\n",
    "# 5.  Hidden-state capture -------------------------------------------------\n",
    "captured = run_probe_capture_for_categories(\n",
    "    model              = model,\n",
    "    tok                = tok,\n",
    "    cot_file           = COT_FILE,\n",
    "    selection_map      = selection_map,\n",
    "    layers             = LAYERS,\n",
    "    output_file        = CAPTURE_FILE,\n",
    ")\n",
    "\n",
    "# 6.  Linear-probe training -----------------------------------------------\n",
    "probes, metrics = train_linear_probes(\n",
    "    captured[\"vectors\"],\n",
    "    captured[\"labels\"],\n",
    "    test_size      = 0.2,\n",
    "    random_state   = 42,\n",
    ")\n",
    "\n",
    "print(\"\\n=== Probe results (weighted F1) ===\")\n",
    "for ln in sorted(metrics):\n",
    "    print(f\"{ln:>8}:  acc {metrics[ln]['accuracy']:.3f}   \"\n",
    "          f\"f1 {metrics[ln]['f1']:.3f}\")\n",
    "\n",
    "# 7.  (optional) save attribute vectors ------------------------------------\n",
    "save_attribute_vectors(captured[\"attr_vecs\"], ATTRVEC_DIR)\n",
    "print(f\"\\nFinished – vectors in {CAPTURE_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'steer_mod'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mc_cluster_analysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcat_probe_5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcot_steer_utils4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msteer_mod\u001b[39;00m\n\u001b[1;32m      8\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(steer_mod)         \u001b[38;5;66;03m# <- forces Python to load the patched code\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msteer_mod\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_attr_vectors, run_steering_experiment\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# ─── user-editable parameters ──────────────────────────────────────────\u001b[39;00m\n\u001b[1;32m     14\u001b[0m CAT_FROM         \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbacktracking\u001b[39m\u001b[38;5;124m\"\u001b[39m          \u001b[38;5;66;03m# steer *with* this\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'steer_mod'"
     ]
    }
   ],
   "source": [
    "# ╔════════════════════════════════════════════════════════════════════╗\n",
    "# ║  Steering experiment                                               ║\n",
    "# ╚════════════════════════════════════════════════════════════════════╝\n",
    "from pathlib import Path\n",
    "\n",
    "from c_cluster_analysis.cat_probe_5.cot_steer_utils4 import (\n",
    "    load_attr_vectors,\n",
    "    run_steering_experiment,\n",
    ")\n",
    "\n",
    "# ─── user-editable parameters ──────────────────────────────────────────\n",
    "CAT_FROM         = \"backtracking\"          # steer *with* this\n",
    "CAT_TO           = \"logical_deduction\"     # steer *into* this\n",
    "ALPHAS           = [0.0, 0.3, 0.6, 1.0, 10.0]    # 0 → no steering\n",
    "ATTR_VEC_DIR     = GENERAL_DIR / \"attr_vecs\"           # from probe stage\n",
    "QUESTIONS_FILE   = \"data/mmlu/input_mcq_data.json\"      # raw questions\n",
    "HINTS_FILE       = None\n",
    "#HINTS_FILE = \"data/mmlu/hints_sycophancy.json\"\n",
    "FULL_COT_FILE    = COT_FILE                            # same as before\n",
    "OUTPUT_STEER_JSON= GENERAL_DIR / \"steering\" / f\"{CAT_FROM}_to_{CAT_TO}.json\"\n",
    "LAYERS_FOR_STEER = [\"layer_11\"]                        # e.g. last layer\n",
    "MAX_QUESTIONS    = 5                                   # shorten dev run\n",
    "# ───────────────────────────────────────────────────────────────────────\n",
    "\n",
    "attr_vecs = load_attr_vectors(ATTR_VEC_DIR)\n",
    "steer_vec = {ln: attr_vecs[CAT_FROM][ln] for ln in LAYERS_FOR_STEER}\n",
    "\n",
    "steer_results = run_steering_experiment(\n",
    "    model              = model,\n",
    "    tok                = tok,\n",
    "    steer_vectors      = steer_vec,\n",
    "    cat_target         = CAT_TO,\n",
    "    alphas             = ALPHAS,\n",
    "    questions_file     = QUESTIONS_FILE,\n",
    "    hints_file         = HINTS_FILE,\n",
    "    full_cot_file      = FULL_COT_FILE,\n",
    "    output_file        = OUTPUT_STEER_JSON,\n",
    "    max_questions      = MAX_QUESTIONS,\n",
    ")\n",
    "\n",
    "print(f\"Saved steered generations to {OUTPUT_STEER_JSON}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available categories: []\n",
      "backtracking.pt  logical_deduction.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "print(\"Available categories:\", list(attr_vecs.keys()))\n",
    "%ls c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/attr_vecs/none_unverb_5001.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
