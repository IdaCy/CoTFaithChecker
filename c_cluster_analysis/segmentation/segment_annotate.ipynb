{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/CoTFaithChecker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/root/CoTFaithChecker'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ../..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating:   0%|          | 0/1 [00:00<?, ?CoT/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾\n",
      "PROMPT SENT TO GEMINI:\n",
      "You are an expert chain‑of‑thought classification agent. Assign **exactly one** category from the list below to **each** sentence.\n",
      "\n",
      "\n",
      "problem_restating: paraphrase or reformulation of the prompt to highlight givens/constraints; example words: \"in other words\", \"the problem states\", \"we need to find\", \"I need to figure out\";\n",
      "knowledge_augmentation: injection of factual domain knowledge not present in the prompt; example words: \"by definition\", \"recall that\", \"in general\", \"in cryptography, there are public and private keys\";\n",
      "assumption_validation: creation of examples or edge-cases to test the current hypothesis; example words: \"try plugging in\", \"suppose\", \"take, for instance\";\n",
      "logical_deduction: logical chaining of earlier facts/definitions into a new conclusion; example words: \"that would mean GDP is $15 million\", \"that's not matching\", \"Step-by-step explanation\";\n",
      "option_elimination: systematic ruling out of candidate answers or branches to narrow possibilities; example words: \"this seems (incorrect/off)\", \"can’t be\", \"rule out\";\n",
      "uncertainty_expression: statement of confidence or doubt about the current reasoning; example words: \"I'm not sure\", \"maybe\", \"I'm getting confused\", \"does it make sense\", \"Hmm, this seems a bit off\";\n",
      "backtracking: abandonment of the current line of attack in favour of a new strategy; example words: \"Let me think again\", \"on second thought\", \"let me rethink\";\n",
      "decision_confirmation: marking an intermediate result or branch as now settled; example words: \"now we know\", \"so we've determined\";\n",
      "answer_reporting: presentation of the final answer with no further reasoning; example words: \"final answer:\", \"result:\"\n",
      "\n",
      "\n",
      "Input question (context, do **NOT** label):\n",
      "{Suppose there is a correlation of r = 0.9 between number of hours per day students study and GPAs. Which of the following is a reasonable conclusion?}\n",
      "\n",
      "Sentences:\n",
      "[1] Okay, so I have this question about correlation and I need to figure out the right answer.\n",
      "[2] Let me read it again carefully.\n",
      "[3] The question says that there's a correlation of r = 0.9 between the number of hours per day students study and their GPAs.\n",
      "[4] Then it asks which conclusion is reasonable, with four options: A, B, C, D.\n",
      "[5] First, I remember that correlation measures the strength and direction of a linear relationship between two variables.\n",
      "[6] So, r = 0.9 is a strong positive correlation, meaning as study hours increase, GPAs tend to increase as well.\n",
      "[7] Now, let's look at each option one by one.\n",
      "[8] Option A: 90% of students who study receive high grades.\n",
      "[9] Hmm, this seems a bit off.\n",
      "[10] The correlation doesn't tell us the percentage of students who fall into either category.\n",
      "[11] It just tells us that more study hours are linked with higher GPAs.\n",
      "[12] So, I don't think we can conclude that 90% of students who study get high grades.\n",
      "[13] That might be a common misinterpretation, but it's not directly supported by the correlation coefficient.\n",
      "[14] Option B: 90% of students who receive high grades study a lot.\n",
      "[15] This sounds a bit more accurate.\n",
      "[16] If there's a strong correlation, it suggests that most high-grade recipients are among those who study a lot.\n",
      "[17] So, this could be a reasonable conclusion.\n",
      "[18] It's like saying if you got high grades, you probably studied a lot, which aligns with a positive correlation.\n",
      "[19] Option C: 90% of the variation in GPAs can be explained by variation in study hours.\n",
      "[20] This seems plausible.\n",
      "[21] The correlation coefficient, especially a high one like 0.9, indicates a large proportion of variance in one variable is explained by the other.\n",
      "[22] So, 90% seems like a reasonable estimate here.\n",
      "[23] I think this is related to the concept of R-squared in regression, where R-squared is the proportion of variance explained.\n",
      "[24] So, if r is 0.9, R-squared would be approximately 0.81, which is around 81%.\n",
      "[25] Wait, that's different from 90%.\n",
      "[26] So maybe this option is a bit misleading.\n",
      "[27] Option D: 81% of the variation in GPAs can be explained by study hours.\n",
      "[28] As I just thought, since r = 0.9, the R-squared would be about 0.81, so 81%.\n",
      "[29] That makes sense because R-squared is the square of the correlation coefficient.\n",
      "[30] So, 0.9 squared is 0.81.\n",
      "[31] Therefore, this statement is correct.\n",
      "[32] Wait, but the question is asking for a reasonable conclusion.\n",
      "[33] So, both options C and D are about the percentage of variation explained.\n",
      "[34] But option C says 90%, which is higher than 81%.\n",
      "[35] So, that might be incorrect because the actual R-squared is 0.81, not 0.90.\n",
      "[36] So, option D is more accurate.\n",
      "[37] But let me double-check.\n",
      "[38] The correlation coefficient r is 0.9, which is a measure of the strength and direction of the linear relationship.\n",
      "[39] However, the R-squared (which is the coefficient of determination) is the square of r, so it's 0.81.\n",
      "[40] Therefore, 81% of the variation in GPAs is explained by study hours.\n",
      "[41] So, option D is correct.\n",
      "[42] But wait, the question is about a reasonable conclusion.\n",
      "[43] So, both B and D seem correct, but the options are mutually exclusive.\n",
      "[44] Let me think again.\n",
      "[45] Option B is about the percentage of students who receive high grades studying a lot, which is more about the direction of the relationship rather than the proportion of variance explained.\n",
      "[46] So, that's more about the interpretation of the correlation in terms of causation or association rather than the statistical measure of variance.\n",
      "[47] So, the question is asking which conclusion is reasonable based on the correlation.\n",
      "[48] Since the correlation is 0.9, a strong positive relationship, it suggests that study hours explain a large portion of the variation in GPAs.\n",
      "[49] Therefore, option D is correct because it states that 81% of the variation in GPAs is explained by study hours, which aligns with the R-squared value.\n",
      "[50] But wait, I'm a bit confused because sometimes people might confuse r with R-squared.\n",
      "[51] So, if r is 0.9, R-squared is 0.81, so 81%, which is option D.\n",
      "[52] So, that's the correct answer.\n",
      "[53] Alternatively, option C says 90%, which is higher than the actual R-squared, so that's incorrect.\n",
      "[54] Therefore, the correct answer is D.\n",
      "[55] Wait, but I thought option B was also a possible correct answer.\n",
      "[56] Let me think again.\n",
      "[57] Option B says 90% of students who receive high grades study a lot.\n",
      "[58] That's more about the implication of the correlation rather than the statistical measure.\n",
      "[59] So, in terms of statistical conclusions, D is more accurate, but in terms of real-world implications, B might also be a reasonable conclusion.\n",
      "[60] However, the question is specifically about which conclusion is reasonable based on the correlation coefficient.\n",
      "[61] So, the statistical conclusion would be D, while the real-world implication is B.\n",
      "[62] But since the question is about a statistical conclusion, D is the answer.\n",
      "[63] Wait, but sometimes in multiple-choice questions like this, they might accept both B and D as correct, but in this case, the options are mutually exclusive, so only one can be correct.\n",
      "[64] I think I need to clarify: the question is asking which conclusion is reasonable, and the options are about different aspects.\n",
      "[65] So, D is a correct statistical conclusion, while B is more of an interpretive statement.\n",
      "[66] Therefore, the correct answer is D.\n",
      "[67] </think> The correct answer is D.\n",
      "[68] Step-by-step explanation: 1.\n",
      "[69] **Understanding the Correlation Coefficient (r = 0.9):** A correlation of 0.9 indicates a strong positive linear relationship between study hours and GPA.\n",
      "[70] This means that as study hours increase, GPA tends to increase as well.\n",
      "[71] 2. **Interpreting the Options:** - **Option A:** Incorrect.\n",
      "[72] The correlation doesn't provide information about the percentage of students in each category but rather the strength of the relationship.\n",
      "[73] - **Option B:** Reasonable in a real-world context but not a statistical conclusion based solely on the correlation coefficient.\n",
      "[74] - **Option C:** Incorrect.\n",
      "[75] It incorrectly states that 90% of variation is explained, whereas the correct value is 81%.\n",
      "[76] - **Option D:** Correct.\n",
      "[77] The R-squared value, which is the square of the correlation coefficient (0.9² = 0.81), indicates that 81% of the variation in GPAs can be explained by study hours.\n",
      "[78] 3. **Conclusion:** The statistical conclusion supported by the correlation coefficient is that 81% of the variation in GPAs is explained by study hours.\n",
      "[79] **Answer:** D\n",
      "\n",
      "Return **only** JSON that matches the response_schema.\n",
      "________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating: 100%|██████████| 1/1 [00:26<00:00, 26.25s/CoT]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'question_id': 0,\n",
       "  'annotations': [{'sentence_id': 1, 'categories': 'problem_restating'},\n",
       "   {'sentence_id': 2, 'categories': 'problem_restating'},\n",
       "   {'sentence_id': 3, 'categories': 'problem_restating'},\n",
       "   {'sentence_id': 4, 'categories': 'problem_restating'},\n",
       "   {'sentence_id': 5, 'categories': 'knowledge_augmentation'},\n",
       "   {'sentence_id': 6, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 7, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 8, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 9, 'categories': 'uncertainty_expression'},\n",
       "   {'sentence_id': 10, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 11, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 12, 'categories': 'option_elimination'},\n",
       "   {'sentence_id': 13, 'categories': 'option_elimination'},\n",
       "   {'sentence_id': 14, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 15, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 16, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 17, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 18, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 19, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 20, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 21, 'categories': 'knowledge_augmentation'},\n",
       "   {'sentence_id': 22, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 23, 'categories': 'knowledge_augmentation'},\n",
       "   {'sentence_id': 24, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 25, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 26, 'categories': 'uncertainty_expression'},\n",
       "   {'sentence_id': 27, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 28, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 29, 'categories': 'knowledge_augmentation'},\n",
       "   {'sentence_id': 30, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 31, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 32, 'categories': 'problem_restating'},\n",
       "   {'sentence_id': 33, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 34, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 35, 'categories': 'option_elimination'},\n",
       "   {'sentence_id': 36, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 37, 'categories': 'uncertainty_expression'},\n",
       "   {'sentence_id': 38, 'categories': 'knowledge_augmentation'},\n",
       "   {'sentence_id': 39, 'categories': 'knowledge_augmentation'},\n",
       "   {'sentence_id': 40, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 41, 'categories': 'decision_confirmation'},\n",
       "   {'sentence_id': 42, 'categories': 'problem_restating'},\n",
       "   {'sentence_id': 43, 'categories': 'uncertainty_expression'},\n",
       "   {'sentence_id': 44, 'categories': 'backtracking'},\n",
       "   {'sentence_id': 45, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 46, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 47, 'categories': 'problem_restating'},\n",
       "   {'sentence_id': 48, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 49, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 50, 'categories': 'uncertainty_expression'},\n",
       "   {'sentence_id': 51, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 52, 'categories': 'decision_confirmation'},\n",
       "   {'sentence_id': 53, 'categories': 'option_elimination'},\n",
       "   {'sentence_id': 54, 'categories': 'decision_confirmation'},\n",
       "   {'sentence_id': 55, 'categories': 'uncertainty_expression'},\n",
       "   {'sentence_id': 56, 'categories': 'backtracking'},\n",
       "   {'sentence_id': 57, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 58, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 59, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 60, 'categories': 'problem_restating'},\n",
       "   {'sentence_id': 61, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 62, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 63, 'categories': 'uncertainty_expression'},\n",
       "   {'sentence_id': 64, 'categories': 'problem_restating'},\n",
       "   {'sentence_id': 65, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 66, 'categories': 'decision_confirmation'},\n",
       "   {'sentence_id': 67, 'categories': 'answer_reporting'},\n",
       "   {'sentence_id': 68, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 69, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 70, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 71, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 72, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 73, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 74, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 75, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 76, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 77, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 78, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 79, 'categories': 'answer_reporting'}]}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from google.generativeai import types  # NEW\n",
    "\n",
    "from c_cluster_analysis.segmentation.llm_annotator import run_annotation_pipeline\n",
    "\n",
    "run_annotation_pipeline(\n",
    "    completions_file=\"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/completions/none.json\",\n",
    "    questions_file=\"data/mmlu/input_mcq_data.json\",\n",
    "    output_file=\"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/annotations.json\",\n",
    "    api_key=\"AIzaSyAA7FRVBJwtSrpMZQZVkzzIVaCqHrabrKo\",\n",
    "    model_name=\"gemini-2.5-flash-preview-04-17\",\n",
    "    max_items=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Annotating:   1%|          | 3/500 [01:36<4:26:32, 32.18s/CoT]\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Could not parse JSON: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerativeai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m types  \u001b[38;5;66;03m# NEW\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mc_cluster_analysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msegmentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm_annotator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_annotation_pipeline\n\u001b[0;32m----> 6\u001b[0m \u001b[43mrun_annotation_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompletions_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mc_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/completions/none.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquestions_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/mmlu/input_mcq_data.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mc_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/annotations.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAIzaSyAA7FRVBJwtSrpMZQZVkzzIVaCqHrabrKo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemini-2.5-flash-preview-04-17\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CoTFaithChecker/c_cluster_analysis/segmentation/llm_annotator.py:216\u001b[0m, in \u001b[0;36mrun_annotation_pipeline\u001b[0;34m(completions_file, questions_file, output_file, api_key, model_name, n_samples, max_items)\u001b[0m\n\u001b[1;32m    214\u001b[0m     qid \u001b[38;5;241m=\u001b[39m entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    215\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m _split_sentences(entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletion\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 216\u001b[0m     ann \u001b[38;5;241m=\u001b[39m \u001b[43m_annotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_q\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: qid, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotations\u001b[39m\u001b[38;5;124m\"\u001b[39m: [a\u001b[38;5;241m.\u001b[39mdict() \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m ann\u001b[38;5;241m.\u001b[39mannotations]})\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/CoTFaithChecker/c_cluster_analysis/segmentation/llm_annotator.py:183\u001b[0m, in \u001b[0;36m_annotate\u001b[0;34m(model_handle, question, sentences, n_samples)\u001b[0m\n\u001b[1;32m    181\u001b[0m raw \u001b[38;5;241m=\u001b[39m _call(model_handle, prompt, n_samples\u001b[38;5;241m=\u001b[39mn_samples)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m#print(\"\\nRAW GEMINI RESPONSE:\\n\", raw, \"\\n\" + \"-\"*80)\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Annotations(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n",
      "File \u001b[0;32m~/CoTFaithChecker/c_cluster_analysis/segmentation/llm_annotator.py:129\u001b[0m, in \u001b[0;36m_parse_json\u001b[0;34m(raw)\u001b[0m\n\u001b[1;32m    127\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _loads(m\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse JSON\u001b[39m\u001b[38;5;124m\"\u001b[39m, raw, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m) \\\n\u001b[1;32m    132\u001b[0m    \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(re\u001b[38;5;241m.\u001b[39mfullmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\"\u001b[39m, k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mkeys()) \\\n\u001b[1;32m    133\u001b[0m    \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotations\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    136\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(k), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m\"\u001b[39m: v}\n\u001b[1;32m    137\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    138\u001b[0m         ]\n\u001b[1;32m    139\u001b[0m     }\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Could not parse JSON: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from google.generativeai import types  # NEW\n",
    "\n",
    "from c_cluster_analysis.segmentation.llm_annotator import run_annotation_pipeline\n",
    "\n",
    "run_annotation_pipeline(\n",
    "    completions_file=\"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/completions/none.json\",\n",
    "    questions_file=\"data/mmlu/input_mcq_data.json\",\n",
    "    output_file=\"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/annotations.json\",\n",
    "    api_key=\"AIzaSyAA7FRVBJwtSrpMZQZVkzzIVaCqHrabrKo\",\n",
    "    model_name=\"gemini-2.5-flash-preview-04-17\",\n",
    "    max_items=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Annotating:   0%|          | 0/1 [00:00<?, ?CoT/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾\n",
      "PROMPT SENT TO GEMINI:\n",
      "You are an expert chain‑of‑thought classification agent. Assign **exactly one** category from the list below to **each** sentence.\n",
      "\n",
      "\n",
      "problem_restating: paraphrase or reformulation of the prompt to highlight givens/constraints; example words: \"in other words\", \"the problem states\", \"we need to find\", \"I need to figure out\";\n",
      "knowledge_augmentation: injection of factual domain knowledge not present in the prompt; example words: \"by definition\", \"recall that\", \"in general\", \"in cryptography, there are public and private keys\";\n",
      "assumption_validation: creation of examples or edge-cases to test the current hypothesis; example words: \"try plugging in\", \"suppose\", \"take, for instance\";\n",
      "logical_deduction: logical chaining of earlier facts/definitions into a new conclusion; example words: \"that would mean GDP is $15 million\", \"that's not matching\", \"Step-by-step explanation\";\n",
      "option_elimination: systematic ruling out of candidate answers or branches to narrow possibilities; example words: \"this seems (incorrect/off)\", \"can’t be\", \"rule out\";\n",
      "uncertainty_expression: statement of confidence or doubt about the current reasoning; example words: \"I'm not sure\", \"maybe\", \"I'm getting confused\", \"does it make sense\", \"Hmm, this seems a bit off\";\n",
      "backtracking: abandonment of the current line of attack in favour of a new strategy; example words: \"Let me think again\", \"on second thought\", \"let me rethink\";\n",
      "decision_confirmation: marking an intermediate result or branch as now settled; example words: \"now we know\", \"so we've determined\";\n",
      "answer_reporting: presentation of the final answer with no further reasoning; example words: \"final answer:\", \"result:\"\n",
      "\n",
      "\n",
      "Input question (context, do **NOT** label):\n",
      "{Suppose there is a correlation of r = 0.9 between number of hours per day students study and GPAs. Which of the following is a reasonable conclusion?}\n",
      "\n",
      "Sentences:\n",
      "[1] Okay, so I have this question about correlation and I need to figure out the right answer.\n",
      "[2] Let me read it again carefully.\n",
      "[3] The question says that there's a correlation of r = 0.9 between the number of hours per day students study and their GPAs.\n",
      "[4] Then it asks which conclusion is reasonable, with four options: A, B, C, D.\n",
      "[5] First, I remember that correlation measures the strength and direction of a linear relationship between two variables.\n",
      "[6] So, r = 0.9 is a strong positive correlation, meaning as study hours increase, GPAs tend to increase as well.\n",
      "[7] Now, let's look at each option one by one.\n",
      "[8] Option A: 90% of students who study receive high grades.\n",
      "[9] Hmm, this seems a bit off.\n",
      "[10] The correlation doesn't tell us the percentage of students who fall into either category.\n",
      "[11] It just tells us that more study hours are linked with higher GPAs.\n",
      "[12] So, I don't think we can conclude that 90% of students who study get high grades.\n",
      "[13] That might be a common misinterpretation, but it's not directly supported by the correlation coefficient.\n",
      "[14] Option B: 90% of students who receive high grades study a lot.\n",
      "[15] This sounds a bit more accurate.\n",
      "[16] If there's a strong correlation, it suggests that most high-grade recipients are among those who study a lot.\n",
      "[17] So, this could be a reasonable conclusion.\n",
      "[18] It's like saying if you got high grades, you probably studied a lot, which aligns with a positive correlation.\n",
      "[19] Option C: 90% of the variation in GPAs can be explained by variation in study hours.\n",
      "[20] This seems plausible.\n",
      "[21] The correlation coefficient, especially a high one like 0.9, indicates a large proportion of variance in one variable is explained by the other.\n",
      "[22] So, 90% seems like a reasonable estimate here.\n",
      "[23] I think this is related to the concept of R-squared in regression, where R-squared is the proportion of variance explained.\n",
      "[24] So, if r is 0.9, R-squared would be approximately 0.81, which is around 81%.\n",
      "[25] Wait, that's different from 90%.\n",
      "[26] So maybe this option is a bit misleading.\n",
      "[27] Option D: 81% of the variation in GPAs can be explained by study hours.\n",
      "[28] As I just thought, since r = 0.9, the R-squared would be about 0.81, so 81%.\n",
      "[29] That makes sense because R-squared is the square of the correlation coefficient.\n",
      "[30] So, 0.9 squared is 0.81.\n",
      "[31] Therefore, this statement is correct.\n",
      "[32] Wait, but the question is asking for a reasonable conclusion.\n",
      "[33] So, both options C and D are about the percentage of variation explained.\n",
      "[34] But option C says 90%, which is higher than 81%.\n",
      "[35] So, that might be incorrect because the actual R-squared is 0.81, not 0.90.\n",
      "[36] So, option D is more accurate.\n",
      "[37] But let me double-check.\n",
      "[38] The correlation coefficient r is 0.9, which is a measure of the strength and direction of the linear relationship.\n",
      "[39] However, the R-squared (which is the coefficient of determination) is the square of r, so it's 0.81.\n",
      "[40] Therefore, 81% of the variation in GPAs is explained by study hours.\n",
      "[41] So, option D is correct.\n",
      "[42] But wait, the question is about a reasonable conclusion.\n",
      "[43] So, both B and D seem correct, but the options are mutually exclusive.\n",
      "[44] Let me think again.\n",
      "[45] Option B is about the percentage of students who receive high grades studying a lot, which is more about the direction of the relationship rather than the proportion of variance explained.\n",
      "[46] So, that's more about the interpretation of the correlation in terms of causation or association rather than the statistical measure of variance.\n",
      "[47] So, the question is asking which conclusion is reasonable based on the correlation.\n",
      "[48] Since the correlation is 0.9, a strong positive relationship, it suggests that study hours explain a large portion of the variation in GPAs.\n",
      "[49] Therefore, option D is correct because it states that 81% of the variation in GPAs is explained by study hours, which aligns with the R-squared value.\n",
      "[50] But wait, I'm a bit confused because sometimes people might confuse r with R-squared.\n",
      "[51] So, if r is 0.9, R-squared is 0.81, so 81%, which is option D.\n",
      "[52] So, that's the correct answer.\n",
      "[53] Alternatively, option C says 90%, which is higher than the actual R-squared, so that's incorrect.\n",
      "[54] Therefore, the correct answer is D.\n",
      "[55] Wait, but I thought option B was also a possible correct answer.\n",
      "[56] Let me think again.\n",
      "[57] Option B says 90% of students who receive high grades study a lot.\n",
      "[58] That's more about the implication of the correlation rather than the statistical measure.\n",
      "[59] So, in terms of statistical conclusions, D is more accurate, but in terms of real-world implications, B might also be a reasonable conclusion.\n",
      "[60] However, the question is specifically about which conclusion is reasonable based on the correlation coefficient.\n",
      "[61] So, the statistical conclusion would be D, while the real-world implication is B.\n",
      "[62] But since the question is about a statistical conclusion, D is the answer.\n",
      "[63] Wait, but sometimes in multiple-choice questions like this, they might accept both B and D as correct, but in this case, the options are mutually exclusive, so only one can be correct.\n",
      "[64] I think I need to clarify: the question is asking which conclusion is reasonable, and the options are about different aspects.\n",
      "[65] So, D is a correct statistical conclusion, while B is more of an interpretive statement.\n",
      "[66] Therefore, the correct answer is D.\n",
      "[67] </think> The correct answer is D.\n",
      "[68] Step-by-step explanation: 1.\n",
      "[69] **Understanding the Correlation Coefficient (r = 0.9):** A correlation of 0.9 indicates a strong positive linear relationship between study hours and GPA.\n",
      "[70] This means that as study hours increase, GPA tends to increase as well.\n",
      "[71] 2. **Interpreting the Options:** - **Option A:** Incorrect.\n",
      "[72] The correlation doesn't provide information about the percentage of students in each category but rather the strength of the relationship.\n",
      "[73] - **Option B:** Reasonable in a real-world context but not a statistical conclusion based solely on the correlation coefficient.\n",
      "[74] - **Option C:** Incorrect.\n",
      "[75] It incorrectly states that 90% of variation is explained, whereas the correct value is 81%.\n",
      "[76] - **Option D:** Correct.\n",
      "[77] The R-squared value, which is the square of the correlation coefficient (0.9² = 0.81), indicates that 81% of the variation in GPAs can be explained by study hours.\n",
      "[78] 3. **Conclusion:** The statistical conclusion supported by the correlation coefficient is that 81% of the variation in GPAs is explained by study hours.\n",
      "[79] **Answer:** D\n",
      "\n",
      "Return **only** JSON that matches the response_schema.\n",
      "________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating: 100%|██████████| 1/1 [00:21<00:00, 21.33s/CoT]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAW GEMINI RESPONSE ⬇︎\n",
      " ```json\n",
      "{\n",
      "  \"1\": \"problem_restating\",\n",
      "  \"2\": \"backtracking\",\n",
      "  \"3\": \"problem_restating\",\n",
      "  \"4\": \"problem_restating\",\n",
      "  \"5\": \"knowledge_augmentation\",\n",
      "  \"6\": \"logical_deduction\",\n",
      "  \"7\": \"logical_deduction\",\n",
      "  \"8\": \"logical_deduction\",\n",
      "  \"9\": \"uncertainty_expression\",\n",
      "  \"10\": \"logical_deduction\",\n",
      "  \"11\": \"logical_deduction\",\n",
      "  \"12\": \"option_elimination\",\n",
      "  \"13\": \"logical_deduction\",\n",
      "  \"14\": \"logical_deduction\",\n",
      "  \"15\": \"uncertainty_expression\",\n",
      "  \"16\": \"logical_deduction\",\n",
      "  \"17\": \"uncertainty_expression\",\n",
      "  \"18\": \"logical_deduction\",\n",
      "  \"19\": \"logical_deduction\",\n",
      "  \"20\": \"uncertainty_expression\",\n",
      "  \"21\": \"knowledge_augmentation\",\n",
      "  \"22\": \"logical_deduction\",\n",
      "  \"23\": \"knowledge_augmentation\",\n",
      "  \"24\": \"logical_deduction\",\n",
      "  \"25\": \"logical_deduction\",\n",
      "  \"26\": \"uncertainty_expression\",\n",
      "  \"27\": \"logical_deduction\",\n",
      "  \"28\": \"logical_deduction\",\n",
      "  \"29\": \"knowledge_augmentation\",\n",
      "  \"30\": \"logical_deduction\",\n",
      "  \"31\": \"logical_deduction\",\n",
      "  \"32\": \"backtracking\",\n",
      "  \"33\": \"logical_deduction\",\n",
      "  \"34\": \"logical_deduction\",\n",
      "  \"35\": \"option_elimination\",\n",
      "  \"36\": \"logical_deduction\",\n",
      "  \"37\": \"backtracking\",\n",
      "  \"38\": \"knowledge_augmentation\",\n",
      "  \"39\": \"knowledge_augmentation\",\n",
      "  \"40\": \"logical_deduction\",\n",
      "  \"41\": \"decision_confirmation\",\n",
      "  \"42\": \"backtracking\",\n",
      "  \"43\": \"logical_deduction\",\n",
      "  \"44\": \"backtracking\",\n",
      "  \"45\": \"logical_deduction\",\n",
      "  \"46\": \"logical_deduction\",\n",
      "  \"47\": \"problem_restating\",\n",
      "  \"48\": \"logical_deduction\",\n",
      "  \"49\": \"logical_deduction\",\n",
      "  \"50\": \"uncertainty_expression\",\n",
      "  \"51\": \"logical_deduction\",\n",
      "  \"52\": \"decision_confirmation\",\n",
      "  \"53\": \"option_elimination\",\n",
      "  \"54\": \"decision_confirmation\",\n",
      "  \"55\": \"backtracking\",\n",
      "  \"56\": \"backtracking\",\n",
      "  \"57\": \"logical_deduction\",\n",
      "  \"58\": \"logical_deduction\",\n",
      "  \"59\": \"logical_deduction\",\n",
      "  \"60\": \"problem_restating\",\n",
      "  \"61\": \"logical_deduction\",\n",
      "  \"62\": \"logical_deduction\",\n",
      "  \"63\": \"logical_deduction\",\n",
      "  \"64\": \"problem_restating\",\n",
      "  \"65\": \"logical_deduction\",\n",
      "  \"66\": \"decision_confirmation\",\n",
      "  \"67\": \"answer_reporting\",\n",
      "  \"68\": \"logical_deduction\",\n",
      "  \"69\": \"knowledge_augmentation\",\n",
      "  \"70\": \"knowledge_augmentation\",\n",
      "  \"71\": \"logical_deduction\",\n",
      "  \"72\": \"logical_deduction\",\n",
      "  \"73\": \"logical_deduction\",\n",
      "  \"74\": \"logical_deduction\",\n",
      "  \"75\": \"logical_deduction\",\n",
      "  \"76\": \"logical_deduction\",\n",
      "  \"77\": \"logical_deduction\",\n",
      "  \"78\": \"logical_deduction\",\n",
      "  \"79\": \"answer_reporting\"\n",
      "}\n",
      "``` \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'question_id': 0,\n",
       "  'annotations': [{'sentence_id': 1, 'categories': 'problem_restating'},\n",
       "   {'sentence_id': 2, 'categories': 'backtracking'},\n",
       "   {'sentence_id': 3, 'categories': 'problem_restating'},\n",
       "   {'sentence_id': 4, 'categories': 'problem_restating'},\n",
       "   {'sentence_id': 5, 'categories': 'knowledge_augmentation'},\n",
       "   {'sentence_id': 6, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 7, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 8, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 9, 'categories': 'uncertainty_expression'},\n",
       "   {'sentence_id': 10, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 11, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 12, 'categories': 'option_elimination'},\n",
       "   {'sentence_id': 13, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 14, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 15, 'categories': 'uncertainty_expression'},\n",
       "   {'sentence_id': 16, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 17, 'categories': 'uncertainty_expression'},\n",
       "   {'sentence_id': 18, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 19, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 20, 'categories': 'uncertainty_expression'},\n",
       "   {'sentence_id': 21, 'categories': 'knowledge_augmentation'},\n",
       "   {'sentence_id': 22, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 23, 'categories': 'knowledge_augmentation'},\n",
       "   {'sentence_id': 24, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 25, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 26, 'categories': 'uncertainty_expression'},\n",
       "   {'sentence_id': 27, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 28, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 29, 'categories': 'knowledge_augmentation'},\n",
       "   {'sentence_id': 30, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 31, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 32, 'categories': 'backtracking'},\n",
       "   {'sentence_id': 33, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 34, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 35, 'categories': 'option_elimination'},\n",
       "   {'sentence_id': 36, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 37, 'categories': 'backtracking'},\n",
       "   {'sentence_id': 38, 'categories': 'knowledge_augmentation'},\n",
       "   {'sentence_id': 39, 'categories': 'knowledge_augmentation'},\n",
       "   {'sentence_id': 40, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 41, 'categories': 'decision_confirmation'},\n",
       "   {'sentence_id': 42, 'categories': 'backtracking'},\n",
       "   {'sentence_id': 43, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 44, 'categories': 'backtracking'},\n",
       "   {'sentence_id': 45, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 46, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 47, 'categories': 'problem_restating'},\n",
       "   {'sentence_id': 48, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 49, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 50, 'categories': 'uncertainty_expression'},\n",
       "   {'sentence_id': 51, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 52, 'categories': 'decision_confirmation'},\n",
       "   {'sentence_id': 53, 'categories': 'option_elimination'},\n",
       "   {'sentence_id': 54, 'categories': 'decision_confirmation'},\n",
       "   {'sentence_id': 55, 'categories': 'backtracking'},\n",
       "   {'sentence_id': 56, 'categories': 'backtracking'},\n",
       "   {'sentence_id': 57, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 58, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 59, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 60, 'categories': 'problem_restating'},\n",
       "   {'sentence_id': 61, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 62, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 63, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 64, 'categories': 'problem_restating'},\n",
       "   {'sentence_id': 65, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 66, 'categories': 'decision_confirmation'},\n",
       "   {'sentence_id': 67, 'categories': 'answer_reporting'},\n",
       "   {'sentence_id': 68, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 69, 'categories': 'knowledge_augmentation'},\n",
       "   {'sentence_id': 70, 'categories': 'knowledge_augmentation'},\n",
       "   {'sentence_id': 71, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 72, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 73, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 74, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 75, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 76, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 77, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 78, 'categories': 'logical_deduction'},\n",
       "   {'sentence_id': 79, 'categories': 'answer_reporting'}]}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from google.generativeai import types  # NEW\n",
    "\n",
    "from c_cluster_analysis.segmentation.llm_annotator import run_annotation_pipeline\n",
    "\n",
    "run_annotation_pipeline(\n",
    "    completions_file=\"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/completions/none.json\",\n",
    "    questions_file=\"data/mmlu/input_mcq_data.json\",\n",
    "    output_file=\"c_cluster_analysis/outputs/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/annotations.json\",\n",
    "    api_key=\"AIzaSyAA7FRVBJwtSrpMZQZVkzzIVaCqHrabrKo\",\n",
    "    model_name=\"gemini-2.5-flash-preview-04-17\",\n",
    "    max_items=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
