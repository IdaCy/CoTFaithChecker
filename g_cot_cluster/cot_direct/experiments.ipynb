{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db6428b",
   "metadata": {},
   "source": [
    "# Chain‑of‑Thought Faithfulness Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d9861e",
   "metadata": {},
   "source": [
    "Install dependencies if needed (`pip install transformers scikit-learn umap-learn cpca matplotlib`) and import helper modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97cdf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, json, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# add project path\n",
    "sys.path.append(\"/mnt/data/cot_faithfulness\")\n",
    "\n",
    "from data_loader import load_segmented_completions, iter_segments\n",
    "from representations import RepresentationExtractor\n",
    "from clustering import cluster_kmeans, embed_to_umap, plot_clusters_2d\n",
    "from contrastive import run_cpca, plot_cpca_projection\n",
    "from probes import layerwise_probe\n",
    "from causal_edit import ActivationPatcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = Path(\"g_cot_cluster/outputs/mmlu/DeepSeek-R1-Distill-Llama-8B\")\n",
    "HINT_TYPES = [\"none\", \"sycophancy\", \"induced_urgency\", \"unethical_information\"]\n",
    "MODEL_NAME = \"gpt2\"\n",
    "\n",
    "extractor = RepresentationExtractor(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a889e047",
   "metadata": {},
   "source": [
    "## 2‑a. Clustering representations by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9412bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "results = []\n",
    "for hint in HINT_TYPES:\n",
    "    file_path = DATA_DIR / f\"segmented_completions_{hint}.json\"\n",
    "    data = load_segmented_completions(file_path)\n",
    "    segs = list(iter_segments(data))\n",
    "    texts = [s[\"text\"] for s in segs]\n",
    "    cats  = [s[\"phrase_category\"] for s in segs]\n",
    "    emb   = extractor.bulk_embed(texts, layer=-1)\n",
    "    labels, sil = cluster_kmeans(emb, n_clusters=len(set(cats)))\n",
    "    um2 = embed_to_umap(emb)\n",
    "    fig = plot_clusters_2d(um2, [list(sorted(set(cats))).index(c) for c in cats],\n",
    "                           f\"UMAP projection by category – {hint}\")\n",
    "    plt.show()\n",
    "    results.append({\"hint\": hint, \"silhouette\": sil})\n",
    "pd.DataFrame(results).set_index(\"hint\").plot(kind=\"bar\", legend=False, title=\"Silhouette scores\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5fb9c6",
   "metadata": {},
   "source": [
    "## 2‑b. Contrastive PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af17f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bg_emb = extractor.bulk_embed(\n",
    "    [s[\"text\"] for s in iter_segments(load_segmented_completions(DATA_DIR / \"segmented_completions_none.json\"))]\n",
    ")\n",
    "for hint in HINT_TYPES[1:]:\n",
    "    tgt_emb = extractor.bulk_embed(\n",
    "        [s[\"text\"] for s in iter_segments(load_segmented_completions(DATA_DIR / f\"segmented_completions_{hint}.json\"))]\n",
    "    )\n",
    "    model = run_cpca(background=bg_emb, target=tgt_emb)\n",
    "    fig = plot_cpca_projection(model, bg_emb, tgt_emb, f\"cPCA – {hint} vs none\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b9818c",
   "metadata": {},
   "source": [
    "## 2‑c. Probing predictability of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1469239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_none = load_segmented_completions(DATA_DIR / \"segmented_completions_none.json\")\n",
    "segs = list(iter_segments(data_none))\n",
    "texts = [s[\"text\"] for s in segs]\n",
    "cats = [s[\"phrase_category\"] for s in segs]\n",
    "label_map = {c:i for i,c in enumerate(sorted(set(cats)))}\n",
    "y = np.array([label_map[c] for c in cats])\n",
    "\n",
    "# Example: only last layer; extend to all layers as needed\n",
    "reps_last = extractor.bulk_embed(texts, layer=-1)\n",
    "layer_reps = reps_last[:, None, :]  # shape (n, 1, d)\n",
    "accs = layerwise_probe(layer_reps, y)\n",
    "print(\"Probe accuracy, last layer:\", accs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc0488a",
   "metadata": {},
   "source": [
    "## 2‑d. Activation patching demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b3c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "patcher = ActivationPatcher(MODEL_NAME)\n",
    "sample_src = segs[0][\"text\"]\n",
    "sample_donor = segs[1][\"text\"]\n",
    "logits = patcher.patch(sample_src, sample_donor, num_tokens=20, layer_idx=-1)\n",
    "print(\"Patched logits shape:\", logits.shape)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
