nohup: ignoring input
Working dir: /root/CoTFaithChecker
CoTFaithChecker/e_confirm_xy_yx_5_nohup.py starting!
[2025-04-27T21:03:19.247322] starting setup
[2025-04-27T21:03:19.321824] loading model & tokenizer
2025-04-27 21:03:20,943 - INFO - CUDA is available. Using GPU.
2025-04-27 21:03:20,943 - INFO - Loading model and tokenizer: deepseek-ai/DeepSeek-R1-Distill-Llama-8B onto cuda
/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:817: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.26it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.26it/s]
2025-04-27 21:03:24,772 - INFO - Model and tokenizer loaded successfully.
data_loader — INFO — Logger initialised; log file = /root/CoTFaithChecker/logs/data_loader_20250427_210324.log
2025-04-27 21:03:24,775 - INFO - Logger initialised; log file = /root/CoTFaithChecker/logs/data_loader_20250427_210324.log
[2025-04-27T21:03:24.776060] loading data
data_loader — INFO — → kept 1 after cluster filter ['one']
2025-04-27 21:03:24,776 - INFO - → kept 1 after cluster filter ['one']
data_loader — INFO — Found 1 files in data/chainscope/questions_json/gt_NO_1
2025-04-27 21:03:24,776 - INFO - Found 1 files in data/chainscope/questions_json/gt_NO_1
data_loader — INFO — Total files collected: 1
2025-04-27 21:03:24,776 - INFO - Total files collected: 1
prompt_builder — INFO — Logger initialised; log file = /root/CoTFaithChecker/logs/prompt_builder_20250427_210324.log
2025-04-27 21:03:24,777 - INFO - Logger initialised; log file = /root/CoTFaithChecker/logs/prompt_builder_20250427_210324.log
prompt_builder — INFO — PromptBuilder initialised with style=instr-v0, mode=cot
2025-04-27 21:03:24,777 - INFO - PromptBuilder initialised with style=instr-v0, mode=cot
[2025-04-27T21:03:24.777257] running inference
inference — INFO — Logger initialised; log file = /root/CoTFaithChecker/logs/inference_20250427_210324.log
2025-04-27 21:03:24,777 - INFO - Logger initialised; log file = /root/CoTFaithChecker/logs/inference_20250427_210324.log
inference — INFO — Processing wm-only-an-example.json
2025-04-27 21:03:24,777 - INFO - Processing wm-only-an-example.json
2025-04-27 21:03:24,777 - DEBUG - Loading data/chainscope/questions_json/gt_NO_1/wm-only-an-example.json
2025-04-27 21:03:24,778 - DEBUG -   ↳ run 1/1
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
inference — INFO — Saved tensor list → h_hidden_states/outputs/xyyx/gt_lt_completions_1/wm-only-an-example_run0_hidden.pt
2025-04-27 21:03:35,832 - INFO - Saved tensor list → h_hidden_states/outputs/xyyx/gt_lt_completions_1/wm-only-an-example_run0_hidden.pt
inference — INFO — Saved 1 completions → h_hidden_states/outputs/xyyx/gt_lt_completions_1/wm-only-an-example_DeepSeek-R1-Distill-Llama-8B_completions.json
2025-04-27 21:03:35,832 - INFO - Saved 1 completions → h_hidden_states/outputs/xyyx/gt_lt_completions_1/wm-only-an-example_DeepSeek-R1-Distill-Llama-8B_completions.json
inference — INFO — Aggregated 1 records → h_hidden_states/outputs/xyyx/gt_lt_completions_1/clusters/one_unknown_unknown_DeepSeek-R1-Distill-Llama-8B_completions.json
2025-04-27 21:03:35,833 - INFO - Aggregated 1 records → h_hidden_states/outputs/xyyx/gt_lt_completions_1/clusters/one_unknown_unknown_DeepSeek-R1-Distill-Llama-8B_completions.json
[2025-04-27T21:03:35.833123] done!
