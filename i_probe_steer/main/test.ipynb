{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/CoTFaithChecker\n"
     ]
    },
    {
>>>>>>> c97d793099548bd91ae26e8822ce75baadab6f3a
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/CoTFaithChecker\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'glob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlist_pt\u001b[39m(directory):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mstr\u001b[39m(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m directory\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 23\u001b[0m files_none  \u001b[38;5;241m=\u001b[39m \u001b[43mlist_pt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDIR_NONE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m files_sync  \u001b[38;5;241m=\u001b[39m list_pt(DIR_unverb)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m files_none \u001b[38;5;129;01mand\u001b[39;00m files_sync, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo .pt files found ! check paths!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m, in \u001b[0;36mlist_pt\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlist_pt\u001b[39m(directory):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mstr\u001b[39m(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'glob'"
     ]
=======
     "data": {
      "text/plain": [
       "'/root/CoTFaithChecker'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> c97d793099548bd91ae26e8822ce75baadab6f3a
    }
   ],
   "source": [
    "%cd ../..\n",
<<<<<<< HEAD
    "%pwd\n",
    "import os, pickle, datetime, re\n",
    "from pathlib import Path\n",
    "\n",
    "import torch, numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\"\"\"ROOT = Path(\"i_probe_steer/outputs/f1_hint_xyyx/hints/mmlu/DeepSeek-R1-Distill-Llama-8B\")\n",
    "ROOT = Path(\"i_probe_steer/outputs/f1_hint_xyyx/hints/mmlu/DeepSeek-R1-Distill-Llama-8B\")\n",
    "DIR_NONE        = ROOT / \"none/500_captures\"\n",
    "DIR_unverb  = ROOT / \"sycophancy/500_captures\"\"\"\n",
    "\n",
    "DIR_NONE   = Path(\"i_probe_steer/outputs/f1_hint_xyyx/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/none/500_captures\")\n",
    "DIR_unverb = Path(\"i_probe_steer/outputs/f1_hint_xyyx/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/sycophancy/500_captures\")\n",
    "\n",
    "def list_pt(directory):\n",
    "    return sorted(str(p) for p in directory.glob(\"*.pt\"))\n",
    "\n",
    "files_none  = list_pt(DIR_NONE)\n",
    "files_sync  = list_pt(DIR_unverb)\n",
    "assert files_none and files_sync, \"No .pt files found ! check paths!\""
=======
    "%pwd"
>>>>>>> c97d793099548bd91ae26e8822ce75baadab6f3a
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "first_token_acts_batch_0.pt    first_token_acts_batch_320.pt\n",
      "first_token_acts_batch_128.pt  first_token_acts_batch_352.pt\n",
      "first_token_acts_batch_160.pt  first_token_acts_batch_384.pt\n",
      "first_token_acts_batch_192.pt  first_token_acts_batch_416.pt\n",
      "first_token_acts_batch_224.pt  first_token_acts_batch_448.pt\n",
      "first_token_acts_batch_256.pt  first_token_acts_batch_480.pt\n",
      "first_token_acts_batch_288.pt  first_token_acts_batch_64.pt\n",
      "first_token_acts_batch_32.pt   first_token_acts_batch_96.pt\n"
=======
      "h_hidden_space/outputs/f1_hint_xyyx/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/induced_urgency:\n",
      "\u001b[0m\u001b[01;34m500_captures\u001b[0m/\n",
      "\n",
      "h_hidden_space/outputs/f1_hint_xyyx/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/none:\n",
      "\u001b[01;34m500_captures\u001b[0m/\n",
      "\n",
      "h_hidden_space/outputs/f1_hint_xyyx/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/sycophancy:\n",
      "\u001b[01;34m500_captures\u001b[0m/\n",
      "\n",
      "h_hidden_space/outputs/f1_hint_xyyx/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/unethical_information:\n",
      "\u001b[01;34m500_captures\u001b[0m/\n"
>>>>>>> c97d793099548bd91ae26e8822ce75baadab6f3a
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "%ls i_probe_steer/outputs/f1_hint_xyyx/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/sycophancy/500_captures"
=======
    "%ls h_hidden_space/outputs/f1_hint_xyyx/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/*"
>>>>>>> c97d793099548bd91ae26e8822ce75baadab6f3a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, datetime, re\n",
    "from pathlib import Path\n",
    "\n",
    "import torch, numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ROOT = Path(\"i_probe_steer/extractions/hints/mmlu/DeepSeek-R1-Distill-Llama-8B\")\n",
    "DIR_NONE        = ROOT / \"none/500_captures\"\n",
    "DIR_SYCOPHANCY  = ROOT / \"sycophancy/500_captures\"\n",
    "\n",
    "def list_pt(directory):\n",
    "    return sorted(str(p) for p in directory.glob(\"*.pt\"))\n",
    "\n",
    "files_none  = list_pt(DIR_NONE)\n",
    "files_sync  = list_pt(DIR_SYCOPHANCY)\n",
    "assert files_none and files_sync, \"No .pt files found – check your paths!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> c97d793099548bd91ae26e8822ce75baadab6f3a
    "pointer_re = re.compile(br\"^version https://git-lfs.github.com/spec/\")\n",
    "def safe_torch_load(fname):\n",
    "    with open(fname, \"rb\") as f:\n",
    "        if pointer_re.match(f.read(80)):\n",
    "            print(f\"{Path(fname).name}: Git-LFS pointer, skipping\")\n",
    "            return None\n",
<<<<<<< HEAD
    "    return torch.load(fname, map_location=\"cpu\")\n",
    "\n",
=======
    "    return torch.load(fname, map_location=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 33 layers, hidden size = 4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81709/1195087584.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(fname, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
>>>>>>> c97d793099548bd91ae26e8822ce75baadab6f3a
    "def dict_to_list(d):\n",
    "    return [d[f\"layer_{i}\"] for i in range(len(d))]\n",
    "def normalise_batch(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return dict_to_list(obj)\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        return list(obj)\n",
    "    raise TypeError(f\"Unexpected batch type: {type(obj)}\")\n",
    "\n",
    "sample = None\n",
    "for fp in files_none + files_sync:\n",
    "    raw = safe_torch_load(fp)\n",
    "    if raw is not None:\n",
    "        sample = normalise_batch(raw)\n",
    "        break\n",
    "\n",
    "assert sample is not None, \"No real .pt blobs present – run `git lfs pull`\"\n",
    "N_LAYERS     = len(sample)\n",
    "HIDDEN_SIZE  = sample[0].shape[-1]\n",
    "print(f\"Detected {N_LAYERS} layers, hidden size = {HIDDEN_SIZE}\")\n",
<<<<<<< HEAD
    "\n",
    "\n",
=======
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "label=0:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_81709/1195087584.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(fname, map_location=\"cpu\")\n",
      "label=0: 100%|██████████| 16/16 [00:00<00:00, 86.38it/s]\n",
      "label=1: 100%|██████████| 16/16 [00:00<00:00, 98.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1000\n"
     ]
    }
   ],
   "source": [
>>>>>>> c97d793099548bd91ae26e8822ce75baadab6f3a
    "layer_blobs = {L: [] for L in range(N_LAYERS)}\n",
    "labels      = []\n",
    "\n",
    "def add_files(file_list, lab):\n",
    "    for fp in tqdm(file_list, desc=f\"label={lab}\"):\n",
    "        raw = safe_torch_load(fp)\n",
    "        if raw is None:\n",
    "            continue\n",
    "        batch = normalise_batch(raw)\n",
    "        B = batch[0].shape[0]\n",
    "        for L, h in enumerate(batch):\n",
    "            layer_blobs[L].append(h.float().numpy())\n",
    "        labels.extend([lab]*B)\n",
    "\n",
    "add_files(files_none,  0)   # 0 = none\n",
<<<<<<< HEAD
    "add_files(files_sync,  1)   # 1 = unverb\n",
=======
    "add_files(files_sync,  1)   # 1 = sycophancy\n",
>>>>>>> c97d793099548bd91ae26e8822ce75baadab6f3a
    "\n",
    "assert labels, \"No usable data loaded.\"\n",
    "labels = np.asarray(labels, dtype=np.int8)\n",
    "print(\"Total samples:\", len(labels))\n",
    "\n",
    "layer_X = {L: np.concatenate(layer_blobs[L], axis=0) for L in layer_blobs}\n",
    "del layer_blobs\n",
    "\n",
    "scalers = {}\n",
    "for L in range(N_LAYERS):\n",
    "    scaler = StandardScaler()\n",
    "    layer_X[L] = scaler.fit_transform(layer_X[L])\n",
<<<<<<< HEAD
    "    scalers[L] = scaler\n",
    "\n",
=======
    "    scalers[L] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation accuracy:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer  0:  0.678\n",
      "layer  1:  0.973\n",
      "layer  2:  0.984\n",
      "layer  3:  0.992\n",
      "layer  4:  0.996\n",
      "layer  5:  0.996\n",
      "layer  6:  0.997\n",
      "layer  7:  0.999\n",
      "layer  8:  1.000\n",
      "layer  9:  1.000\n",
      "layer 10:  1.000\n",
      "layer 11:  1.000\n",
      "layer 12:  1.000\n",
      "layer 13:  1.000\n",
      "layer 14:  1.000\n",
      "layer 15:  1.000\n",
      "layer 16:  1.000\n",
      "layer 17:  1.000\n",
      "layer 18:  1.000\n",
      "layer 19:  1.000\n",
      "layer 20:  1.000\n",
      "layer 21:  1.000\n",
      "layer 22:  1.000\n",
      "layer 23:  1.000\n",
      "layer 24:  1.000\n",
      "layer 25:  1.000\n",
      "layer 26:  1.000\n",
      "layer 27:  1.000\n",
      "layer 28:  1.000\n",
      "layer 29:  1.000\n",
      "layer 30:  1.000\n",
      "layer 31:  1.000\n",
      "layer 32:  1.000\n",
      "\\First highest layer = 8  (acc = 1.000)\n",
      "\n",
      "Probe saved to i_probe_steer/extractions/hints/mmlu/DeepSeek-R1-Distill-Llama-8B/sycophancy_probe_layer8.pkl\n"
     ]
    }
   ],
   "source": [
>>>>>>> c97d793099548bd91ae26e8822ce75baadab6f3a
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "layer_scores = []\n",
    "\n",
    "print(\"\\nCross-validation accuracy:\")\n",
    "for L in range(N_LAYERS):\n",
    "    clf = LogisticRegression(penalty=\"l2\", C=1.0, max_iter=1000, n_jobs=-1)\n",
    "    acc = cross_val_score(clf, layer_X[L], labels, cv=cv, scoring=\"accuracy\").mean()\n",
    "    print(f\"layer {L:2d}:  {acc:.3f}\")\n",
    "    layer_scores.append(acc)\n",
    "\n",
    "best_layer = int(np.argmax(layer_scores))\n",
    "print(f\"\\First highest layer = {best_layer}  (acc = {layer_scores[best_layer]:.3f})\")\n",
    "\n",
    "# final fit on the best layer, save probe + Δµ\n",
    "X_best  = layer_X[best_layer]\n",
    "clf_best = LogisticRegression(penalty=\"l2\", C=1.0, max_iter=1000, n_jobs=-1).fit(X_best, labels)\n",
    "\n",
    "mu_none = X_best[labels == 0].mean(axis=0)\n",
    "mu_sync = X_best[labels == 1].mean(axis=0)\n",
    "delta_mu = mu_sync - mu_none\n",
    "\n",
<<<<<<< HEAD
    "OUT = ROOT / f\"unverb_probe_layer{best_layer}.pkl\"\n",
=======
    "OUT = ROOT / f\"sycophancy_probe_layer{best_layer}.pkl\"\n",
>>>>>>> c97d793099548bd91ae26e8822ce75baadab6f3a
    "with open(OUT, \"wb\") as f:\n",
    "    pickle.dump(\n",
    "        dict(\n",
    "            layer       = best_layer,\n",
    "            weights     = clf_best.coef_[0].astype(np.float32),\n",
    "            intercept   = float(clf_best.intercept_[0]),\n",
    "            delta_mu    = delta_mu.astype(np.float32),\n",
    "            hidden_size = HIDDEN_SIZE,\n",
    "            created     = datetime.datetime.now().isoformat(timespec=\"seconds\"),\n",
    "            acc_cv      = float(layer_scores[best_layer]),\n",
<<<<<<< HEAD
    "            note        = \"0 = none, 1 = unverb; StandardScaler applied.\",\n",
    "        ),\n",
    "        f,\n",
    "    )\n",
    "print(f\"\\nProbe saved to {OUT.relative_to(Path('.'))}\")\n",
    "\n"
=======
    "            note        = \"0 = none, 1 = sycophancy; StandardScaler applied.\",\n",
    "        ),\n",
    "        f,\n",
    "    )\n",
    "print(f\"\\nProbe saved to {OUT.relative_to(Path('.'))}\")\n"
>>>>>>> c97d793099548bd91ae26e8822ce75baadab6f3a
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
