{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n",
      "02:34:05  INFO │ 🔌  loading linear probe  →  linear_probes/realyesno_None4k/linear_probe_layer5.joblib\n",
      "02:34:05  INFO │    → expecting activations from transformer layer  5\n",
      "02:34:05  INFO │ answers_map built with 100 entries\n",
      "02:34:05  INFO │ found 592 hidden-state files in h_hidden_space/outputs/f1_hint_xyyx/xyyx_deterministic/gt_lt_completions_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59759/3426602988.py:117: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  batch_hidden = torch.load(hid_fp)            # list[n_layers]  each  (B,H)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/CoTFaithChecker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02:34:07  INFO │ collected 9620 labelled activation-vectors\n",
      "02:34:07  INFO │ running probe on 9620 vectors (d=4096)\n",
      "02:34:07  INFO │ RESULTS  ·  acc 0.770   f1 0.870\n",
      "02:34:07  INFO │ \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.800     0.002     0.004      2220\n",
      "           1      0.770     1.000     0.870      7400\n",
      "\n",
      "    accuracy                          0.770      9620\n",
      "   macro avg      0.785     0.501     0.437      9620\n",
      "weighted avg      0.777     0.770     0.670      9620\n",
      "\n",
      "02:34:07  INFO │ • confusion-matrix written → linear_probes/realyesno_None4k/confusion_matrix_apply.png\n",
      "02:34:07  INFO │ • ROC curve written        → linear_probes/realyesno_None4k/roc_apply.png\n",
      "02:34:08  INFO │ • probability histogram    → linear_probes/realyesno_None4k/prob_hist_apply.png\n",
      "02:34:08  INFO │ done in 2.2 s\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#  XY⇄YX  faithfulness  ·  APPLY  a previously-trained linear probe\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "%cd ../..\n",
    "%pwd\n",
    "import os, re, json, time, random, logging\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, confusion_matrix, classification_report,\n",
    "    roc_curve, auc,\n",
    ")\n",
    "\n",
    "# ╭───────────────────────── CONFIGURABLE PARAMETERS ─────────────────────────╮\n",
    "PROBE_PATH          = Path(\"linear_probes/realyesno_None4k/linear_probe_layer5.joblib\")\n",
    "ACTIVATIONS_DIR     = Path(\"h_hidden_space/outputs/f1_hint_xyyx/xyyx_deterministic/gt_lt_completions_1\")\n",
    "ANSWERS_DIRS        = [\n",
    "    Path(\"e_confirm_xy_yx/outputs/matched_vals_gt\"),\n",
    "    Path(\"e_confirm_xy_yx/outputs/matched_vals_lt\"),\n",
    "]\n",
    "QUESTION_JSON_ROOT  = Path(\"data/chainscope/questions_json/linked\")\n",
    "\n",
    "INFERENCE_BATCH_SIZE = 32        # must match the batch-size used when capturing hiddens\n",
    "MAX_SAMPLES          = None      # e.g. 10_000 to subsample for speed, or None = use all\n",
    "SEED                 = 0\n",
    "# ╰────────────────────────────────────────────────────────────────────────────╯\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# ─── logging setup ───────────────────────────────────────────────────────────\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s  %(levelname)s │ %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    ")\n",
    "log = logging.getLogger(\"apply_probe\")\n",
    "\n",
    "t0 = time.time()\n",
    "log.info(\"loading linear probe  →  %s\", PROBE_PATH)\n",
    "probe = joblib.load(PROBE_PATH)\n",
    "\n",
    "m = re.search(r\"layer(\\d+)\", PROBE_PATH.name)        # ← fixed: plain assignment\n",
    "LAYER = int(m.group(1)) if m else None\n",
    "if LAYER is None:\n",
    "    raise RuntimeError(\"Could not infer layer-number from probe filename – \"\n",
    "                       \"rename as “…layerXX.joblib” or set LAYER manually.\")\n",
    "log.info(\"   → expecting activations from transformer layer  %d\", LAYER)\n",
    "\n",
    "# ╭────────────────────────────────────────────────────────────────────────────╮\n",
    "# │ 1.  answers-metadata lookup                                               │\n",
    "# ╰────────────────────────────────────────────────────────────────────────────╯\n",
    "answers_map = {}\n",
    "for dir_ in ANSWERS_DIRS:\n",
    "    for fp in dir_.glob(\"*.json\"):\n",
    "        with open(fp) as f:\n",
    "            raw = json.load(f)\n",
    "        questions = raw[\"questions\"] if isinstance(raw, dict) else raw\n",
    "        for q in questions:\n",
    "            same_flag = q[\"same\"][0] if isinstance(q[\"same\"], list) else q[\"same\"]\n",
    "            q_no  = q[\"question_id\"]\n",
    "            q_yes = q[\"question_yes_id\"]\n",
    "            answers_map[q_no]  = {\"expected\": \"NO\",  \"actual\": q[\"a_answers\"][0],\n",
    "                                  \"same\": same_flag}\n",
    "            answers_map[q_yes] = {\"expected\": \"YES\", \"actual\": q[\"b_answers\"][0],\n",
    "                                  \"same\": same_flag}\n",
    "\n",
    "log.info(\"answers_map built with %d entries\", len(answers_map))\n",
    "\n",
    "# ╭────────────────────────────────────────────────────────────────────────────╮\n",
    "# │ 2.  utilities to resolve hidden-file rows → question-ids                  │\n",
    "# ╰────────────────────────────────────────────────────────────────────────────╯\n",
    "_STEM2PATH = {}\n",
    "\n",
    "def _index_datasets_once():\n",
    "    if _STEM2PATH:               # already done\n",
    "        return\n",
    "    for p in QUESTION_JSON_ROOT.rglob(\"*.json\"):\n",
    "        _STEM2PATH[p.stem] = p\n",
    "    if not _STEM2PATH:\n",
    "        raise RuntimeError(f\"No *.json found under {QUESTION_JSON_ROOT}\")\n",
    "\n",
    "def _dataset_questions_for(stem: str):\n",
    "    _index_datasets_once()\n",
    "    fp = _STEM2PATH.get(stem)\n",
    "    if fp is None:\n",
    "        raise FileNotFoundError(f\"Cannot find dataset JSON for stem {stem}\")\n",
    "    with open(fp) as f:\n",
    "        raw = json.load(f)\n",
    "    return raw[\"questions\"] if isinstance(raw, dict) else raw\n",
    "\n",
    "_BATCH_RE = re.compile(r\"_batch(\\d+)_hidden\\.pt$\")\n",
    "\n",
    "def question_ids_for_hidden_file(hid_path: Path, batch_size: int, actual_len: int):\n",
    "    m = _BATCH_RE.search(hid_path.name)\n",
    "    if m is None:\n",
    "        raise ValueError(f\"Bad hidden filename: {hid_path.name}\")\n",
    "    batch_idx = int(m.group(1))\n",
    "    stem      = hid_path.name[:m.start()]         # strip “…_batchX_hidden.pt”\n",
    "    q_list    = _dataset_questions_for(stem)\n",
    "    start     = batch_idx * batch_size\n",
    "    return [q_list[start + j][\"question_id\"] for j in range(actual_len)]\n",
    "\n",
    "# ╭────────────────────────────────────────────────────────────────────────────╮\n",
    "# │ 3.  collect hidden-vectors & labels                                       │\n",
    "# ╰────────────────────────────────────────────────────────────────────────────╯\n",
    "X_vecs, y_labels = [], []\n",
    "\n",
    "hidden_files = sorted(ACTIVATIONS_DIR.rglob(\"*_hidden.pt\"))\n",
    "log.info(\"found %d hidden-state files in %s\", len(hidden_files), ACTIVATIONS_DIR)\n",
    "\n",
    "for hid_fp in hidden_files:\n",
    "    batch_hidden = torch.load(hid_fp)            # list[n_layers]  each  (B,H)\n",
    "    vecs_L       = batch_hidden[LAYER]           # (B,H) tensor for probed layer\n",
    "    batch_len    = vecs_L.size(0)\n",
    "\n",
    "    q_ids = question_ids_for_hidden_file(\n",
    "        hid_fp, INFERENCE_BATCH_SIZE, batch_len\n",
    "    )\n",
    "\n",
    "    for row_idx, qid in enumerate(q_ids):\n",
    "        meta = answers_map.get(qid)\n",
    "        if meta is None:\n",
    "            continue        # shouldn’t happen unless dirs mismatch\n",
    "\n",
    "        correct = (meta[\"actual\"] == meta[\"expected\"])\n",
    "        if not correct and not meta[\"same\"]:\n",
    "            continue        # we *skip* ordinary wrong answers\n",
    "\n",
    "        label = 1 if correct else 0      # 1 = faithful-and-correct, 0 = same-answer error\n",
    "        X_vecs.append(vecs_L[row_idx].float().numpy())\n",
    "        y_labels.append(label)\n",
    "\n",
    "log.info(\"collected %d labelled activation-vectors\", len(X_vecs))\n",
    "if not X_vecs:\n",
    "    raise RuntimeError(\"Nothing to evaluate on – check the filters & paths.\")\n",
    "\n",
    "# optional subsample for speed\n",
    "if MAX_SAMPLES and len(X_vecs) > MAX_SAMPLES:\n",
    "    log.info(\"sub-sampling to %d items (random, reproducible)\", MAX_SAMPLES)\n",
    "    idx = np.random.RandomState(SEED).choice(len(X_vecs), MAX_SAMPLES, replace=False)\n",
    "    X_vecs = [X_vecs[i] for i in idx]\n",
    "    y_labels = [y_labels[i] for i in idx]\n",
    "\n",
    "X = np.stack(X_vecs)\n",
    "y = np.array(y_labels)\n",
    "\n",
    "# ╭────────────────────────────────────────────────────────────────────────────╮\n",
    "# │ 4.  run the probe                                                         │\n",
    "# ╰────────────────────────────────────────────────────────────────────────────╯\n",
    "log.info(\"running probe on %s vectors (d=%d)\", len(X), X.shape[1])\n",
    "\n",
    "if hasattr(probe, \"predict_proba\"):\n",
    "    prob_pos = probe.predict_proba(X)[:, 1]\n",
    "else:\n",
    "    prob_pos = probe.decision_function(X)\n",
    "pred = (prob_pos >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y, pred)\n",
    "f1  = f1_score(y, pred)\n",
    "log.info(\"RESULTS  ·  acc %.3f   f1 %.3f\", acc, f1)\n",
    "log.info(\"\\n\" + classification_report(y, pred, digits=3))\n",
    "\n",
    "# ╭────────────────────────────────────────────────────────────────────────────╮\n",
    "# │ 5.  quick-look figures                                                    │\n",
    "# ╰────────────────────────────────────────────────────────────────────────────╯\n",
    "figdir = PROBE_PATH.parent\n",
    "figdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Confusion-matrix\n",
    "cm = confusion_matrix(y, pred)\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(cm, cmap=\"Blues\")\n",
    "for (i,j),v in np.ndenumerate(cm):\n",
    "    plt.text(j, i, f\"{v:,}\", ha=\"center\", va=\"center\", fontsize=9)\n",
    "plt.xticks([0,1], [\"error\",\"correct\"]); plt.yticks([0,1], [\"error\",\"correct\"])\n",
    "plt.title(\"confusion matrix\")\n",
    "plt.tight_layout(); cm_path = figdir / \"confusion_matrix_apply.png\"; plt.savefig(cm_path); plt.close()\n",
    "log.info(\"• confusion-matrix written → %s\", cm_path)\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, _ = roc_curve(y, prob_pos)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(fpr, tpr, lw=2); plt.plot([0,1],[0,1],\"--\")\n",
    "plt.title(f\"ROC AUC {roc_auc:.3f}\")\n",
    "plt.xlabel(\"false-positive-rate\"); plt.ylabel(\"true-positive-rate\")\n",
    "plt.tight_layout(); roc_path = figdir / \"roc_apply.png\"; plt.savefig(roc_path); plt.close()\n",
    "log.info(\"• ROC curve written        → %s\", roc_path)\n",
    "\n",
    "# probability histogram\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.hist(prob_pos[y==0], bins=40, alpha=0.6, label=\"label 0  (same-answer error)\")\n",
    "plt.hist(prob_pos[y==1], bins=40, alpha=0.6, label=\"label 1  (correct)\")\n",
    "plt.xlabel(\"probe p(correct)\"); plt.ylabel(\"count\"); plt.legend()\n",
    "plt.tight_layout(); hist_path = figdir / \"prob_hist_apply.png\"; plt.savefig(hist_path); plt.close()\n",
    "log.info(\"• probability histogram    → %s\", hist_path)\n",
    "\n",
    "log.info(\"done in %.1f s\", time.time() - t0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
