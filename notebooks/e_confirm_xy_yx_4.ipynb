{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ───────────────────────────────────────────────\n",
    "# 0. Manual configuration\n",
    "# ───────────────────────────────────────────────\n",
    "%cd ..\n",
    "%pwd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "DATA_ROOT = Path(\"data/chainscope/questions_json\")\n",
    "TEMPLATE_PATH = Path(\"data/chainscope/templates/instructions.json\")\n",
    "LOG_DIR = Path(\"logs\")\n",
    "OUT_DIR = Path(\"e_confirm_xy_yx/outputs\")          # completions, verification, matches\n",
    "MODEL_PATH = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# choose folder subsets\n",
    "DATASETS = [\"gt_YES_1\"]\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "MAX_NEW_TOKENS = None\n",
    "SAVE_HIDDEN, SAVE_ATTN = False, False\n",
    "HIDDEN_LAYERS, ATTN_LAYERS = [0, -1], [0, -1]   # ignored unless above switches True\n",
    "N_VERIFY = 0   # 0 == verify all\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 1. Load model & tokenizer  (your helper)\n",
    "# ───────────────────────────────────────────────\n",
    "from a_confirm_posthoc.utils.model_handler import load_model_and_tokenizer\n",
    "\n",
    "model, tokenizer, model_name, device = load_model_and_tokenizer(MODEL_PATH)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from e_confirm_xy_yx.main.data_loader import get_dataset_files\n",
    "\n",
    "# 0. Extra toggle\n",
    "CLUSTERS = [\"us\"]   # no \"no_wm\"\n",
    "\n",
    "# 2. Collect dataset files\n",
    "dataset_files = get_dataset_files(\n",
    "    DATA_ROOT,\n",
    "    DATASETS,\n",
    "    clusters=CLUSTERS,          # ← NEW ARG\n",
    ")\n",
    "\n",
    "# 5. Verify – point to aggregated cluster outputs\n",
    "completion_files = sorted(\n",
    "    (OUT_DIR / \"completions\" / \"clusters\").glob(\"*_completions.json\")\n",
    ")\n",
    "\n",
    "# 6. Match YES vs NO on cluster files\n",
    "verified_files = sorted((OUT_DIR / \"verified\").glob(\"*_verified.json\"))\n",
    "\n",
    "pairs = [\n",
    "    (vf, vf.parent / vf.name.replace(\"_NO_\", \"_YES_\"))\n",
    "    for vf in verified_files\n",
    "    if \"_NO_\" in vf.name\n",
    "    and (vf.parent / vf.name.replace(\"_NO_\", \"_YES_\")).exists()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 2. Collect dataset files\n",
    "# ───────────────────────────────────────────────\n",
    "#from e_confirm_xy_yx.main.data_loader import get_dataset_files\n",
    "#dataset_files = get_dataset_files(DATA_ROOT, DATASETS)\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 3. Prepare prompt builder\n",
    "# ───────────────────────────────────────────────\n",
    "from e_confirm_xy_yx.main.prompt_builder import PromptBuilder\n",
    "pb = PromptBuilder(template_path=TEMPLATE_PATH, style=\"instr-v0\", mode=\"cot\")\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 4. Run inference\n",
    "# ───────────────────────────────────────────────\n",
    "from e_confirm_xy_yx.main.inference import run_inference\n",
    "\n",
    "run_inference(\n",
    "    dataset_files=dataset_files,\n",
    "    prompt_builder=pb,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    model_name=model_name,\n",
    "    device=device,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_new_tokens=MAX_NEW_TOKENS,\n",
    "    save_hidden=SAVE_HIDDEN,\n",
    "    hidden_layers=HIDDEN_LAYERS,\n",
    "    save_attention=SAVE_ATTN,\n",
    "    attn_layers=ATTN_LAYERS,\n",
    "    output_dir=OUT_DIR / \"completions\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ───────────────────────────────────────────────\n",
    "# 5. Verify model answers\n",
    "# ───────────────────────────────────────────────\n",
    "from e_confirm_xy_yx.main.verifier import run_verification\n",
    "completion_files = sorted((OUT_DIR / \"completions\").glob(\"*_completions.json\"))\n",
    "\n",
    "run_verification(\n",
    "    completion_files=completion_files,\n",
    "    n_questions=N_VERIFY,\n",
    "    output_dir=OUT_DIR / \"verified\",\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "# ───────────────────────────────────────────────\n",
    "# 6. Cross-match YES vs NO answers\n",
    "# ───────────────────────────────────────────────\n",
    "from e_confirm_xy_yx.main.match_checker import check_matches\n",
    "verified_files = sorted((OUT_DIR / \"verified\").glob(\"*_verified.json\"))\n",
    "\n",
    "# pair them: every gt_NO_X file with its matching gt_YES_X (adapt if lt)\n",
    "pairs = [\n",
    "    (\n",
    "        vf,\n",
    "        vf.parent\n",
    "        / vf.name.replace(\"gt_NO\", \"gt_YES\")\n",
    "    )\n",
    "    for vf in verified_files\n",
    "    if \"_NO_\" in vf.name\n",
    "]\n",
    "\n",
    "for no_file, yes_file in pairs:\n",
    "    out_match = (\n",
    "        OUT_DIR\n",
    "        / \"matches\"\n",
    "        / f\"{no_file.stem.replace('_verified','')}_match.json\"\n",
    "    )\n",
    "    out_match.parent.mkdir(parents=True, exist_ok=True)\n",
    "    check_matches(no_file, yes_file, out_match)\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
