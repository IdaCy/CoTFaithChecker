{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/CoTFaithChecker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/root/CoTFaithChecker'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, torch, json, logging\n",
    "from a_confirm_posthoc.src.utils.model_handler import load_model_and_tokenizer\n",
    "from a_confirm_posthoc.src.eval.core_steps_extractor import run_core_step_extraction\n",
    "from a_confirm_posthoc.src.ablation.kv_ablation import run_kv_ablation_experiment\n",
    "from a_confirm_posthoc.src.ablation.plot_ablation import load_ablation_dataframe, plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 20:27:34,635 - INFO - CUDA is available. Using GPU.\n",
      "2025-04-24 20:27:34,637 - INFO - Loading model and tokenizer: deepseek-ai/DeepSeek-R1-Distill-Llama-8B onto cuda\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]\n",
      "2025-04-24 20:27:41,455 - INFO - Model and tokenizer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "DATASET     = \"mmlu\"\n",
    "HINT_TYPES  = [\"none\", \"sycophancy\", \"unethical_information\", \"induced_urgency\"]\n",
    "N_QUESTIONS = 500\n",
    "\n",
    "model, tok, model_name, device = load_model_and_tokenizer(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 19:54:45,838 - INFO - Extracting core steps for sycophancy / DeepSeek-R1-Distill-Llama-8B\n",
      "sycophancy: extracting:   0%|          | 0/121 [00:00<?, ?it/s]2025-04-24 19:54:45,854 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:54:47,306 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:54:47,310 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:   1%|          | 1/121 [00:01<02:54,  1.46s/it]2025-04-24 19:54:47,312 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:54:48,718 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:54:48,722 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:   2%|▏         | 2/121 [00:02<02:50,  1.43s/it]2025-04-24 19:54:48,723 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:54:50,175 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:54:50,179 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:   2%|▏         | 3/121 [00:04<02:50,  1.44s/it]2025-04-24 19:54:50,181 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:54:51,631 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:54:51,635 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:   3%|▎         | 4/121 [00:05<02:49,  1.45s/it]2025-04-24 19:54:51,637 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:54:52,645 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:54:52,648 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:   4%|▍         | 5/121 [00:06<02:29,  1.29s/it]2025-04-24 19:54:52,651 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:54:53,929 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:54:53,932 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:   5%|▍         | 6/121 [00:08<02:28,  1.29s/it]2025-04-24 19:54:53,935 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:54:55,355 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:54:55,359 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:   6%|▌         | 7/121 [00:09<02:32,  1.33s/it]2025-04-24 19:54:55,361 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:54:56,523 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:54:56,527 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:   7%|▋         | 8/121 [00:10<02:24,  1.28s/it]2025-04-24 19:54:56,529 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:54:58,308 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:54:58,311 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:   7%|▋         | 9/121 [00:12<02:41,  1.44s/it]2025-04-24 19:54:58,313 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:54:59,790 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:54:59,793 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:   8%|▊         | 10/121 [00:13<02:41,  1.45s/it]2025-04-24 19:54:59,795 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:01,031 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:01,034 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:   9%|▉         | 11/121 [00:15<02:32,  1.39s/it]2025-04-24 19:55:01,036 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:02,302 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:02,306 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  10%|▉         | 12/121 [00:16<02:27,  1.35s/it]2025-04-24 19:55:02,308 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:03,280 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:03,284 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  11%|█         | 13/121 [00:17<02:13,  1.24s/it]2025-04-24 19:55:03,285 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:04,143 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:04,147 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  12%|█▏        | 14/121 [00:18<02:00,  1.13s/it]2025-04-24 19:55:04,149 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:05,976 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:05,980 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  12%|█▏        | 15/121 [00:20<02:21,  1.34s/it]2025-04-24 19:55:05,982 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:07,246 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:07,250 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  13%|█▎        | 16/121 [00:21<02:18,  1.32s/it]2025-04-24 19:55:07,252 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:08,693 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:08,696 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  14%|█▍        | 17/121 [00:22<02:21,  1.36s/it]2025-04-24 19:55:08,698 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:10,258 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:10,262 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  15%|█▍        | 18/121 [00:24<02:26,  1.42s/it]2025-04-24 19:55:10,263 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:11,520 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:11,524 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  16%|█▌        | 19/121 [00:25<02:19,  1.37s/it]2025-04-24 19:55:11,526 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:12,712 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:12,716 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  17%|█▋        | 20/121 [00:26<02:13,  1.32s/it]2025-04-24 19:55:12,718 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:13,970 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:13,974 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  17%|█▋        | 21/121 [00:28<02:10,  1.30s/it]2025-04-24 19:55:13,976 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:15,174 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:15,177 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  18%|█▊        | 22/121 [00:29<02:05,  1.27s/it]2025-04-24 19:55:15,179 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:16,755 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:16,758 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  19%|█▉        | 23/121 [00:30<02:13,  1.36s/it]2025-04-24 19:55:16,760 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:18,104 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:18,108 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  20%|█▉        | 24/121 [00:32<02:11,  1.36s/it]2025-04-24 19:55:18,110 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:19,561 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:19,564 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  21%|██        | 25/121 [00:33<02:13,  1.39s/it]2025-04-24 19:55:19,566 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:20,438 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:20,442 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  21%|██▏       | 26/121 [00:34<01:57,  1.24s/it]2025-04-24 19:55:20,444 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:22,242 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:22,247 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  22%|██▏       | 27/121 [00:36<02:12,  1.41s/it]2025-04-24 19:55:22,248 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:23,506 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:23,509 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  23%|██▎       | 28/121 [00:37<02:06,  1.36s/it]2025-04-24 19:55:23,511 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:24,770 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:24,773 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  24%|██▍       | 29/121 [00:38<02:02,  1.33s/it]2025-04-24 19:55:24,775 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:26,181 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:26,185 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  25%|██▍       | 30/121 [00:40<02:03,  1.36s/it]2025-04-24 19:55:26,187 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:28,289 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:28,291 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  26%|██▌       | 31/121 [00:42<02:22,  1.58s/it]2025-04-24 19:55:28,294 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:29,339 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:29,343 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  26%|██▋       | 32/121 [00:43<02:06,  1.42s/it]2025-04-24 19:55:29,345 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:30,324 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:30,327 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  27%|██▋       | 33/121 [00:44<01:53,  1.29s/it]2025-04-24 19:55:30,329 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:31,337 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:31,340 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  28%|██▊       | 34/121 [00:45<01:45,  1.21s/it]2025-04-24 19:55:31,341 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:32,976 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:32,979 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  29%|██▉       | 35/121 [00:47<01:54,  1.34s/it]2025-04-24 19:55:32,981 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:34,336 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:34,339 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  30%|██▉       | 36/121 [00:48<01:54,  1.34s/it]2025-04-24 19:55:34,342 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:35,723 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:35,727 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  31%|███       | 37/121 [00:49<01:53,  1.36s/it]2025-04-24 19:55:35,729 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:36,595 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:36,597 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  31%|███▏      | 38/121 [00:50<01:40,  1.21s/it]2025-04-24 19:55:36,599 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:37,560 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:37,563 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  32%|███▏      | 39/121 [00:51<01:33,  1.14s/it]2025-04-24 19:55:37,565 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:38,990 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:38,994 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  33%|███▎      | 40/121 [00:53<01:39,  1.23s/it]2025-04-24 19:55:38,996 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:39,874 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:39,876 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  34%|███▍      | 41/121 [00:54<01:29,  1.12s/it]2025-04-24 19:55:39,877 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:40,720 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:40,723 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  35%|███▍      | 42/121 [00:54<01:22,  1.04s/it]2025-04-24 19:55:40,725 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:41,903 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:41,907 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  36%|███▌      | 43/121 [00:56<01:24,  1.08s/it]2025-04-24 19:55:41,909 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:42,695 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:42,699 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  36%|███▋      | 44/121 [00:56<01:16,  1.00it/s]2025-04-24 19:55:42,700 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:44,093 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:44,097 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  37%|███▋      | 45/121 [00:58<01:24,  1.12s/it]2025-04-24 19:55:44,098 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:45,773 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:45,777 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  38%|███▊      | 46/121 [00:59<01:36,  1.29s/it]2025-04-24 19:55:45,779 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:46,931 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:46,934 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  39%|███▉      | 47/121 [01:01<01:32,  1.25s/it]2025-04-24 19:55:46,936 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:47,638 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:47,641 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  40%|███▉      | 48/121 [01:01<01:19,  1.08s/it]2025-04-24 19:55:47,642 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:50,063 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:50,066 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  40%|████      | 49/121 [01:04<01:47,  1.49s/it]2025-04-24 19:55:50,068 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:51,023 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:51,026 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  41%|████▏     | 50/121 [01:05<01:34,  1.33s/it]2025-04-24 19:55:51,028 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:52,043 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:52,045 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  42%|████▏     | 51/121 [01:06<01:26,  1.24s/it]2025-04-24 19:55:52,047 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:53,253 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:53,255 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  43%|████▎     | 52/121 [01:07<01:24,  1.23s/it]2025-04-24 19:55:53,257 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:54,165 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:54,168 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  44%|████▍     | 53/121 [01:08<01:17,  1.13s/it]2025-04-24 19:55:54,169 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:56,220 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:56,224 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  45%|████▍     | 54/121 [01:10<01:34,  1.41s/it]2025-04-24 19:55:56,226 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:57,470 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:57,473 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  45%|████▌     | 55/121 [01:11<01:29,  1.36s/it]2025-04-24 19:55:57,475 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:55:58,901 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:55:58,904 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  46%|████▋     | 56/121 [01:13<01:29,  1.38s/it]2025-04-24 19:55:58,905 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:00,426 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:00,429 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  47%|████▋     | 57/121 [01:14<01:31,  1.43s/it]2025-04-24 19:56:00,431 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:02,126 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:02,130 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  48%|████▊     | 58/121 [01:16<01:35,  1.51s/it]2025-04-24 19:56:02,131 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:03,316 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:03,320 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  49%|████▉     | 59/121 [01:17<01:27,  1.41s/it]2025-04-24 19:56:03,322 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:04,215 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:04,217 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  50%|████▉     | 60/121 [01:18<01:16,  1.26s/it]2025-04-24 19:56:04,219 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:05,259 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:05,262 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  50%|█████     | 61/121 [01:19<01:11,  1.19s/it]2025-04-24 19:56:05,264 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:06,183 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:06,185 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  51%|█████     | 62/121 [01:20<01:05,  1.11s/it]2025-04-24 19:56:06,187 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:07,422 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:07,425 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  52%|█████▏    | 63/121 [01:21<01:06,  1.15s/it]2025-04-24 19:56:07,427 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:09,300 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:09,303 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  53%|█████▎    | 64/121 [01:23<01:18,  1.37s/it]2025-04-24 19:56:09,305 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:10,381 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:10,384 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  54%|█████▎    | 65/121 [01:24<01:11,  1.28s/it]2025-04-24 19:56:10,386 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:11,382 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:11,386 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  55%|█████▍    | 66/121 [01:25<01:05,  1.20s/it]2025-04-24 19:56:11,387 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:13,212 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:13,216 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  55%|█████▌    | 67/121 [01:27<01:14,  1.39s/it]2025-04-24 19:56:13,218 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:14,684 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:14,687 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  56%|█████▌    | 68/121 [01:28<01:14,  1.41s/it]2025-04-24 19:56:14,690 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:16,091 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:16,095 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  57%|█████▋    | 69/121 [01:30<01:13,  1.41s/it]2025-04-24 19:56:16,096 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:17,204 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:17,208 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  58%|█████▊    | 70/121 [01:31<01:07,  1.32s/it]2025-04-24 19:56:17,210 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:18,711 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:18,714 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  59%|█████▊    | 71/121 [01:32<01:08,  1.38s/it]2025-04-24 19:56:18,715 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:19,536 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:19,539 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  60%|█████▉    | 72/121 [01:33<00:59,  1.21s/it]2025-04-24 19:56:19,541 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:21,071 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:21,074 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  60%|██████    | 73/121 [01:35<01:02,  1.31s/it]2025-04-24 19:56:21,076 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:22,511 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:22,515 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  61%|██████    | 74/121 [01:36<01:03,  1.35s/it]2025-04-24 19:56:22,517 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:23,460 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:23,464 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  62%|██████▏   | 75/121 [01:37<00:56,  1.23s/it]2025-04-24 19:56:23,466 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:24,866 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:24,870 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  63%|██████▎   | 76/121 [01:39<00:57,  1.28s/it]2025-04-24 19:56:24,871 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:26,023 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:26,026 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  64%|██████▎   | 77/121 [01:40<00:54,  1.24s/it]2025-04-24 19:56:26,028 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:26,892 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:26,895 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  64%|██████▍   | 78/121 [01:41<00:48,  1.13s/it]2025-04-24 19:56:26,897 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:28,394 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:28,397 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  65%|██████▌   | 79/121 [01:42<00:52,  1.24s/it]2025-04-24 19:56:28,399 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:29,977 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:29,980 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  66%|██████▌   | 80/121 [01:44<00:55,  1.34s/it]2025-04-24 19:56:29,982 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:31,208 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:31,211 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  67%|██████▋   | 81/121 [01:45<00:52,  1.31s/it]2025-04-24 19:56:31,213 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:32,360 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:32,362 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  68%|██████▊   | 82/121 [01:46<00:49,  1.26s/it]2025-04-24 19:56:32,364 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:33,595 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:33,598 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  69%|██████▊   | 83/121 [01:47<00:47,  1.25s/it]2025-04-24 19:56:33,600 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:34,684 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:34,686 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  69%|██████▉   | 84/121 [01:48<00:44,  1.20s/it]2025-04-24 19:56:34,688 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:35,963 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:35,966 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  70%|███████   | 85/121 [01:50<00:44,  1.23s/it]2025-04-24 19:56:35,968 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:37,548 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:37,551 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  71%|███████   | 86/121 [01:51<00:46,  1.33s/it]2025-04-24 19:56:37,553 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:38,640 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:38,644 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  72%|███████▏  | 87/121 [01:52<00:42,  1.26s/it]2025-04-24 19:56:38,646 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:40,109 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:40,113 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  73%|███████▎  | 88/121 [01:54<00:43,  1.32s/it]2025-04-24 19:56:40,115 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:41,074 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:41,077 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  74%|███████▎  | 89/121 [01:55<00:38,  1.22s/it]2025-04-24 19:56:41,079 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:42,559 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:42,562 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  74%|███████▍  | 90/121 [01:56<00:40,  1.30s/it]2025-04-24 19:56:42,564 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:43,628 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:43,631 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  75%|███████▌  | 91/121 [01:57<00:36,  1.23s/it]2025-04-24 19:56:43,633 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:44,632 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:44,635 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  76%|███████▌  | 92/121 [01:58<00:33,  1.16s/it]2025-04-24 19:56:44,637 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:46,302 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:46,306 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  77%|███████▋  | 93/121 [02:00<00:36,  1.31s/it]2025-04-24 19:56:46,308 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:47,298 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:47,300 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  78%|███████▊  | 94/121 [02:01<00:32,  1.22s/it]2025-04-24 19:56:47,302 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:48,428 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:48,432 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  79%|███████▊  | 95/121 [02:02<00:30,  1.19s/it]2025-04-24 19:56:48,434 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:49,366 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:49,369 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  79%|███████▉  | 96/121 [02:03<00:27,  1.12s/it]2025-04-24 19:56:49,372 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:50,289 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:50,292 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  80%|████████  | 97/121 [02:04<00:25,  1.06s/it]2025-04-24 19:56:50,294 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:51,342 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:51,345 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  81%|████████  | 98/121 [02:05<00:24,  1.06s/it]2025-04-24 19:56:51,347 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:52,103 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:52,105 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  82%|████████▏ | 99/121 [02:06<00:21,  1.03it/s]2025-04-24 19:56:52,107 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:53,272 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:53,279 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  83%|████████▎ | 100/121 [02:07<00:21,  1.03s/it]2025-04-24 19:56:53,281 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:54,183 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:54,186 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  83%|████████▎ | 101/121 [02:08<00:19,  1.01it/s]2025-04-24 19:56:54,187 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:55,718 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:55,722 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  84%|████████▍ | 102/121 [02:09<00:21,  1.16s/it]2025-04-24 19:56:55,724 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:56,853 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:56,856 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  85%|████████▌ | 103/121 [02:11<00:20,  1.15s/it]2025-04-24 19:56:56,858 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:58,416 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:58,420 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  86%|████████▌ | 104/121 [02:12<00:21,  1.27s/it]2025-04-24 19:56:58,423 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:56:59,803 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:56:59,807 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  87%|████████▋ | 105/121 [02:13<00:20,  1.31s/it]2025-04-24 19:56:59,809 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:00,931 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:00,934 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  88%|████████▊ | 106/121 [02:15<00:18,  1.25s/it]2025-04-24 19:57:00,936 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:02,198 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:02,202 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  88%|████████▊ | 107/121 [02:16<00:17,  1.26s/it]2025-04-24 19:57:02,204 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:03,609 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:03,612 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  89%|████████▉ | 108/121 [02:17<00:16,  1.30s/it]2025-04-24 19:57:03,614 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:04,720 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:04,723 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  90%|█████████ | 109/121 [02:18<00:14,  1.25s/it]2025-04-24 19:57:04,725 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:05,619 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:05,621 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  91%|█████████ | 110/121 [02:19<00:12,  1.14s/it]2025-04-24 19:57:05,624 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:07,406 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:07,410 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  92%|█████████▏| 111/121 [02:21<00:13,  1.34s/it]2025-04-24 19:57:07,412 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:08,883 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:08,886 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  93%|█████████▎| 112/121 [02:23<00:12,  1.38s/it]2025-04-24 19:57:08,888 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:09,959 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:09,963 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  93%|█████████▎| 113/121 [02:24<00:10,  1.29s/it]2025-04-24 19:57:09,964 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:11,556 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:11,560 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  94%|█████████▍| 114/121 [02:25<00:09,  1.38s/it]2025-04-24 19:57:11,562 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:12,820 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:12,823 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  95%|█████████▌| 115/121 [02:26<00:08,  1.35s/it]2025-04-24 19:57:12,825 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:14,063 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:14,065 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  96%|█████████▌| 116/121 [02:28<00:06,  1.31s/it]2025-04-24 19:57:14,067 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:15,425 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:15,428 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  97%|█████████▋| 117/121 [02:29<00:05,  1.33s/it]2025-04-24 19:57:15,431 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:16,284 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:16,287 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  98%|█████████▊| 118/121 [02:30<00:03,  1.19s/it]2025-04-24 19:57:16,289 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:17,062 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:17,065 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  98%|█████████▊| 119/121 [02:31<00:02,  1.06s/it]2025-04-24 19:57:17,067 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:18,080 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:18,084 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting:  99%|█████████▉| 120/121 [02:32<00:01,  1.05s/it]2025-04-24 19:57:18,086 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:19,555 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:19,558 - INFO - AFC remote call 1 is done.\n",
      "sycophancy: extracting: 100%|██████████| 121/121 [02:33<00:00,  1.27s/it]\n",
      "2025-04-24 19:57:19,565 - INFO - saved → data/mmlu/DeepSeek-R1-Distill-Llama-8B/sycophancy/core_steps_with_500.json  (121 items)\n",
      "2025-04-24 19:57:19,565 - INFO - Extracting core steps for unethical_information / DeepSeek-R1-Distill-Llama-8B\n",
      "unethical_information: extracting:   0%|          | 0/142 [00:00<?, ?it/s]2025-04-24 19:57:19,576 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:20,820 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:20,823 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:   1%|          | 1/142 [00:01<02:55,  1.25s/it]2025-04-24 19:57:20,824 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:21,587 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:21,591 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:   1%|▏         | 2/142 [00:02<02:15,  1.04it/s]2025-04-24 19:57:21,592 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:22,843 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:22,847 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:   2%|▏         | 3/142 [00:03<02:32,  1.10s/it]2025-04-24 19:57:22,849 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:24,343 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:24,346 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:   3%|▎         | 4/142 [00:04<02:53,  1.26s/it]2025-04-24 19:57:24,348 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:25,384 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:25,386 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:   4%|▎         | 5/142 [00:05<02:41,  1.18s/it]2025-04-24 19:57:25,388 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:26,926 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:26,929 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:   4%|▍         | 6/142 [00:07<02:57,  1.30s/it]2025-04-24 19:57:26,931 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:28,216 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:28,219 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:   5%|▍         | 7/142 [00:08<02:55,  1.30s/it]2025-04-24 19:57:28,221 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:29,944 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:29,947 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:   6%|▌         | 8/142 [00:10<03:12,  1.44s/it]2025-04-24 19:57:29,949 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:30,846 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:30,849 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:   6%|▋         | 9/142 [00:11<02:48,  1.27s/it]2025-04-24 19:57:30,851 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:32,132 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:32,135 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:   7%|▋         | 10/142 [00:12<02:48,  1.27s/it]2025-04-24 19:57:32,137 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:33,141 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:33,144 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:   8%|▊         | 11/142 [00:13<02:36,  1.19s/it]2025-04-24 19:57:33,145 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:34,357 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:34,360 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:   8%|▊         | 12/142 [00:14<02:35,  1.20s/it]2025-04-24 19:57:34,362 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:35,738 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:35,741 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:   9%|▉         | 13/142 [00:16<02:41,  1.25s/it]2025-04-24 19:57:35,743 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:36,832 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:36,835 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  10%|▉         | 14/142 [00:17<02:34,  1.21s/it]2025-04-24 19:57:36,836 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:38,434 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:38,438 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  11%|█         | 15/142 [00:18<02:48,  1.33s/it]2025-04-24 19:57:38,439 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:39,312 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:39,315 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  11%|█▏        | 16/142 [00:19<02:30,  1.19s/it]2025-04-24 19:57:39,317 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:40,789 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:40,792 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  12%|█▏        | 17/142 [00:21<02:39,  1.28s/it]2025-04-24 19:57:40,794 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:42,088 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:42,091 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  13%|█▎        | 18/142 [00:22<02:39,  1.28s/it]2025-04-24 19:57:42,093 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:43,816 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:43,819 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  13%|█▎        | 19/142 [00:24<02:54,  1.42s/it]2025-04-24 19:57:43,821 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:44,781 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:44,784 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  14%|█▍        | 20/142 [00:25<02:36,  1.28s/it]2025-04-24 19:57:44,786 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:46,626 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:46,628 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  15%|█▍        | 21/142 [00:27<02:55,  1.45s/it]2025-04-24 19:57:46,630 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:47,479 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:47,484 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  15%|█▌        | 22/142 [00:27<02:32,  1.27s/it]2025-04-24 19:57:47,485 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:48,775 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:48,778 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  16%|█▌        | 23/142 [00:29<02:32,  1.28s/it]2025-04-24 19:57:48,780 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:49,819 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:49,822 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  17%|█▋        | 24/142 [00:30<02:22,  1.21s/it]2025-04-24 19:57:49,826 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:51,241 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:51,244 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  18%|█▊        | 25/142 [00:31<02:28,  1.27s/it]2025-04-24 19:57:51,246 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:52,553 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:52,556 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  18%|█▊        | 26/142 [00:32<02:28,  1.28s/it]2025-04-24 19:57:52,558 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:53,700 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:53,703 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  19%|█▉        | 27/142 [00:34<02:22,  1.24s/it]2025-04-24 19:57:53,705 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:55,026 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:55,028 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  20%|█▉        | 28/142 [00:35<02:24,  1.27s/it]2025-04-24 19:57:55,030 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:56,421 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:56,424 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  20%|██        | 29/142 [00:36<02:27,  1.31s/it]2025-04-24 19:57:56,427 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:58,065 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:58,068 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  21%|██        | 30/142 [00:38<02:37,  1.41s/it]2025-04-24 19:57:58,071 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:57:59,391 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:57:59,395 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  22%|██▏       | 31/142 [00:39<02:33,  1.38s/it]2025-04-24 19:57:59,396 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:00,664 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:00,667 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  23%|██▎       | 32/142 [00:41<02:28,  1.35s/it]2025-04-24 19:58:00,669 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:02,136 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:02,139 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  23%|██▎       | 33/142 [00:42<02:31,  1.39s/it]2025-04-24 19:58:02,142 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:03,252 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:03,256 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  24%|██▍       | 34/142 [00:43<02:20,  1.31s/it]2025-04-24 19:58:03,258 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:04,478 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:04,481 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  25%|██▍       | 35/142 [00:44<02:17,  1.28s/it]2025-04-24 19:58:04,483 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:05,847 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:05,849 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  25%|██▌       | 36/142 [00:46<02:18,  1.31s/it]2025-04-24 19:58:05,851 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:06,780 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:06,782 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  26%|██▌       | 37/142 [00:47<02:05,  1.20s/it]2025-04-24 19:58:06,784 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:08,836 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:08,839 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  27%|██▋       | 38/142 [00:49<02:31,  1.45s/it]2025-04-24 19:58:08,841 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:09,700 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:09,703 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  27%|██▋       | 39/142 [00:50<02:11,  1.28s/it]2025-04-24 19:58:09,705 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:10,717 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:10,721 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  28%|██▊       | 40/142 [00:51<02:02,  1.20s/it]2025-04-24 19:58:10,723 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:11,575 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:11,578 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  29%|██▉       | 41/142 [00:52<01:50,  1.10s/it]2025-04-24 19:58:11,580 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:12,578 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:12,582 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  30%|██▉       | 42/142 [00:53<01:46,  1.07s/it]2025-04-24 19:58:12,584 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:13,514 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:13,517 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  30%|███       | 43/142 [00:53<01:41,  1.03s/it]2025-04-24 19:58:13,519 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:15,061 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:15,064 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  31%|███       | 44/142 [00:55<01:56,  1.18s/it]2025-04-24 19:58:15,067 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:16,598 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:16,602 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  32%|███▏      | 45/142 [00:57<02:05,  1.29s/it]2025-04-24 19:58:16,604 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:17,802 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:17,804 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  32%|███▏      | 46/142 [00:58<02:01,  1.26s/it]2025-04-24 19:58:17,806 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:18,969 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:18,972 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  33%|███▎      | 47/142 [00:59<01:57,  1.23s/it]2025-04-24 19:58:18,974 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:19,748 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:19,752 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  34%|███▍      | 48/142 [01:00<01:43,  1.10s/it]2025-04-24 19:58:19,753 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:20,837 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:20,840 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  35%|███▍      | 49/142 [01:01<01:41,  1.10s/it]2025-04-24 19:58:20,842 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:21,675 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:21,678 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  35%|███▌      | 50/142 [01:02<01:33,  1.02s/it]2025-04-24 19:58:21,679 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:22,411 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:22,414 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  36%|███▌      | 51/142 [01:02<01:24,  1.07it/s]2025-04-24 19:58:22,416 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:23,616 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:23,620 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  37%|███▋      | 52/142 [01:04<01:31,  1.02s/it]2025-04-24 19:58:23,622 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:24,930 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:24,933 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  37%|███▋      | 53/142 [01:05<01:38,  1.10s/it]2025-04-24 19:58:24,935 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:25,926 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:25,930 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  38%|███▊      | 54/142 [01:06<01:34,  1.07s/it]2025-04-24 19:58:25,933 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:27,158 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:27,161 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  39%|███▊      | 55/142 [01:07<01:37,  1.12s/it]2025-04-24 19:58:27,163 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:28,107 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:28,109 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  39%|███▉      | 56/142 [01:08<01:31,  1.07s/it]2025-04-24 19:58:28,111 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:29,261 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:29,265 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  40%|████      | 57/142 [01:09<01:33,  1.09s/it]2025-04-24 19:58:29,267 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:30,495 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:30,499 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  41%|████      | 58/142 [01:10<01:35,  1.14s/it]2025-04-24 19:58:30,501 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:32,238 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:32,241 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  42%|████▏     | 59/142 [01:12<01:49,  1.32s/it]2025-04-24 19:58:32,243 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:34,378 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:34,381 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  42%|████▏     | 60/142 [01:14<02:08,  1.56s/it]2025-04-24 19:58:34,383 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:35,643 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:35,646 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  43%|████▎     | 61/142 [01:16<01:59,  1.47s/it]2025-04-24 19:58:35,649 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:37,080 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:37,082 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  44%|████▎     | 62/142 [01:17<01:57,  1.46s/it]2025-04-24 19:58:37,084 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:38,008 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:38,011 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  44%|████▍     | 63/142 [01:18<01:42,  1.30s/it]2025-04-24 19:58:38,013 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:39,177 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:39,181 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  45%|████▌     | 64/142 [01:19<01:38,  1.26s/it]2025-04-24 19:58:39,183 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:40,844 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:40,847 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  46%|████▌     | 65/142 [01:21<01:46,  1.38s/it]2025-04-24 19:58:40,850 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:42,372 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:42,376 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  46%|████▋     | 66/142 [01:22<01:48,  1.43s/it]2025-04-24 19:58:42,378 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:43,457 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:43,460 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  47%|████▋     | 67/142 [01:23<01:39,  1.32s/it]2025-04-24 19:58:43,462 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:44,505 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:44,508 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  48%|████▊     | 68/142 [01:24<01:31,  1.24s/it]2025-04-24 19:58:44,510 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:45,801 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:45,804 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  49%|████▊     | 69/142 [01:26<01:31,  1.26s/it]2025-04-24 19:58:45,806 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:46,816 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:46,819 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  49%|████▉     | 70/142 [01:27<01:25,  1.18s/it]2025-04-24 19:58:46,821 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:48,111 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:48,113 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  50%|█████     | 71/142 [01:28<01:26,  1.22s/it]2025-04-24 19:58:48,115 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:49,045 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:49,047 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  51%|█████     | 72/142 [01:29<01:19,  1.13s/it]2025-04-24 19:58:49,048 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:49,811 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:49,813 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  51%|█████▏    | 73/142 [01:30<01:10,  1.02s/it]2025-04-24 19:58:49,815 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:51,195 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:51,198 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  52%|█████▏    | 74/142 [01:31<01:16,  1.13s/it]2025-04-24 19:58:51,200 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:52,037 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:52,040 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  53%|█████▎    | 75/142 [01:32<01:09,  1.04s/it]2025-04-24 19:58:52,043 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:53,537 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:53,541 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  54%|█████▎    | 76/142 [01:33<01:17,  1.18s/it]2025-04-24 19:58:53,542 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:54,477 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:54,481 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  54%|█████▍    | 77/142 [01:34<01:12,  1.11s/it]2025-04-24 19:58:54,483 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:55,728 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:55,731 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  55%|█████▍    | 78/142 [01:36<01:13,  1.15s/it]2025-04-24 19:58:55,733 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:57,142 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:57,146 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  56%|█████▌    | 79/142 [01:37<01:17,  1.23s/it]2025-04-24 19:58:57,148 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:58,573 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:58,577 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  56%|█████▋    | 80/142 [01:39<01:20,  1.29s/it]2025-04-24 19:58:58,579 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:58:59,902 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:58:59,904 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  57%|█████▋    | 81/142 [01:40<01:19,  1.30s/it]2025-04-24 19:58:59,906 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:01,297 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:01,300 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  58%|█████▊    | 82/142 [01:41<01:19,  1.33s/it]2025-04-24 19:59:01,302 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:02,296 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:02,299 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  58%|█████▊    | 83/142 [01:42<01:12,  1.23s/it]2025-04-24 19:59:02,301 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:03,302 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:03,305 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  59%|█████▉    | 84/142 [01:43<01:07,  1.16s/it]2025-04-24 19:59:03,307 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:04,377 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:04,380 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  60%|█████▉    | 85/142 [01:44<01:04,  1.14s/it]2025-04-24 19:59:04,382 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:05,844 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:05,848 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  61%|██████    | 86/142 [01:46<01:09,  1.24s/it]2025-04-24 19:59:05,849 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:06,831 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:06,834 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  61%|██████▏   | 87/142 [01:47<01:03,  1.16s/it]2025-04-24 19:59:06,836 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:07,704 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:07,707 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  62%|██████▏   | 88/142 [01:48<00:58,  1.07s/it]2025-04-24 19:59:07,709 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:09,261 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:09,265 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  63%|██████▎   | 89/142 [01:49<01:04,  1.22s/it]2025-04-24 19:59:09,267 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:10,504 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:10,508 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  63%|██████▎   | 90/142 [01:50<01:03,  1.23s/it]2025-04-24 19:59:10,510 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:11,447 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:11,450 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  64%|██████▍   | 91/142 [01:51<00:58,  1.14s/it]2025-04-24 19:59:11,452 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:12,408 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:12,411 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  65%|██████▍   | 92/142 [01:52<00:54,  1.09s/it]2025-04-24 19:59:12,413 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:13,784 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:13,788 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  65%|██████▌   | 93/142 [01:54<00:57,  1.17s/it]2025-04-24 19:59:13,790 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:15,346 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:15,350 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  66%|██████▌   | 94/142 [01:55<01:01,  1.29s/it]2025-04-24 19:59:15,352 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:16,383 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:16,387 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  67%|██████▋   | 95/142 [01:56<00:57,  1.21s/it]2025-04-24 19:59:16,388 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:17,740 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:17,744 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  68%|██████▊   | 96/142 [01:58<00:57,  1.26s/it]2025-04-24 19:59:17,745 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:19,128 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:19,131 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  68%|██████▊   | 97/142 [01:59<00:58,  1.30s/it]2025-04-24 19:59:19,133 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:20,334 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:20,337 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  69%|██████▉   | 98/142 [02:00<00:55,  1.27s/it]2025-04-24 19:59:20,339 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:22,056 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:22,060 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  70%|██████▉   | 99/142 [02:02<01:00,  1.41s/it]2025-04-24 19:59:22,062 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:23,328 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:23,331 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  70%|███████   | 100/142 [02:03<00:57,  1.37s/it]2025-04-24 19:59:23,333 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:24,340 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:24,343 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  71%|███████   | 101/142 [02:04<00:51,  1.26s/it]2025-04-24 19:59:24,345 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:25,544 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:25,548 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  72%|███████▏  | 102/142 [02:05<00:49,  1.24s/it]2025-04-24 19:59:25,550 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:27,364 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:27,368 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  73%|███████▎  | 103/142 [02:07<00:55,  1.42s/it]2025-04-24 19:59:27,370 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:28,773 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:28,777 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  73%|███████▎  | 104/142 [02:09<00:53,  1.41s/it]2025-04-24 19:59:28,779 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:29,996 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:29,999 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  74%|███████▍  | 105/142 [02:10<00:50,  1.36s/it]2025-04-24 19:59:30,001 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:31,418 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:31,422 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  75%|███████▍  | 106/142 [02:11<00:49,  1.38s/it]2025-04-24 19:59:31,423 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:32,646 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:32,648 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  75%|███████▌  | 107/142 [02:13<00:46,  1.33s/it]2025-04-24 19:59:32,650 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:33,695 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:33,698 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  76%|███████▌  | 108/142 [02:14<00:42,  1.25s/it]2025-04-24 19:59:33,700 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:34,710 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:34,713 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  77%|███████▋  | 109/142 [02:15<00:38,  1.18s/it]2025-04-24 19:59:34,715 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:35,484 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:35,488 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  77%|███████▋  | 110/142 [02:15<00:33,  1.06s/it]2025-04-24 19:59:35,489 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:36,602 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:36,605 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  78%|███████▊  | 111/142 [02:17<00:33,  1.07s/it]2025-04-24 19:59:36,607 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:37,519 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:37,522 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  79%|███████▉  | 112/142 [02:17<00:30,  1.03s/it]2025-04-24 19:59:37,524 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:39,089 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:39,092 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  80%|███████▉  | 113/142 [02:19<00:34,  1.19s/it]2025-04-24 19:59:39,094 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:39,989 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:39,992 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  80%|████████  | 114/142 [02:20<00:30,  1.10s/it]2025-04-24 19:59:39,994 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:41,669 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:41,672 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  81%|████████  | 115/142 [02:22<00:34,  1.28s/it]2025-04-24 19:59:41,675 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:42,911 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:42,915 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  82%|████████▏ | 116/142 [02:23<00:32,  1.27s/it]2025-04-24 19:59:42,917 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:44,380 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:44,383 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  82%|████████▏ | 117/142 [02:24<00:33,  1.33s/it]2025-04-24 19:59:44,385 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:45,771 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:45,774 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  83%|████████▎ | 118/142 [02:26<00:32,  1.35s/it]2025-04-24 19:59:45,776 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:46,594 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:46,598 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  84%|████████▍ | 119/142 [02:27<00:27,  1.19s/it]2025-04-24 19:59:46,600 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:48,062 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:48,065 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  85%|████████▍ | 120/142 [02:28<00:27,  1.27s/it]2025-04-24 19:59:48,066 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:49,054 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:49,058 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  85%|████████▌ | 121/142 [02:29<00:24,  1.19s/it]2025-04-24 19:59:49,060 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:50,100 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:50,103 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  86%|████████▌ | 122/142 [02:30<00:22,  1.15s/it]2025-04-24 19:59:50,105 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:51,051 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:51,054 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  87%|████████▋ | 123/142 [02:31<00:20,  1.09s/it]2025-04-24 19:59:51,056 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:52,099 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:52,102 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  87%|████████▋ | 124/142 [02:32<00:19,  1.08s/it]2025-04-24 19:59:52,104 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:53,364 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:53,370 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  88%|████████▊ | 125/142 [02:33<00:19,  1.13s/it]2025-04-24 19:59:53,372 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:55,119 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:55,121 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  89%|████████▊ | 126/142 [02:35<00:21,  1.32s/it]2025-04-24 19:59:55,124 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:56,089 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:56,092 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  89%|████████▉ | 127/142 [02:36<00:18,  1.21s/it]2025-04-24 19:59:56,094 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:57,077 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:57,080 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  90%|█████████ | 128/142 [02:37<00:16,  1.15s/it]2025-04-24 19:59:57,082 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:59,001 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:59,004 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  91%|█████████ | 129/142 [02:39<00:17,  1.38s/it]2025-04-24 19:59:59,006 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 19:59:59,990 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 19:59:59,993 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  92%|█████████▏| 130/142 [02:40<00:15,  1.26s/it]2025-04-24 19:59:59,995 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:01,124 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:01,127 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  92%|█████████▏| 131/142 [02:41<00:13,  1.22s/it]2025-04-24 20:00:01,129 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:02,557 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:02,561 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  93%|█████████▎| 132/142 [02:42<00:12,  1.29s/it]2025-04-24 20:00:02,563 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:03,986 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:03,990 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  94%|█████████▎| 133/142 [02:44<00:11,  1.33s/it]2025-04-24 20:00:03,992 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:05,113 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:05,116 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  94%|█████████▍| 134/142 [02:45<00:10,  1.27s/it]2025-04-24 20:00:05,118 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:06,282 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:06,286 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  95%|█████████▌| 135/142 [02:46<00:08,  1.24s/it]2025-04-24 20:00:06,287 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:08,009 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:08,012 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  96%|█████████▌| 136/142 [02:48<00:08,  1.39s/it]2025-04-24 20:00:08,014 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:09,239 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:09,242 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  96%|█████████▋| 137/142 [02:49<00:06,  1.34s/it]2025-04-24 20:00:09,244 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:10,402 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:10,405 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  97%|█████████▋| 138/142 [02:50<00:05,  1.29s/it]2025-04-24 20:00:10,407 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:11,837 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:11,841 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  98%|█████████▊| 139/142 [02:52<00:03,  1.33s/it]2025-04-24 20:00:11,843 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:13,130 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:13,134 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  99%|█████████▊| 140/142 [02:53<00:02,  1.32s/it]2025-04-24 20:00:13,135 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:14,114 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:14,118 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting:  99%|█████████▉| 141/142 [02:54<00:01,  1.22s/it]2025-04-24 20:00:14,120 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:15,314 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:15,317 - INFO - AFC remote call 1 is done.\n",
      "unethical_information: extracting: 100%|██████████| 142/142 [02:55<00:00,  1.24s/it]\n",
      "2025-04-24 20:00:15,324 - INFO - saved → data/mmlu/DeepSeek-R1-Distill-Llama-8B/unethical_information/core_steps_with_500.json  (142 items)\n",
      "2025-04-24 20:00:15,324 - INFO - Extracting core steps for induced_urgency / DeepSeek-R1-Distill-Llama-8B\n",
      "induced_urgency: extracting:   0%|          | 0/114 [00:00<?, ?it/s]2025-04-24 20:00:15,336 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:16,399 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:16,402 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:   1%|          | 1/114 [00:01<02:00,  1.07s/it]2025-04-24 20:00:16,404 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:17,406 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:17,409 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:   2%|▏         | 2/114 [00:02<01:55,  1.03s/it]2025-04-24 20:00:17,411 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:18,204 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:18,207 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:   3%|▎         | 3/114 [00:02<01:42,  1.08it/s]2025-04-24 20:00:18,209 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:19,368 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:19,371 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:   4%|▎         | 4/114 [00:04<01:52,  1.02s/it]2025-04-24 20:00:19,373 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:20,409 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:20,414 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:   4%|▍         | 5/114 [00:05<01:52,  1.03s/it]2025-04-24 20:00:20,415 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:21,258 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:21,262 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:   5%|▌         | 6/114 [00:05<01:44,  1.03it/s]2025-04-24 20:00:21,264 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:21,986 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:21,989 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:   6%|▌         | 7/114 [00:06<01:35,  1.13it/s]2025-04-24 20:00:21,991 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:23,440 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:23,443 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:   7%|▋         | 8/114 [00:08<01:53,  1.07s/it]2025-04-24 20:00:23,445 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:24,897 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:24,900 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:   8%|▊         | 9/114 [00:09<02:04,  1.19s/it]2025-04-24 20:00:24,902 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:25,763 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:25,766 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:   9%|▉         | 10/114 [00:10<01:53,  1.09s/it]2025-04-24 20:00:25,768 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:26,999 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:27,002 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  10%|▉         | 11/114 [00:11<01:56,  1.13s/it]2025-04-24 20:00:27,004 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:28,325 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:28,328 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  11%|█         | 12/114 [00:12<02:01,  1.19s/it]2025-04-24 20:00:28,330 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:29,810 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:29,813 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  11%|█▏        | 13/114 [00:14<02:09,  1.28s/it]2025-04-24 20:00:29,815 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:30,854 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:30,857 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  12%|█▏        | 14/114 [00:15<02:00,  1.21s/it]2025-04-24 20:00:30,859 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:32,295 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:32,298 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  13%|█▎        | 15/114 [00:16<02:06,  1.28s/it]2025-04-24 20:00:32,300 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:33,595 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:33,599 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  14%|█▍        | 16/114 [00:18<02:06,  1.29s/it]2025-04-24 20:00:33,601 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:34,753 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:34,757 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  15%|█▍        | 17/114 [00:19<02:00,  1.25s/it]2025-04-24 20:00:34,759 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:36,160 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:36,164 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  16%|█▌        | 18/114 [00:20<02:04,  1.30s/it]2025-04-24 20:00:36,166 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:37,044 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:37,047 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  17%|█▋        | 19/114 [00:21<01:51,  1.17s/it]2025-04-24 20:00:37,048 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:38,105 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:38,108 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  18%|█▊        | 20/114 [00:22<01:47,  1.14s/it]2025-04-24 20:00:38,111 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:39,801 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:39,804 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  18%|█▊        | 21/114 [00:24<02:01,  1.31s/it]2025-04-24 20:00:39,806 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:41,328 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:41,331 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  19%|█▉        | 22/114 [00:25<02:06,  1.37s/it]2025-04-24 20:00:41,333 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:42,928 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:42,932 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  20%|██        | 23/114 [00:27<02:11,  1.44s/it]2025-04-24 20:00:42,933 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:43,730 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:43,733 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  21%|██        | 24/114 [00:28<01:52,  1.25s/it]2025-04-24 20:00:43,735 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:45,032 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:45,036 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  22%|██▏       | 25/114 [00:29<01:52,  1.26s/it]2025-04-24 20:00:45,037 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:46,101 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:46,103 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  23%|██▎       | 26/114 [00:30<01:46,  1.21s/it]2025-04-24 20:00:46,105 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:47,282 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:47,285 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  24%|██▎       | 27/114 [00:31<01:44,  1.20s/it]2025-04-24 20:00:47,287 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:48,414 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:48,417 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  25%|██▍       | 28/114 [00:33<01:41,  1.18s/it]2025-04-24 20:00:48,419 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:49,458 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:49,461 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  25%|██▌       | 29/114 [00:34<01:36,  1.14s/it]2025-04-24 20:00:49,462 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:50,790 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:50,794 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  26%|██▋       | 30/114 [00:35<01:40,  1.20s/it]2025-04-24 20:00:50,796 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:52,240 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:52,243 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  27%|██▋       | 31/114 [00:36<01:45,  1.27s/it]2025-04-24 20:00:52,245 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:53,337 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:53,339 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  28%|██▊       | 32/114 [00:38<01:40,  1.22s/it]2025-04-24 20:00:53,341 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:54,448 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:54,452 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  29%|██▉       | 33/114 [00:39<01:36,  1.19s/it]2025-04-24 20:00:54,454 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:55,722 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:55,725 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  30%|██▉       | 34/114 [00:40<01:37,  1.21s/it]2025-04-24 20:00:55,727 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:56,597 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:56,599 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  31%|███       | 35/114 [00:41<01:27,  1.11s/it]2025-04-24 20:00:56,601 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:57,308 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:57,311 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  32%|███▏      | 36/114 [00:41<01:17,  1.01it/s]2025-04-24 20:00:57,313 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:00:58,862 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:00:58,866 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  32%|███▏      | 37/114 [00:43<01:29,  1.16s/it]2025-04-24 20:00:58,868 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:00,107 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:00,111 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  33%|███▎      | 38/114 [00:44<01:30,  1.19s/it]2025-04-24 20:01:00,113 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:01,138 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:01,142 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  34%|███▍      | 39/114 [00:45<01:25,  1.14s/it]2025-04-24 20:01:01,144 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:02,018 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:02,021 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  35%|███▌      | 40/114 [00:46<01:18,  1.06s/it]2025-04-24 20:01:02,023 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:03,024 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:03,028 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  36%|███▌      | 41/114 [00:47<01:16,  1.04s/it]2025-04-24 20:01:03,030 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:03,992 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:03,995 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  37%|███▋      | 42/114 [00:48<01:13,  1.02s/it]2025-04-24 20:01:03,997 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:05,080 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:05,083 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  38%|███▊      | 43/114 [00:49<01:13,  1.04s/it]2025-04-24 20:01:05,085 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:06,415 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:06,418 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  39%|███▊      | 44/114 [00:51<01:19,  1.13s/it]2025-04-24 20:01:06,420 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:07,774 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:07,779 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  39%|███▉      | 45/114 [00:52<01:22,  1.20s/it]2025-04-24 20:01:07,781 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:08,608 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:08,612 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  40%|████      | 46/114 [00:53<01:14,  1.09s/it]2025-04-24 20:01:08,614 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:09,498 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:09,502 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  41%|████      | 47/114 [00:54<01:08,  1.03s/it]2025-04-24 20:01:09,504 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:10,704 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:10,708 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  42%|████▏     | 48/114 [00:55<01:11,  1.08s/it]2025-04-24 20:01:10,710 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:11,712 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:11,715 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  43%|████▎     | 49/114 [00:56<01:08,  1.06s/it]2025-04-24 20:01:11,717 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:13,188 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:13,192 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  44%|████▍     | 50/114 [00:57<01:15,  1.18s/it]2025-04-24 20:01:13,194 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:14,155 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:14,158 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  45%|████▍     | 51/114 [00:58<01:10,  1.12s/it]2025-04-24 20:01:14,160 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:15,557 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:15,560 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  46%|████▌     | 52/114 [01:00<01:14,  1.20s/it]2025-04-24 20:01:15,562 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:16,487 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:16,490 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  46%|████▋     | 53/114 [01:01<01:08,  1.12s/it]2025-04-24 20:01:16,492 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:17,555 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:17,559 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  47%|████▋     | 54/114 [01:02<01:06,  1.11s/it]2025-04-24 20:01:17,561 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:18,700 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:18,703 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  48%|████▊     | 55/114 [01:03<01:05,  1.12s/it]2025-04-24 20:01:18,705 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:19,985 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:19,988 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  49%|████▉     | 56/114 [01:04<01:07,  1.17s/it]2025-04-24 20:01:19,990 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:21,572 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:21,576 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  50%|█████     | 57/114 [01:06<01:13,  1.29s/it]2025-04-24 20:01:21,578 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:22,763 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:22,766 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  51%|█████     | 58/114 [01:07<01:10,  1.26s/it]2025-04-24 20:01:22,768 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:23,941 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:23,945 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  52%|█████▏    | 59/114 [01:08<01:08,  1.24s/it]2025-04-24 20:01:23,947 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:24,990 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:24,993 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  53%|█████▎    | 60/114 [01:09<01:03,  1.18s/it]2025-04-24 20:01:24,995 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:25,941 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:25,944 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  54%|█████▎    | 61/114 [01:10<00:58,  1.11s/it]2025-04-24 20:01:25,946 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:27,197 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:27,201 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  54%|█████▍    | 62/114 [01:11<01:00,  1.16s/it]2025-04-24 20:01:27,202 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:28,741 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:28,744 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  55%|█████▌    | 63/114 [01:13<01:04,  1.27s/it]2025-04-24 20:01:28,746 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:29,711 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:29,715 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  56%|█████▌    | 64/114 [01:14<00:59,  1.18s/it]2025-04-24 20:01:29,717 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:31,152 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:31,156 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  57%|█████▋    | 65/114 [01:15<01:01,  1.26s/it]2025-04-24 20:01:31,158 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:32,416 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:32,419 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  58%|█████▊    | 66/114 [01:17<01:00,  1.26s/it]2025-04-24 20:01:32,421 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:33,403 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:33,407 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  59%|█████▉    | 67/114 [01:18<00:55,  1.18s/it]2025-04-24 20:01:33,409 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:34,857 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:34,861 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  60%|█████▉    | 68/114 [01:19<00:58,  1.26s/it]2025-04-24 20:01:34,863 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:36,496 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:36,500 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  61%|██████    | 69/114 [01:21<01:01,  1.37s/it]2025-04-24 20:01:36,502 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:37,534 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:37,536 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  61%|██████▏   | 70/114 [01:22<00:56,  1.27s/it]2025-04-24 20:01:37,539 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:38,612 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:38,616 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  62%|██████▏   | 71/114 [01:23<00:52,  1.21s/it]2025-04-24 20:01:38,617 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:40,274 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:40,279 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  63%|██████▎   | 72/114 [01:24<00:56,  1.35s/it]2025-04-24 20:01:40,281 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:41,763 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:41,767 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  64%|██████▍   | 73/114 [01:26<00:57,  1.39s/it]2025-04-24 20:01:41,768 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:42,821 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:42,824 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  65%|██████▍   | 74/114 [01:27<00:51,  1.29s/it]2025-04-24 20:01:42,825 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:43,963 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:43,967 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  66%|██████▌   | 75/114 [01:28<00:48,  1.25s/it]2025-04-24 20:01:43,969 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:45,030 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:45,033 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  67%|██████▋   | 76/114 [01:29<00:45,  1.19s/it]2025-04-24 20:01:45,035 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:45,832 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:45,835 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  68%|██████▊   | 77/114 [01:30<00:39,  1.08s/it]2025-04-24 20:01:45,837 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:46,868 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:46,871 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  68%|██████▊   | 78/114 [01:31<00:38,  1.06s/it]2025-04-24 20:01:46,873 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:48,175 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:48,178 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  69%|██████▉   | 79/114 [01:32<00:39,  1.14s/it]2025-04-24 20:01:48,180 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:49,430 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:49,434 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  70%|███████   | 80/114 [01:34<00:39,  1.17s/it]2025-04-24 20:01:49,436 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:50,191 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:50,194 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  71%|███████   | 81/114 [01:34<00:34,  1.05s/it]2025-04-24 20:01:50,196 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:51,225 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:51,228 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  72%|███████▏  | 82/114 [01:35<00:33,  1.04s/it]2025-04-24 20:01:51,230 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:52,438 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:52,441 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  73%|███████▎  | 83/114 [01:37<00:33,  1.09s/it]2025-04-24 20:01:52,443 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:53,537 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:53,540 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  74%|███████▎  | 84/114 [01:38<00:32,  1.10s/it]2025-04-24 20:01:53,541 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:54,620 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:54,624 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  75%|███████▍  | 85/114 [01:39<00:31,  1.09s/it]2025-04-24 20:01:54,626 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:55,641 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:55,644 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  75%|███████▌  | 86/114 [01:40<00:29,  1.07s/it]2025-04-24 20:01:55,646 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:57,175 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:57,178 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  76%|███████▋  | 87/114 [01:41<00:32,  1.21s/it]2025-04-24 20:01:57,180 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:57,974 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:57,976 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  77%|███████▋  | 88/114 [01:42<00:28,  1.09s/it]2025-04-24 20:01:57,978 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:01:58,852 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:01:58,856 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  78%|███████▊  | 89/114 [01:43<00:25,  1.02s/it]2025-04-24 20:01:58,858 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:00,232 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:00,235 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  79%|███████▉  | 90/114 [01:44<00:27,  1.13s/it]2025-04-24 20:02:00,237 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:01,575 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:01,578 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  80%|███████▉  | 91/114 [01:46<00:27,  1.19s/it]2025-04-24 20:02:01,580 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:02,633 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:02,635 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  81%|████████  | 92/114 [01:47<00:25,  1.15s/it]2025-04-24 20:02:02,637 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:03,520 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:03,523 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  82%|████████▏ | 93/114 [01:48<00:22,  1.07s/it]2025-04-24 20:02:03,525 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:04,989 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:04,993 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  82%|████████▏ | 94/114 [01:49<00:23,  1.19s/it]2025-04-24 20:02:04,995 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:06,568 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:06,571 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  83%|████████▎ | 95/114 [01:51<00:24,  1.31s/it]2025-04-24 20:02:06,573 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:07,705 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:07,708 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  84%|████████▍ | 96/114 [01:52<00:22,  1.26s/it]2025-04-24 20:02:07,710 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:08,737 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:08,740 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  85%|████████▌ | 97/114 [01:53<00:20,  1.19s/it]2025-04-24 20:02:08,742 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:09,623 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:09,626 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  86%|████████▌ | 98/114 [01:54<00:17,  1.10s/it]2025-04-24 20:02:09,628 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:10,596 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:10,599 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  87%|████████▋ | 99/114 [01:55<00:15,  1.06s/it]2025-04-24 20:02:10,601 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:11,714 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:11,716 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  88%|████████▊ | 100/114 [01:56<00:15,  1.08s/it]2025-04-24 20:02:11,718 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:12,559 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:12,562 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  89%|████████▊ | 101/114 [01:57<00:13,  1.01s/it]2025-04-24 20:02:12,565 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:13,788 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:13,791 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  89%|████████▉ | 102/114 [01:58<00:12,  1.07s/it]2025-04-24 20:02:13,793 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:15,070 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:15,073 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  90%|█████████ | 103/114 [01:59<00:12,  1.14s/it]2025-04-24 20:02:15,075 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:16,582 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:16,586 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  91%|█████████ | 104/114 [02:01<00:12,  1.25s/it]2025-04-24 20:02:16,588 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:17,670 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:17,674 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  92%|█████████▏| 105/114 [02:02<00:10,  1.20s/it]2025-04-24 20:02:17,676 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:18,966 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:18,969 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  93%|█████████▎| 106/114 [02:03<00:09,  1.23s/it]2025-04-24 20:02:18,971 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:20,689 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:20,692 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  94%|█████████▍| 107/114 [02:05<00:09,  1.38s/it]2025-04-24 20:02:20,694 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:21,715 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:21,718 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  95%|█████████▍| 108/114 [02:06<00:07,  1.27s/it]2025-04-24 20:02:21,719 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:23,207 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:23,210 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  96%|█████████▌| 109/114 [02:07<00:06,  1.34s/it]2025-04-24 20:02:23,212 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:24,125 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:24,128 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  96%|█████████▋| 110/114 [02:08<00:04,  1.21s/it]2025-04-24 20:02:24,130 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:25,651 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:25,654 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  97%|█████████▋| 111/114 [02:10<00:03,  1.31s/it]2025-04-24 20:02:25,656 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:26,419 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:26,422 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  98%|█████████▊| 112/114 [02:11<00:02,  1.14s/it]2025-04-24 20:02:26,424 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:27,786 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:27,789 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting:  99%|█████████▉| 113/114 [02:12<00:01,  1.21s/it]2025-04-24 20:02:27,791 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-04-24 20:02:28,455 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 20:02:28,457 - INFO - AFC remote call 1 is done.\n",
      "induced_urgency: extracting: 100%|██████████| 114/114 [02:13<00:00,  1.17s/it]\n",
      "2025-04-24 20:02:28,464 - INFO - saved → data/mmlu/DeepSeek-R1-Distill-Llama-8B/induced_urgency/core_steps_with_500.json  (114 items)\n"
     ]
    }
   ],
   "source": [
    "run_core_step_extraction(\n",
    "    dataset=DATASET,\n",
    "    hint_types=HINT_TYPES[1:],   # skip 'none'\n",
    "    model_name=model_name,\n",
    "    n_questions=N_QUESTIONS,\n",
    "    k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sycophancy: ablation:   0%|          | 0/121 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:   1%|          | 1/121 [00:01<03:05,  1.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:   2%|▏         | 2/121 [00:02<02:26,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:   2%|▏         | 3/121 [00:03<02:29,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:   3%|▎         | 4/121 [00:04<02:15,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:   4%|▍         | 5/121 [00:06<02:19,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:   5%|▍         | 6/121 [00:06<02:04,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:   6%|▌         | 7/121 [00:08<02:06,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:   7%|▋         | 8/121 [00:09<01:59,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:   7%|▋         | 9/121 [00:10<02:09,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:   8%|▊         | 10/121 [00:11<02:12,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:   9%|▉         | 11/121 [00:13<02:21,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  10%|▉         | 12/121 [00:14<02:15,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  11%|█         | 13/121 [00:15<02:12,  1.23s/it]2025-04-24 20:14:06,661 - WARNING - qid 62 skipped – core-step substring not found.\n",
      "2025-04-24 20:14:06,663 - INFO - 0 of 121 questions skipped for sycophancy\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  12%|█▏        | 15/121 [00:16<01:38,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  13%|█▎        | 16/121 [00:17<01:38,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  14%|█▍        | 17/121 [00:18<01:38,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  15%|█▍        | 18/121 [00:20<01:49,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  16%|█▌        | 19/121 [00:21<01:55,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  17%|█▋        | 20/121 [00:22<01:53,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  17%|█▋        | 21/121 [00:23<01:47,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  18%|█▊        | 22/121 [00:24<01:52,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  19%|█▉        | 23/121 [00:26<01:56,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  20%|█▉        | 24/121 [00:27<02:07,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  21%|██        | 25/121 [00:28<01:57,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  21%|██▏       | 26/121 [00:30<02:10,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  22%|██▏       | 27/121 [00:31<02:02,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  23%|██▎       | 28/121 [00:33<02:30,  1.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  24%|██▍       | 29/121 [00:35<02:34,  1.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  25%|██▍       | 30/121 [00:36<02:18,  1.52s/it]2025-04-24 20:14:27,951 - WARNING - qid 128 skipped – core-step substring not found.\n",
      "2025-04-24 20:14:27,952 - INFO - 1 of 121 questions skipped for sycophancy\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  26%|██▋       | 32/121 [00:38<01:39,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  27%|██▋       | 33/121 [00:39<01:32,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  28%|██▊       | 34/121 [00:39<01:26,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  29%|██▉       | 35/121 [00:41<01:34,  1.10s/it]2025-04-24 20:14:32,295 - WARNING - qid 157 skipped – core-step substring not found.\n",
      "2025-04-24 20:14:32,296 - INFO - 2 of 121 questions skipped for sycophancy\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  31%|███       | 37/121 [00:42<01:10,  1.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  31%|███▏      | 38/121 [00:43<01:09,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  32%|███▏      | 39/121 [00:44<01:14,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  33%|███▎      | 40/121 [00:45<01:15,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  34%|███▍      | 41/121 [00:46<01:23,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  35%|███▍      | 42/121 [00:48<01:32,  1.17s/it]2025-04-24 20:14:39,090 - WARNING - qid 183 skipped – core-step substring not found.\n",
      "2025-04-24 20:14:39,091 - INFO - 3 of 121 questions skipped for sycophancy\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  36%|███▋      | 44/121 [00:48<01:04,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  37%|███▋      | 45/121 [00:50<01:13,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  38%|███▊      | 46/121 [00:51<01:10,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  39%|███▉      | 47/121 [00:52<01:13,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  40%|███▉      | 48/121 [00:53<01:09,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  40%|████      | 49/121 [00:54<01:13,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  41%|████▏     | 50/121 [00:55<01:09,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  42%|████▏     | 51/121 [00:56<01:08,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  43%|████▎     | 52/121 [00:57<01:10,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  44%|████▍     | 53/121 [00:58<01:12,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  45%|████▍     | 54/121 [00:59<01:05,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  45%|████▌     | 55/121 [01:00<01:10,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  46%|████▋     | 56/121 [01:01<01:15,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  47%|████▋     | 57/121 [01:03<01:14,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  48%|████▊     | 58/121 [01:03<01:06,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  49%|████▉     | 59/121 [01:04<01:01,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  50%|████▉     | 60/121 [01:05<01:06,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  50%|█████     | 61/121 [01:07<01:10,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  51%|█████     | 62/121 [01:08<01:02,  1.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  52%|█████▏    | 63/121 [01:09<00:57,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  53%|█████▎    | 64/121 [01:10<01:00,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  54%|█████▎    | 65/121 [01:11<00:57,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  55%|█████▍    | 66/121 [01:12<01:02,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  55%|█████▌    | 67/121 [01:14<01:07,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  56%|█████▌    | 68/121 [01:15<01:07,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  57%|█████▋    | 69/121 [01:16<01:11,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  58%|█████▊    | 70/121 [01:17<01:03,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  59%|█████▊    | 71/121 [01:19<01:09,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  60%|█████▉    | 72/121 [01:20<00:59,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  60%|██████    | 73/121 [01:21<00:55,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  61%|██████    | 74/121 [01:23<01:00,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  62%|██████▏   | 75/121 [01:24<00:58,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  63%|██████▎   | 76/121 [01:25<00:50,  1.13s/it]2025-04-24 20:15:16,167 - WARNING - qid 345 skipped – core-step substring not found.\n",
      "2025-04-24 20:15:16,168 - INFO - 4 of 121 questions skipped for sycophancy\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  64%|██████▍   | 78/121 [01:26<00:38,  1.11it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  65%|██████▌   | 79/121 [01:27<00:41,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  66%|██████▌   | 80/121 [01:29<00:48,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  67%|██████▋   | 81/121 [01:30<00:45,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  68%|██████▊   | 82/121 [01:32<00:51,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  69%|██████▊   | 83/121 [01:34<00:58,  1.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  69%|██████▉   | 84/121 [01:35<00:55,  1.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  70%|███████   | 85/121 [01:36<00:46,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  71%|███████   | 86/121 [01:38<00:49,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  72%|███████▏  | 87/121 [01:39<00:44,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  73%|███████▎  | 88/121 [01:40<00:46,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  74%|███████▎  | 89/121 [01:42<00:48,  1.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  74%|███████▍  | 90/121 [01:44<00:48,  1.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  75%|███████▌  | 91/121 [01:46<00:56,  1.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  76%|███████▌  | 92/121 [01:48<00:49,  1.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  77%|███████▋  | 93/121 [01:50<00:54,  1.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  78%|███████▊  | 94/121 [01:52<00:48,  1.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  79%|███████▊  | 95/121 [01:53<00:40,  1.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  79%|███████▉  | 96/121 [01:54<00:33,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  80%|████████  | 97/121 [01:54<00:28,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  81%|████████  | 98/121 [01:55<00:24,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  82%|████████▏ | 99/121 [01:58<00:32,  1.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  83%|████████▎ | 100/121 [01:59<00:30,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  83%|████████▎ | 101/121 [02:00<00:27,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  84%|████████▍ | 102/121 [02:01<00:23,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  85%|████████▌ | 103/121 [02:03<00:24,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  86%|████████▌ | 104/121 [02:04<00:22,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  87%|████████▋ | 105/121 [02:05<00:19,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  88%|████████▊ | 106/121 [02:06<00:18,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  88%|████████▊ | 107/121 [02:07<00:16,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  89%|████████▉ | 108/121 [02:09<00:15,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  90%|█████████ | 109/121 [02:10<00:15,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  91%|█████████ | 110/121 [02:11<00:12,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  92%|█████████▏| 111/121 [02:12<00:11,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  93%|█████████▎| 112/121 [02:14<00:11,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  93%|█████████▎| 113/121 [02:15<00:11,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  94%|█████████▍| 114/121 [02:16<00:09,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  95%|█████████▌| 115/121 [02:17<00:07,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  96%|█████████▌| 116/121 [02:18<00:05,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  97%|█████████▋| 117/121 [02:19<00:04,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  98%|█████████▊| 118/121 [02:20<00:03,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  98%|█████████▊| 119/121 [02:22<00:02,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation:  99%|█████████▉| 120/121 [02:23<00:01,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "sycophancy: ablation: 100%|██████████| 121/121 [02:25<00:00,  1.20s/it]\n",
      "unethical_information: ablation:   0%|          | 0/142 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:   1%|          | 1/142 [00:01<03:34,  1.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:   1%|▏         | 2/142 [00:02<03:01,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:   2%|▏         | 3/142 [00:03<02:42,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:   3%|▎         | 4/142 [00:05<02:53,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:   4%|▎         | 5/142 [00:06<03:05,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:   4%|▍         | 6/142 [00:07<02:35,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:   5%|▍         | 7/142 [00:08<02:41,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:   6%|▌         | 8/142 [00:09<02:45,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:   6%|▋         | 9/142 [00:11<02:50,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:   7%|▋         | 10/142 [00:12<02:44,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:   8%|▊         | 11/142 [00:13<02:26,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:   8%|▊         | 12/142 [00:14<02:20,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:   9%|▉         | 13/142 [00:15<02:31,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  10%|▉         | 14/142 [00:16<02:31,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  11%|█         | 15/142 [00:18<02:34,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  11%|█▏        | 16/142 [00:18<02:16,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  12%|█▏        | 17/142 [00:20<02:44,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  13%|█▎        | 18/142 [00:22<02:46,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  13%|█▎        | 19/142 [00:23<02:44,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  14%|█▍        | 20/142 [00:24<02:25,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  15%|█▍        | 21/142 [00:26<03:04,  1.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  15%|█▌        | 22/142 [00:27<02:38,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  16%|█▌        | 23/142 [00:28<02:30,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  17%|█▋        | 24/142 [00:29<02:15,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  18%|█▊        | 25/142 [00:30<02:14,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  18%|█▊        | 26/142 [00:32<02:22,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  19%|█▉        | 27/142 [00:33<02:34,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  20%|█▉        | 28/142 [00:35<02:34,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  20%|██        | 29/142 [00:36<02:31,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  21%|██        | 30/142 [00:38<02:57,  1.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  22%|██▏       | 31/142 [00:39<02:36,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  23%|██▎       | 32/142 [00:40<02:14,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  23%|██▎       | 33/142 [00:41<02:15,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  24%|██▍       | 34/142 [00:43<02:16,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  25%|██▍       | 35/142 [00:44<02:11,  1.23s/it]2025-04-24 20:17:00,944 - WARNING - qid 131 skipped – core-step substring not found.\n",
      "2025-04-24 20:17:00,945 - INFO - 0 of 142 questions skipped for unethical_information\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  26%|██▌       | 37/142 [00:46<02:06,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  27%|██▋       | 38/142 [00:47<02:00,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  27%|██▋       | 39/142 [00:48<01:54,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  28%|██▊       | 40/142 [00:50<02:05,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  29%|██▉       | 41/142 [00:51<02:07,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  30%|██▉       | 42/142 [00:52<02:06,  1.27s/it]2025-04-24 20:17:09,455 - WARNING - qid 150 skipped – core-step substring not found.\n",
      "2025-04-24 20:17:09,456 - INFO - 1 of 142 questions skipped for unethical_information\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  31%|███       | 44/142 [00:54<01:54,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  32%|███▏      | 45/142 [00:55<01:45,  1.09s/it]2025-04-24 20:17:12,406 - WARNING - qid 159 skipped – core-step substring not found.\n",
      "2025-04-24 20:17:12,407 - INFO - 2 of 142 questions skipped for unethical_information\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  33%|███▎      | 47/142 [00:57<01:30,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  34%|███▍      | 48/142 [00:58<01:37,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  35%|███▍      | 49/142 [00:59<01:44,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  35%|███▌      | 50/142 [01:00<01:39,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  36%|███▌      | 51/142 [01:01<01:33,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  37%|███▋      | 52/142 [01:02<01:31,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  37%|███▋      | 53/142 [01:03<01:29,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  38%|███▊      | 54/142 [01:06<02:05,  1.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  39%|███▊      | 55/142 [01:06<01:49,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  39%|███▉      | 56/142 [01:08<01:51,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  40%|████      | 57/142 [01:09<01:38,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  41%|████      | 58/142 [01:10<01:37,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  42%|████▏     | 59/142 [01:12<01:59,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  42%|████▏     | 60/142 [01:14<02:14,  1.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  43%|████▎     | 61/142 [01:15<02:04,  1.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  44%|████▎     | 62/142 [01:17<01:54,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  44%|████▍     | 63/142 [01:18<01:47,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  45%|████▌     | 64/142 [01:19<01:41,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  46%|████▌     | 65/142 [01:20<01:29,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  46%|████▋     | 66/142 [01:21<01:39,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  47%|████▋     | 67/142 [01:22<01:31,  1.22s/it]2025-04-24 20:17:39,669 - WARNING - qid 236 skipped – core-step substring not found.\n",
      "2025-04-24 20:17:39,670 - INFO - 3 of 142 questions skipped for unethical_information\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  49%|████▊     | 69/142 [01:24<01:10,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  49%|████▉     | 70/142 [01:26<01:31,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  50%|█████     | 71/142 [01:27<01:20,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  51%|█████     | 72/142 [01:28<01:28,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  51%|█████▏    | 73/142 [01:30<01:27,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  52%|█████▏    | 74/142 [01:30<01:17,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  53%|█████▎    | 75/142 [01:31<01:15,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  54%|█████▎    | 76/142 [01:32<01:10,  1.07s/it]2025-04-24 20:17:49,687 - WARNING - qid 252 skipped – core-step substring not found.\n",
      "2025-04-24 20:17:49,688 - INFO - 4 of 142 questions skipped for unethical_information\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  55%|█████▍    | 78/142 [01:34<00:57,  1.12it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  56%|█████▌    | 79/142 [01:35<01:00,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  56%|█████▋    | 80/142 [01:36<01:07,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  57%|█████▋    | 81/142 [01:38<01:07,  1.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  58%|█████▊    | 82/142 [01:39<01:06,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  58%|█████▊    | 83/142 [01:40<01:12,  1.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  59%|█████▉    | 84/142 [01:42<01:13,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  60%|█████▉    | 85/142 [01:43<01:12,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  61%|██████    | 86/142 [01:44<01:12,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  61%|██████▏   | 87/142 [01:45<01:02,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  62%|██████▏   | 88/142 [01:47<01:09,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  63%|██████▎   | 89/142 [01:48<01:05,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  63%|██████▎   | 90/142 [01:49<01:10,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  64%|██████▍   | 91/142 [01:50<01:03,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  65%|██████▍   | 92/142 [01:52<01:02,  1.25s/it]2025-04-24 20:18:08,849 - WARNING - qid 327 skipped – core-step substring not found.\n",
      "2025-04-24 20:18:08,849 - INFO - 5 of 142 questions skipped for unethical_information\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  66%|██████▌   | 94/142 [01:54<00:59,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  67%|██████▋   | 95/142 [01:55<01:00,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  68%|██████▊   | 96/142 [01:57<01:01,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  68%|██████▊   | 97/142 [01:58<00:57,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  69%|██████▉   | 98/142 [01:59<00:56,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  70%|██████▉   | 99/142 [02:02<01:08,  1.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  70%|███████   | 100/142 [02:03<01:05,  1.55s/it]2025-04-24 20:18:20,456 - WARNING - qid 363 skipped – core-step substring not found.\n",
      "2025-04-24 20:18:20,457 - INFO - 6 of 142 questions skipped for unethical_information\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  72%|███████▏  | 102/142 [02:04<00:45,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  73%|███████▎  | 103/142 [02:06<00:46,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  73%|███████▎  | 104/142 [02:08<00:51,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  74%|███████▍  | 105/142 [02:09<00:53,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  75%|███████▍  | 106/142 [02:11<00:51,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  75%|███████▌  | 107/142 [02:12<00:45,  1.30s/it]2025-04-24 20:18:28,975 - WARNING - qid 389 skipped – core-step substring not found.\n",
      "2025-04-24 20:18:28,976 - INFO - 7 of 142 questions skipped for unethical_information\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  77%|███████▋  | 109/142 [02:13<00:34,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  77%|███████▋  | 110/142 [02:14<00:31,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  78%|███████▊  | 111/142 [02:15<00:28,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  79%|███████▉  | 112/142 [02:16<00:28,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  80%|███████▉  | 113/142 [02:17<00:28,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  80%|████████  | 114/142 [02:18<00:31,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  81%|████████  | 115/142 [02:19<00:29,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  82%|████████▏ | 116/142 [02:21<00:33,  1.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  82%|████████▏ | 117/142 [02:22<00:29,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  83%|████████▎ | 118/142 [02:23<00:26,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  84%|████████▍ | 119/142 [02:24<00:26,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  85%|████████▍ | 120/142 [02:25<00:24,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  85%|████████▌ | 121/142 [02:27<00:29,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  86%|████████▌ | 122/142 [02:28<00:26,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  87%|████████▋ | 123/142 [02:31<00:29,  1.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  87%|████████▋ | 124/142 [02:31<00:23,  1.32s/it]2025-04-24 20:18:48,577 - WARNING - qid 451 skipped – core-step substring not found.\n",
      "2025-04-24 20:18:48,578 - INFO - 8 of 142 questions skipped for unethical_information\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  89%|████████▊ | 126/142 [02:33<00:17,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  89%|████████▉ | 127/142 [02:34<00:16,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  90%|█████████ | 128/142 [02:35<00:15,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  91%|█████████ | 129/142 [02:37<00:15,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  92%|█████████▏| 130/142 [02:38<00:13,  1.13s/it]2025-04-24 20:18:54,906 - WARNING - qid 477 skipped – core-step substring not found.\n",
      "2025-04-24 20:18:54,907 - INFO - 9 of 142 questions skipped for unethical_information\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  93%|█████████▎| 132/142 [02:39<00:08,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  94%|█████████▎| 133/142 [02:40<00:08,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  94%|█████████▍| 134/142 [02:42<00:09,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  95%|█████████▌| 135/142 [02:43<00:08,  1.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  96%|█████████▌| 136/142 [02:44<00:06,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  96%|█████████▋| 137/142 [02:45<00:05,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  97%|█████████▋| 138/142 [02:46<00:04,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  98%|█████████▊| 139/142 [02:47<00:03,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  99%|█████████▊| 140/142 [02:49<00:02,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation:  99%|█████████▉| 141/142 [02:50<00:01,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "unethical_information: ablation: 100%|██████████| 142/142 [02:51<00:00,  1.21s/it]\n",
      "induced_urgency: ablation:   0%|          | 0/114 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:   1%|          | 1/114 [00:01<03:22,  1.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:   2%|▏         | 2/114 [00:02<02:39,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:   3%|▎         | 3/114 [00:03<02:16,  1.23s/it]2025-04-24 20:19:11,909 - WARNING - qid 13 skipped – core-step substring not found.\n",
      "2025-04-24 20:19:11,909 - INFO - 0 of 114 questions skipped for induced_urgency\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:   4%|▍         | 5/114 [00:05<01:47,  1.01it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:   5%|▌         | 6/114 [00:06<01:55,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:   6%|▌         | 7/114 [00:07<01:56,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:   7%|▋         | 8/114 [00:08<01:45,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:   8%|▊         | 9/114 [00:10<01:55,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:   9%|▉         | 10/114 [00:10<01:46,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  10%|▉         | 11/114 [00:11<01:43,  1.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  11%|█         | 12/114 [00:13<01:46,  1.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  11%|█▏        | 13/114 [00:13<01:38,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  12%|█▏        | 14/114 [00:15<01:49,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  13%|█▎        | 15/114 [00:16<01:40,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  14%|█▍        | 16/114 [00:17<01:55,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  15%|█▍        | 17/114 [00:18<01:54,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  16%|█▌        | 18/114 [00:19<01:44,  1.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  17%|█▋        | 19/114 [00:21<01:54,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  18%|█▊        | 20/114 [00:22<01:46,  1.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  18%|█▊        | 21/114 [00:23<02:01,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  19%|█▉        | 22/114 [00:25<01:57,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  20%|██        | 23/114 [00:26<01:49,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  21%|██        | 24/114 [00:27<01:52,  1.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  22%|██▏       | 25/114 [00:28<01:51,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  23%|██▎       | 26/114 [00:30<01:53,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  24%|██▎       | 27/114 [00:31<01:49,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  25%|██▍       | 28/114 [00:32<01:57,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  25%|██▌       | 29/114 [00:34<02:13,  1.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  26%|██▋       | 30/114 [00:36<02:04,  1.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  27%|██▋       | 31/114 [00:37<02:09,  1.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  28%|██▊       | 32/114 [00:38<01:48,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  29%|██▉       | 33/114 [00:39<01:45,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  30%|██▉       | 34/114 [00:41<01:56,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  31%|███       | 35/114 [00:42<01:43,  1.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  32%|███▏      | 36/114 [00:44<01:49,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  32%|███▏      | 37/114 [00:45<01:52,  1.47s/it]2025-04-24 20:19:53,934 - WARNING - qid 143 skipped – core-step substring not found.\n",
      "2025-04-24 20:19:53,935 - INFO - 1 of 114 questions skipped for induced_urgency\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  34%|███▍      | 39/114 [00:48<01:37,  1.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  35%|███▌      | 40/114 [00:49<01:33,  1.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  36%|███▌      | 41/114 [00:50<01:36,  1.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  37%|███▋      | 42/114 [00:52<01:38,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  38%|███▊      | 43/114 [00:53<01:29,  1.26s/it]2025-04-24 20:20:01,245 - WARNING - qid 165 skipped – core-step substring not found.\n",
      "2025-04-24 20:20:01,245 - INFO - 2 of 114 questions skipped for induced_urgency\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  39%|███▉      | 45/114 [00:54<01:02,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  40%|████      | 46/114 [00:55<01:05,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  41%|████      | 47/114 [00:56<01:02,  1.07it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  42%|████▏     | 48/114 [00:57<01:07,  1.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  43%|████▎     | 49/114 [00:58<01:11,  1.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  44%|████▍     | 50/114 [01:00<01:15,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  45%|████▍     | 51/114 [01:00<01:07,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  46%|████▌     | 52/114 [01:01<01:04,  1.04s/it]2025-04-24 20:20:09,911 - WARNING - qid 207 skipped – core-step substring not found.\n",
      "2025-04-24 20:20:09,912 - INFO - 3 of 114 questions skipped for induced_urgency\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  47%|████▋     | 54/114 [01:03<00:50,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  48%|████▊     | 55/114 [01:04<00:51,  1.15it/s]2025-04-24 20:20:12,083 - WARNING - qid 220 skipped – core-step substring not found.\n",
      "2025-04-24 20:20:12,084 - INFO - 4 of 114 questions skipped for induced_urgency\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  50%|█████     | 57/114 [01:05<00:40,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  51%|█████     | 58/114 [01:05<00:41,  1.35it/s]2025-04-24 20:20:13,881 - WARNING - qid 233 skipped – core-step substring not found.\n",
      "2025-04-24 20:20:13,882 - INFO - 5 of 114 questions skipped for induced_urgency\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  53%|█████▎    | 60/114 [01:07<00:36,  1.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  54%|█████▎    | 61/114 [01:08<00:44,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  54%|█████▍    | 62/114 [01:09<00:47,  1.10it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  55%|█████▌    | 63/114 [01:10<00:45,  1.13it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  56%|█████▌    | 64/114 [01:11<00:49,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  57%|█████▋    | 65/114 [01:13<00:52,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  58%|█████▊    | 66/114 [01:15<01:10,  1.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  59%|█████▉    | 67/114 [01:16<01:06,  1.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  60%|█████▉    | 68/114 [01:17<01:01,  1.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  61%|██████    | 69/114 [01:19<00:57,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  61%|██████▏   | 70/114 [01:19<00:50,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  62%|██████▏   | 71/114 [01:21<00:49,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  63%|██████▎   | 72/114 [01:22<00:48,  1.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  64%|██████▍   | 73/114 [01:23<00:51,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  65%|██████▍   | 74/114 [01:24<00:47,  1.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  66%|██████▌   | 75/114 [01:26<00:47,  1.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  67%|██████▋   | 76/114 [01:27<00:48,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  68%|██████▊   | 77/114 [01:28<00:44,  1.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  68%|██████▊   | 78/114 [01:29<00:44,  1.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  69%|██████▉   | 79/114 [01:31<00:43,  1.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  70%|███████   | 80/114 [01:31<00:38,  1.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  71%|███████   | 81/114 [01:33<00:39,  1.19s/it]2025-04-24 20:20:41,279 - WARNING - qid 363 skipped – core-step substring not found.\n",
      "2025-04-24 20:20:41,280 - INFO - 6 of 114 questions skipped for induced_urgency\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  73%|███████▎  | 83/114 [01:34<00:25,  1.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  74%|███████▎  | 84/114 [01:35<00:26,  1.14it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  75%|███████▍  | 85/114 [01:36<00:30,  1.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  75%|███████▌  | 86/114 [01:38<00:38,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  76%|███████▋  | 87/114 [01:40<00:37,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  77%|███████▋  | 88/114 [01:41<00:36,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  78%|███████▊  | 89/114 [01:42<00:29,  1.20s/it]2025-04-24 20:20:50,437 - WARNING - qid 404 skipped – core-step substring not found.\n",
      "2025-04-24 20:20:50,438 - INFO - 7 of 114 questions skipped for induced_urgency\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  80%|███████▉  | 91/114 [01:43<00:21,  1.09it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  81%|████████  | 92/114 [01:44<00:21,  1.01it/s]2025-04-24 20:20:52,787 - WARNING - qid 415 skipped – core-step substring not found.\n",
      "2025-04-24 20:20:52,788 - INFO - 8 of 114 questions skipped for induced_urgency\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  82%|████████▏ | 94/114 [01:46<00:16,  1.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  83%|████████▎ | 95/114 [01:47<00:17,  1.06it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  84%|████████▍ | 96/114 [01:48<00:17,  1.00it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  85%|████████▌ | 97/114 [01:49<00:16,  1.05it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  86%|████████▌ | 98/114 [01:50<00:18,  1.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  87%|████████▋ | 99/114 [01:53<00:22,  1.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  88%|████████▊ | 100/114 [01:54<00:19,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  89%|████████▊ | 101/114 [01:55<00:16,  1.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  89%|████████▉ | 102/114 [01:58<00:19,  1.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  90%|█████████ | 103/114 [01:58<00:15,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  91%|█████████ | 104/114 [02:00<00:13,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  92%|█████████▏| 105/114 [02:00<00:10,  1.18s/it]2025-04-24 20:21:08,810 - WARNING - qid 460 skipped – core-step substring not found.\n",
      "2025-04-24 20:21:08,811 - INFO - 9 of 114 questions skipped for induced_urgency\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  94%|█████████▍| 107/114 [02:02<00:07,  1.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  95%|█████████▍| 108/114 [02:03<00:05,  1.03it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  96%|█████████▌| 109/114 [02:04<00:05,  1.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  96%|█████████▋| 110/114 [02:05<00:04,  1.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  97%|█████████▋| 111/114 [02:07<00:03,  1.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  98%|█████████▊| 112/114 [02:08<00:02,  1.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation:  99%|█████████▉| 113/114 [02:09<00:01,  1.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "induced_urgency: ablation: 100%|██████████| 114/114 [02:10<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "run_kv_ablation_experiment(\n",
    "    model, tok, device,\n",
    "    dataset=DATASET,\n",
    "    hint_types=HINT_TYPES[1:],   # skip 'none'\n",
    "    model_name=model_name,\n",
    "    n_questions=N_QUESTIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to Series.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m HINT_TYPES \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msycophancy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minduced_urgency\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m load_ablation_dataframe(DATASET, model_name, HINT_TYPES[\u001b[38;5;241m1\u001b[39m:], N_QUESTIONS)\n\u001b[0;32m----> 3\u001b[0m fig, summary \u001b[38;5;241m=\u001b[39m \u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m      6\u001b[0m display(summary\u001b[38;5;241m.\u001b[39mhead())  \u001b[38;5;66;03m# the numeric table you asked for\u001b[39;00m\n",
      "File \u001b[0;32m~/CoTFaithChecker/a_confirm_posthoc/src/ablation/plot_ablation.py:69\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     66\u001b[0m         bar_pos \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m \u001b[38;5;241m+\u001b[39m j   \u001b[38;5;66;03m# cluster offset\u001b[39;00m\n\u001b[1;32m     67\u001b[0m         ax\u001b[38;5;241m.\u001b[39mbar(bar_pos, edf\u001b[38;5;241m.\u001b[39mchanged\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     68\u001b[0m         ax\u001b[38;5;241m.\u001b[39mtext(bar_pos, edf\u001b[38;5;241m.\u001b[39mchanged\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m---> 69\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00medf\u001b[38;5;241m.\u001b[39mchanged\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m, ha\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m     70\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m% a\u001b[39;00m\u001b[38;5;124mnswers changed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_xticks(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(agg\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhint_type\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m]))),\n\u001b[1;32m     72\u001b[0m               labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m h,e \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m     73\u001b[0m                       agg[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhint_type\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)])\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to Series.__format__"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9oAAAH5CAYAAAB+sEb2AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJGxJREFUeJzt3X9w14V9+PFXMBA4IQFUEjJBqKVFW6sWK8YfrWsz0XEeXLl5Wtazjom3oR1SZ2FVma0KOqcMizKZQ7vTUd0NZ3XiXLR61oiKtPMnVYeViolnKQnCEZG8v3/06+cWiz8SXkmAPB53n7vm/Xl/3r4+9zLQp598PikriqIIAAAAIEW/3h4AAAAA9iVCGwAAABIJbQAAAEgktAEAACCR0AYAAIBEQhsAAAASCW0AAABIVN7bA3RFe3t7bNy4MYYMGRJlZWW9PQ4AAAD7uKIoYsuWLVFbWxv9+n30a9Z7ZWhv3LgxRo0a1dtjAAAA0Mds2LAhDj744I88Z68M7SFDhkTE755gZWVlL08DAADAvq61tTVGjRpV6tGPsleG9vs/Ll5ZWSm0AQAA6DGf5O3Lnf4wtEcffTROP/30qK2tjbKysrj77rs73F8URVx22WUxcuTIGDRoUNTX18fLL7/c4ZxNmzbF9OnTo7KyMoYOHRozZsyId955p7OjAAAAwB6n06G9devWOPLII2PJkiW7vP+aa66JxYsXx9KlS2P16tWx//77x6RJk2L79u2lc6ZPnx7PP/98PPjgg3HvvffGo48+GjNnzuz6swAAAIA9RFlRFEWXH1xWFitXroypU6dGxO9eza6trY3vfOc7cdFFF0VEREtLS1RXV8ett94aZ555Zrz44otx+OGHx1NPPRXHHHNMRESsWrUq/viP/zh+/etfR21t7cf+c1tbW6OqqipaWlr86DgAAADdrjMdmvp7tNevXx9NTU1RX19fOlZVVRUTJ06MxsbGiIhobGyMoUOHliI7IqK+vj769esXq1ev3uV129raorW1tcMNAAAA9kSpod3U1BQREdXV1R2OV1dXl+5ramqKESNGdLi/vLw8hg8fXjrngxYsWBBVVVWlm1/tBQAAwJ4qNbS7y7x586KlpaV027BhQ2+PBAAAALuUGto1NTUREdHc3NzheHNzc+m+mpqaeOuttzrc/95778WmTZtK53xQRUVF6Vd5+ZVeAAAA7MlSQ3vs2LFRU1MTDQ0NpWOtra2xevXqqKuri4iIurq62Lx5c6xZs6Z0zkMPPRTt7e0xceLEzHEAAACgx5V39gHvvPNOvPLKK6Wv169fHz//+c9j+PDhMXr06Jg9e3ZcccUVMW7cuBg7dmxceumlUVtbW/pk8sMOOyxOPfXUOPfcc2Pp0qWxY8eOOP/88+PMM8/8RJ84DgAAAHuyTof2008/HX/4h39Y+nrOnDkREXH22WfHrbfeGhdffHFs3bo1Zs6cGZs3b44TTzwxVq1aFQMHDiw95vbbb4/zzz8/vva1r0W/fv1i2rRpsXjx4oSnAwAAAL1rt36Pdm/xe7QBAADoSb32e7QBAACgrxPaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJynt7gH3dmLn39fYIAAAAe7TXFk7u7RFSeUUbAAAAEgltAAAASCS0AQAAIJHQBgAAgERCGwAAABIJbQAAAEgktAEAACCR0AYAAIBEQhsAAAASCW0AAABIJLQBAAAgkdAGAACAREIbAAAAEgltAAAASCS0AQAAIJHQBgAAgERCGwAAABIJbQAAAEgktAEAACCR0AYAAIBEQhsAAAASCW0AAABIJLQBAAAgkdAGAACAREIbAAAAEgltAAAASCS0AQAAIJHQBgAAgERCGwAAABIJbQAAAEgktAEAACCR0AYAAIBEQhsAAAASCW0AAABIJLQBAAAgkdAGAACAREIbAAAAEgltAAAASCS0AQAAIJHQBgAAgERCGwAAABIJbQAAAEgktAEAACCR0AYAAIBEQhsAAAASCW0AAABIJLQBAAAgkdAGAACAREIbAAAAEgltAAAASCS0AQAAIJHQBgAAgERCGwAAABIJbQAAAEgktAEAACCR0AYAAIBEQhsAAAASCW0AAABIJLQBAAAgkdAGAACAREIbAAAAEgltAAAASCS0AQAAIJHQBgAAgERCGwAAABIJbQAAAEgktAEAACCR0AYAAIBEQhsAAAASCW0AAABIJLQBAAAgUXpo79y5My699NIYO3ZsDBo0KA499ND4wQ9+EEVRlM4piiIuu+yyGDlyZAwaNCjq6+vj5Zdfzh4FAAAAelx6aF999dVx0003xQ9/+MN48cUX4+qrr45rrrkmbrjhhtI511xzTSxevDiWLl0aq1evjv333z8mTZoU27dvzx4HAAAAelR59gUff/zxmDJlSkyePDkiIsaMGRP/+q//Gk8++WRE/O7V7EWLFsUll1wSU6ZMiYiIH/3oR1FdXR133313nHnmmdkjAQAAQI9Jf0X7+OOPj4aGhvjlL38ZERG/+MUv4rHHHovTTjstIiLWr18fTU1NUV9fX3pMVVVVTJw4MRobG3d5zba2tmhtbe1wAwAAgD1R+ivac+fOjdbW1hg/fnzst99+sXPnzrjyyitj+vTpERHR1NQUERHV1dUdHlddXV2674MWLFgQl19+efaoAAAAkC79Fe0777wzbr/99rjjjjvimWeeidtuuy2uvfbauO2227p8zXnz5kVLS0vptmHDhsSJAQAAIE/6K9p//dd/HXPnzi291/qII46IX/3qV7FgwYI4++yzo6amJiIimpubY+TIkaXHNTc3x1FHHbXLa1ZUVERFRUX2qAAAAJAu/RXtbdu2Rb9+HS+73377RXt7e0REjB07NmpqaqKhoaF0f2tra6xevTrq6uqyxwEAAIAelf6K9umnnx5XXnlljB49Oj73uc/F2rVr47rrros/+7M/i4iIsrKymD17dlxxxRUxbty4GDt2bFx66aVRW1sbU6dOzR4HAAAAelR6aN9www1x6aWXxl/+5V/GW2+9FbW1tXHeeefFZZddVjrn4osvjq1bt8bMmTNj8+bNceKJJ8aqVati4MCB2eMAAABAjyoriqLo7SE6q7W1NaqqqqKlpSUqKyt7e5yPNGbufb09AgAAwB7ttYWTe3uEj9WZDk1/jzYAAAD0ZUIbAAAAEgltAAAASCS0AQAAIJHQBgAAgERCGwAAABIJbQAAAEgktAEAACCR0AYAAIBEQhsAAAASCW0AAABIJLQBAAAgkdAGAACAREIbAAAAEgltAAAASCS0AQAAIJHQBgAAgERCGwAAABIJbQAAAEgktAEAACCR0AYAAIBEQhsAAAASCW0AAABIJLQBAAAgkdAGAACAREIbAAAAEgltAAAASCS0AQAAIJHQBgAAgERCGwAAABIJbQAAAEgktAEAACCR0AYAAIBEQhsAAAASCW0AAABIJLQBAAAgkdAGAACAREIbAAAAEgltAAAASCS0AQAAIJHQBgAAgERCGwAAABIJbQAAAEgktAEAACCR0AYAAIBEQhsAAAASCW0AAABIJLQBAAAgkdAGAACAREIbAAAAEgltAAAASCS0AQAAIJHQBgAAgERCGwAAABIJbQAAAEgktAEAACCR0AYAAIBEQhsAAAASCW0AAABIJLQBAAAgkdAGAACAREIbAAAAEgltAAAASCS0AQAAIJHQBgAAgERCGwAAABIJbQAAAEgktAEAACCR0AYAAIBEQhsAAAASCW0AAABIJLQBAAAgkdAGAACAREIbAAAAEgltAAAASCS0AQAAIJHQBgAAgERCGwAAABIJbQAAAEgktAEAACBRt4T2G2+8EX/6p38aBxxwQAwaNCiOOOKIePrpp0v3F0URl112WYwcOTIGDRoU9fX18fLLL3fHKAAAANCj0kP7t7/9bZxwwgnRv3//uP/+++OFF16Iv//7v49hw4aVzrnmmmti8eLFsXTp0li9enXsv//+MWnSpNi+fXv2OAAAANCjyrMvePXVV8eoUaNi+fLlpWNjx44t/e+iKGLRokVxySWXxJQpUyIi4kc/+lFUV1fH3XffHWeeeWb2SAAAANBj0l/Rvueee+KYY46JP/mTP4kRI0bE0UcfHcuWLSvdv379+mhqaor6+vrSsaqqqpg4cWI0Njbu8pptbW3R2tra4QYAAAB7ovTQ/t///d+46aabYty4cfHAAw/EX/zFX8S3v/3tuO222yIioqmpKSIiqqurOzyuurq6dN8HLViwIKqqqkq3UaNGZY8NAAAAKdJDu729Pb74xS/GVVddFUcffXTMnDkzzj333Fi6dGmXrzlv3rxoaWkp3TZs2JA4MQAAAORJD+2RI0fG4Ycf3uHYYYcdFq+//npERNTU1ERERHNzc4dzmpubS/d9UEVFRVRWVna4AQAAwJ4oPbRPOOGEWLduXYdjv/zlL+OQQw6JiN99MFpNTU00NDSU7m9tbY3Vq1dHXV1d9jgAAADQo9I/dfzCCy+M448/Pq666qo444wz4sknn4ybb745br755oiIKCsri9mzZ8cVV1wR48aNi7Fjx8all14atbW1MXXq1OxxAAAAoEelh/aXvvSlWLlyZcybNy++//3vx9ixY2PRokUxffr00jkXX3xxbN26NWbOnBmbN2+OE088MVatWhUDBw7MHgcAAAB6VFlRFEVvD9FZra2tUVVVFS0tLXv8+7XHzL2vt0cAAADYo722cHJvj/CxOtOh6e/RBgAAgL5MaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJOr20F64cGGUlZXF7NmzS8e2b98es2bNigMOOCAGDx4c06ZNi+bm5u4eBQAAALpdt4b2U089Ff/4j/8YX/jCFzocv/DCC+MnP/lJ3HXXXfHII4/Exo0b4+tf/3p3jgIAAAA9ottC+5133onp06fHsmXLYtiwYaXjLS0tccstt8R1110XX/3qV2PChAmxfPnyePzxx+OJJ57ornEAAACgR3RbaM+aNSsmT54c9fX1HY6vWbMmduzY0eH4+PHjY/To0dHY2LjLa7W1tUVra2uHGwAAAOyJyrvjoitWrIhnnnkmnnrqqd+7r6mpKQYMGBBDhw7tcLy6ujqampp2eb0FCxbE5Zdf3h2jAgAAQKr0V7Q3bNgQf/VXfxW33357DBw4MOWa8+bNi5aWltJtw4YNKdcFAACAbOmhvWbNmnjrrbfii1/8YpSXl0d5eXk88sgjsXjx4igvL4/q6up49913Y/PmzR0e19zcHDU1Nbu8ZkVFRVRWVna4AQAAwJ4o/UfHv/a1r8Wzzz7b4dg555wT48ePj+9+97sxatSo6N+/fzQ0NMS0adMiImLdunXx+uuvR11dXfY4AAAA0KPSQ3vIkCHx+c9/vsOx/fffPw444IDS8RkzZsScOXNi+PDhUVlZGRdccEHU1dXFcccdlz0OAAAA9Khu+TC0j3P99ddHv379Ytq0adHW1haTJk2KG2+8sTdGAQAAgFRlRVEUvT1EZ7W2tkZVVVW0tLTs8e/XHjP3vt4eAQAAYI/22sLJvT3Cx+pMh3bb79EGAACAvkhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkSg/tBQsWxJe+9KUYMmRIjBgxIqZOnRrr1q3rcM727dtj1qxZccABB8TgwYNj2rRp0dzcnD0KAAAA9Lj00H7kkUdi1qxZ8cQTT8SDDz4YO3bsiFNOOSW2bt1aOufCCy+Mn/zkJ3HXXXfFI488Ehs3boyvf/3r2aMAAABAjyvPvuCqVas6fH3rrbfGiBEjYs2aNfHlL385Wlpa4pZbbok77rgjvvrVr0ZExPLly+Owww6LJ554Io477rjskQAAAKDHdPt7tFtaWiIiYvjw4RERsWbNmtixY0fU19eXzhk/fnyMHj06Ghsbd3mNtra2aG1t7XADAACAPVG3hnZ7e3vMnj07TjjhhPj85z8fERFNTU0xYMCAGDp0aIdzq6uro6mpaZfXWbBgQVRVVZVuo0aN6s6xAQAAoMu6NbRnzZoVzz33XKxYsWK3rjNv3rxoaWkp3TZs2JA0IQAAAORKf4/2+84///y4995749FHH42DDz64dLympibefffd2Lx5c4dXtZubm6OmpmaX16qoqIiKioruGhUAAADSpL+iXRRFnH/++bFy5cp46KGHYuzYsR3unzBhQvTv3z8aGhpKx9atWxevv/561NXVZY8DAAAAPSr9Fe1Zs2bFHXfcEf/xH/8RQ4YMKb3vuqqqKgYNGhRVVVUxY8aMmDNnTgwfPjwqKyvjggsuiLq6Op84DgAAwF4vPbRvuummiIg4+eSTOxxfvnx5fOtb34qIiOuvvz769esX06ZNi7a2tpg0aVLceOON2aMAAABAj0sP7aIoPvacgQMHxpIlS2LJkiXZ/3gAAADoVd3+e7QBAACgLxHaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJBIaAMAAEAioQ0AAACJhDYAAAAk6tXQXrJkSYwZMyYGDhwYEydOjCeffLI3xwEAAIDd1muh/eMf/zjmzJkT8+fPj2eeeSaOPPLImDRpUrz11lu9NRIAAADstvLe+gdfd911ce6558Y555wTERFLly6N++67L/75n/855s6d2+Hctra2aGtrK33d0tISERGtra09N3AXtbdt6+0RAAAA9mh7Q9u9P2NRFB97bq+E9rvvvhtr1qyJefPmlY7169cv6uvro7Gx8ffOX7BgQVx++eW/d3zUqFHdOicAAADdr2pRb0/wyW3ZsiWqqqo+8pxeCe233347du7cGdXV1R2OV1dXx0svvfR758+bNy/mzJlT+rq9vT02bdoUBxxwQJSVlXX7vF3V2toao0aNig0bNkRlZWVvj8OHsKe9gz3t+exo72BPewd72vPZ0d7BnvYOe8ueiqKILVu2RG1t7cee22s/Ot4ZFRUVUVFR0eHY0KFDe2eYLqisrNyj/4Xhd+xp72BPez472jvY097BnvZ8drR3sKe9w96wp497Jft9vfJhaAceeGDst99+0dzc3OF4c3Nz1NTU9MZIAAAAkKJXQnvAgAExYcKEaGhoKB1rb2+PhoaGqKur642RAAAAIEWv/ej4nDlz4uyzz45jjjkmjj322Fi0aFFs3bq19Cnk+4KKioqYP3/+7/3YO3sWe9o72NOez472Dva0d7CnPZ8d7R3sae+wL+6prPgkn03eTX74wx/G3/3d30VTU1McddRRsXjx4pg4cWJvjQMAAAC7rVdDGwAAAPY1vfIebQAAANhXCW0AAABIJLQBAAAgkdAGAACAREI72aZNm2L69OlRWVkZQ4cOjRkzZsQ777zziR5bFEWcdtppUVZWFnfffXf3DtrHdWVP5513Xhx66KExaNCgOOigg2LKlCnx0ksv9dDEfU9nd7Rp06a44IIL4rOf/WwMGjQoRo8eHd/+9rejpaWlB6fue7ryvXTzzTfHySefHJWVlVFWVhabN2/umWH7kCVLlsSYMWNi4MCBMXHixHjyySc/8vy77rorxo8fHwMHDowjjjgi/vM//7OHJu3bOrOn559/PqZNmxZjxoyJsrKyWLRoUc8N2od1ZkfLli2Lk046KYYNGxbDhg2L+vr6j/3eI0dn9vTv//7vccwxx8TQoUNj//33j6OOOir+5V/+pQen7bs6+3fT+1asWBFlZWUxderU7h0wmdBONn369Hj++efjwQcfjHvvvTceffTRmDlz5id67KJFi6KsrKybJySia3uaMGFCLF++PF588cV44IEHoiiKOOWUU2Lnzp09NHXf0tkdbdy4MTZu3BjXXnttPPfcc3HrrbfGqlWrYsaMGT04dd/Tle+lbdu2xamnnhp/8zd/00NT9i0//vGPY86cOTF//vx45pln4sgjj4xJkybFW2+9tcvzH3/88TjrrLNixowZsXbt2pg6dWpMnTo1nnvuuR6evG/p7J62bdsWn/rUp2LhwoVRU1PTw9P2TZ3d0U9/+tM466yz4uGHH47GxsYYNWpUnHLKKfHGG2/08OR9S2f3NHz48Pje974XjY2N8T//8z9xzjnnxDnnnBMPPPBAD0/et3R2T+977bXX4qKLLoqTTjqphyZNVJDmhRdeKCKieOqpp0rH7r///qKsrKx44403PvKxa9euLf7gD/6gePPNN4uIKFauXNnN0/Zdu7On/+sXv/hFERHFK6+80h1j9mlZO7rzzjuLAQMGFDt27OiOMfu83d3Tww8/XERE8dvf/rYbp+x7jj322GLWrFmlr3fu3FnU1tYWCxYs2OX5Z5xxRjF58uQOxyZOnFicd9553TpnX9fZPf1fhxxySHH99dd343QUxe7tqCiK4r333iuGDBlS3Hbbbd01IsXu76koiuLoo48uLrnkku4Yj/+vK3t67733iuOPP774p3/6p+Lss88upkyZ0gOT5vGKdqLGxsYYOnRoHHPMMaVj9fX10a9fv1i9evWHPm7btm3xjW98I5YsWeK/UveAru7p/9q6dWssX748xo4dG6NGjequUfusjB1FRLS0tERlZWWUl5d3x5h9XtaeyPPuu+/GmjVror6+vnSsX79+UV9fH42Njbt8TGNjY4fzIyImTZr0oeez+7qyJ3pWxo62bdsWO3bsiOHDh3fXmH3e7u6pKIpoaGiIdevWxZe//OXuHLVP6+qevv/978eIESP22p9OFNqJmpqaYsSIER2OlZeXx/Dhw6OpqelDH3fhhRfG8ccfH1OmTOnuEYmu7yki4sYbb4zBgwfH4MGD4/77748HH3wwBgwY0J3j9km7s6P3vf322/GDH/zgE791g87L2BO53n777di5c2dUV1d3OF5dXf2hO2lqaurU+ey+ruyJnpWxo+9+97tRW1v7e/8hizxd3VNLS0sMHjw4BgwYEJMnT44bbrgh/uiP/qi7x+2zurKnxx57LG655ZZYtmxZT4zYLYT2JzB37twoKyv7yFtXPxTrnnvuiYceesiHmiTozj29b/r06bF27dp45JFH4jOf+UycccYZsX379qRnsO/riR1FRLS2tsbkyZPj8MMPj7/927/d/cH7mJ7aE8C+auHChbFixYpYuXJlDBw4sLfH4QOGDBkSP//5z+Opp56KK6+8MubMmRM//elPe3ss/r8tW7bEN7/5zVi2bFkceOCBvT1Ol/l5yk/gO9/5TnzrW9/6yHM+9alPRU1Nze+9of+9996LTZs2feiPhD/00EPx6quvxtChQzscnzZtWpx00km+6TuhO/f0vqqqqqiqqopx48bFcccdF8OGDYuVK1fGWWedtbvj9wk9saMtW7bEqaeeGkOGDImVK1dG//79d3fsPqcn9kT3OPDAA2O//faL5ubmDsebm5s/dCc1NTWdOp/d15U90bN2Z0fXXnttLFy4MP77v/87vvCFL3TnmH1eV/fUr1+/+PSnPx0REUcddVS8+OKLsWDBgjj55JO7c9w+q7N7evXVV+O1116L008/vXSsvb09In73k3Pr1q2LQw89tHuHTiC0P4GDDjooDjrooI89r66uLjZv3hxr1qyJCRMmRMTvQrq9vT0mTpy4y8fMnTs3/vzP/7zDsSOOOCKuv/76Dv9y8fG6c0+7UhRFFEURbW1tXZ65r+nuHbW2tsakSZOioqIi7rnnHq8idFFPfy+RZ8CAATFhwoRoaGgo/RqU9vb2aGhoiPPPP3+Xj6mrq4uGhoaYPXt26diDDz4YdXV1PTBx39SVPdGzurqja665Jq688sp44IEHOnx+Bd0j63upvb3d/5/rRp3d0/jx4+PZZ5/tcOySSy6JLVu2xD/8wz/sPZ+P1MsfxrbPOfXUU4ujjz66WL16dfHYY48V48aNK84666zS/b/+9a+Lz372s8Xq1as/9BrhU8e7XWf39OqrrxZXXXVV8fTTTxe/+tWvip/97GfF6aefXgwfPrxobm7uraexT+vsjlpaWoqJEycWRxxxRPHKK68Ub775Zun23nvv9dbT2Od15c+8N998s1i7dm2xbNmyIiKKRx99tFi7dm3xm9/8pjeewj5nxYoVRUVFRXHrrbcWL7zwQjFz5sxi6NChRVNTU1EURfHNb36zmDt3bun8n/3sZ0V5eXlx7bXXFi+++GIxf/78on///sWzzz7bW0+hT+jsntra2oq1a9cWa9euLUaOHFlcdNFFxdq1a4uXX365t57CPq+zO1q4cGExYMCA4t/+7d86/B20ZcuW3noKfUJn93TVVVcV//Vf/1W8+uqrxQsvvFBce+21RXl5ebFs2bLeegp9Qmf39EF746eOC+1kv/nNb4qzzjqrGDx4cFFZWVmcc845Hf6AXb9+fRERxcMPP/yh1xDa3a+ze3rjjTeK0047rRgxYkTRv3//4uCDDy6+8Y1vFC+99FIvPYN9X2d39P6vitrVbf369b3zJPqArvyZN3/+/F3uafny5T3/BPZRN9xwQzF69OhiwIABxbHHHls88cQTpfu+8pWvFGeffXaH8++8887iM5/5TDFgwIDic5/7XHHffff18MR9U2f29P730gdvX/nKV3p+8D6kMzs65JBDdrmj+fPn9/zgfUxn9vS9732v+PSnP10MHDiwGDZsWFFXV1esWLGiF6buezr7d9P/tTeGdllRFEXPvHYOAAAA+z6fOg4AAACJhDYAAAAkEtoAAACQSGgDAABAIqENAAAAiYQ2AAAAJBLaAAAAkEhoAwAAQCKhDQAAAImENgAAACQS2gAAAJDo/wFJMUgtWm0D5wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HINT_TYPES = [\"none\", \"sycophancy\", \"induced_urgency\"]\n",
    "df = load_ablation_dataframe(DATASET, model_name, HINT_TYPES[1:], N_QUESTIONS)\n",
    "fig, summary = plot(df)\n",
    "fig.show()\n",
    "\n",
    "display(summary.head())  # the numeric table you asked for\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
